{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "import pickle\n",
    "from source.utils.file_read import process_and_concat_files \n",
    "from source.utils.file_read import filter_df\n",
    "from source.utils.collect_results import collect_pb_result, collect_rmse_result, create_df_forecaster_first_stage, create_df_forecaster_second_stage\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.simulation.submission_module import submission_forecasters\n",
    "from source.simulation.buyer_module import prepare_buyer_data\n",
    "from source.ensemble.stack_generalization.utils.display_results import display_forecasting_metrics\n",
    "from source.ensemble.combination_scheme.equal_weights import calculate_equal_weights\n",
    "from source.ensemble.combination_scheme.avg_weights import calculate_weighted_avg\n",
    "from source.ensemble.combination_scheme.model_selection import run_model_selection\n",
    "from source.plots.plot_forecasts import plot_forecasts, plot_var_forecasts, plot_weighted_avg_forecasts\n",
    "from source.plots.display_hypothesis_testing import run_statistical_comparison_analysis\n",
    "from source.plots.display_metrics import display_table_metrics\n",
    "from source.plots.display_contributions import weighted_avg_pivot_data, permutation_pivot_data, lasso_coefs_pivot_data\n",
    "from source.ensemble.combination_scheme.weight_avg_plot_importance import plot_weight_avg_contributions\n",
    "from source.assessment_contributions import compute_forecasters_contributions\n",
    "from source.ml_engine import create_ensemble_forecasts\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.simulation_setting import Simulation, WeightedAvg, Stack\n",
    "from source.simulation.helpers_simulation import process_combination_scheme, update_dict_weights, compute_coefficients\n",
    "from source.utils.session_ml_info import delete_previous_day_pickle\n",
    "sim_params = Simulation.testing_period\n",
    "weight_avg_params = WeightedAvg.params\n",
    "ens_params = Stack.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coverage(df_pred_ensemble, col_90, col_10, col_targets):\n",
    "    \"\"\"\n",
    "    Calculates the coverage percentage of target values falling within the\n",
    "    10th and 90th percentile predictions.\n",
    "    \"\"\"\n",
    "    condition = (df_pred_ensemble[col_90] >= df_pred_ensemble[col_targets]) & \\\n",
    "                (df_pred_ensemble[col_10] <= df_pred_ensemble[col_targets])\n",
    "    return np.mean(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(sim_params['random_seed'])\n",
    "\n",
    "# process and concatenate files\n",
    "files = [sim_params['file_1'], sim_params['file_2'], sim_params['file_3'], sim_params['file_4'], \n",
    "            sim_params['file_5'], sim_params['file_6'], sim_params['file_7'], sim_params['file_8'], \n",
    "            sim_params['file_9'], sim_params['file_10'], sim_params['file_11'], sim_params['file_12']]\n",
    "\n",
    "logger.info(' ')\n",
    "logger.info(f'Load Files: {files}')\n",
    "\n",
    "df = process_and_concat_files(files)\n",
    "\n",
    "# filter data forecasters\n",
    "df_filtered = filter_df(df, sim_params['forecasts_col'], sim_params['measured_col'])\n",
    "\n",
    "# replace NaN values\n",
    "if sim_params['replace_nan']:\n",
    "    logger.info(' ')\n",
    "    logger.warning(\"Replacing NaN values with 0s\")\n",
    "    print(df_filtered.isna().sum())\n",
    "    df_filtered.fillna(0, inplace=True)\n",
    "\n",
    "# # set buyer resource name\n",
    "buyer_resource_name = 'b1r1'\n",
    "\n",
    "# loss quantile ensemble regressor\n",
    "lst_rmse_ensemble = []\n",
    "#loss best model selection\n",
    "lst_rmse_best_model = []\n",
    "# loss equal weights scheme\n",
    "lst_rmse_equal_weights = []\n",
    "# loss weighted average scheme\n",
    "lst_rmse_weighted_avg = []\n",
    "# loss weighted average scheme soft\n",
    "lst_rmse_weighted_avg_soft = []\n",
    "# loss baseline day ahead\n",
    "lst_rmse_baseline_dayahead = []\n",
    "# loss baseline day ahead 11\n",
    "lst_rmse_baseline_dayahead11h = []\n",
    "# loss baseline week ahead\n",
    "lst_rmse_baseline_week_ahead = []\n",
    "# loss baseline most recent\n",
    "if sim_params['most_recent']:\n",
    "    lst_rmse_baseline_most_recent = []\n",
    "# loss baseline malicious\n",
    "if sim_params['malicious']:\n",
    "    lst_rmse_baseline_malicious = []\n",
    "# loss baseline noisy\n",
    "if sim_params['noisy']:\n",
    "    lst_rmse_baseline_noisy = []\n",
    "\n",
    "# coverage ensemble regressor\n",
    "lst_coverage_ensemble = []\n",
    "# coverage best model selection\n",
    "lst_coverage_best_model = []\n",
    "# coverage equal weights scheme\n",
    "lst_coverage_equal_weights = []\n",
    "# coverage weighted average scheme\n",
    "lst_coverage_weighted_avg = []\n",
    "# coverage weighted average scheme soft\n",
    "lst_coverage_weighted_avg_soft = []\n",
    "# coverage baseline day ahead\n",
    "lst_coverage_baseline_dayahead = []\n",
    "# coverage baseline day ahead 11\n",
    "lst_coverage_baseline_dayahead11h = []\n",
    "# coverage baseline week ahead\n",
    "lst_coverage_baseline_week_ahead = []\n",
    "# coverage baseline most recent\n",
    "if sim_params['most_recent']:\n",
    "    lst_coverage_baseline_most_recent = []\n",
    "# coverage baseline malicious\n",
    "if sim_params['malicious']:\n",
    "    lst_coverage_baseline_malicious = []\n",
    "# coverage baseline noisy\n",
    "if sim_params['noisy']:\n",
    "    lst_coverage_baseline_noisy = []\n",
    "\n",
    "    \n",
    "# loss var ensemble regressor\n",
    "lst_rmse_var_ensemble = []\n",
    "# loss var best model selection\n",
    "lst_rmse_var_best_model = []\n",
    "# loss var equal weights scheme\n",
    "lst_rmse_var_equal_weights = []\n",
    "# loss var weighted average scheme\n",
    "lst_rmse_var_weighted_avg = []\n",
    "# loss var weighted average scheme soft\n",
    "lst_rmse_var_weighted_avg_soft = []\n",
    "# loss var baseline day ahead\n",
    "lst_rmse_var_baseline_dayahead = []\n",
    "# loss var baseline day ahead 11\n",
    "lst_rmse_var_baseline_dayahead11h = []\n",
    "# loss var baseline week ahead\n",
    "lst_rmse_var_baseline_week_ahead = []\n",
    "# loss var baseline most recent\n",
    "if sim_params['most_recent']:\n",
    "    lst_rmse_var_baseline_most_recent = []\n",
    "    lst_pb_most_recent_q10 = []\n",
    "    lst_pb_most_recent_q90 = []\n",
    "# loss var baseline malicious\n",
    "if sim_params['malicious']:\n",
    "    lst_rmse_var_baseline_malicious = []\n",
    "    lst_pb_malicious_q10 = []\n",
    "    lst_pb_malicious_q90 = []\n",
    "# loss var baseline noisy\n",
    "if sim_params['noisy']:\n",
    "    lst_rmse_var_baseline_noisy = []\n",
    "    lst_pb_noisy_q10 = []\n",
    "    lst_pb_noisy_q90 = []\n",
    "\n",
    "# loss quantile ensemble regressor\n",
    "lst_pb_ensemble_q10 = []\n",
    "lst_pb_ensemble_q90 = []\n",
    "# loss quantile best model selection\n",
    "lst_pb_best_model_q10 = []\n",
    "lst_pb_best_model_q90 = []\n",
    "# loss avg weights scheme\n",
    "lst_pb_weighted_avg_q10 = []\n",
    "lst_pb_weighted_avg_q90 = []\n",
    "# loss soft avg weights scheme\n",
    "lst_pb_weighted_avg_soft_q10 = []\n",
    "lst_pb_weighted_avg_soft_q90 = []\n",
    "# loss equal weighted scheme\n",
    "lst_pb_equal_weights_q10 = []\n",
    "lst_pb_equal_weights_q90 = []\n",
    "# loss baseline day ahead\n",
    "lst_pb_dayahead_q10 = []\n",
    "lst_pb_dayahead_q90  = []\n",
    "# loss baseline day ahead 11\n",
    "lst_pb_dayahead_11h_q10 = []\n",
    "lst_pb_dayahead_11h_q90 = []\n",
    "# loss baseline week ahead\n",
    "lst_pb_week_ahead_q10 = []\n",
    "lst_pb_week_ahead_q90 = []\n",
    "\n",
    "# remove previous day pickle file\n",
    "logger.info(' ')\n",
    "delete_previous_day_pickle()\n",
    "logger.opt(colors = True).warning('previous day pickle file removed')\n",
    "\n",
    "# final contributions forecasters\n",
    "avg_permutation_contributions = defaultdict(dict)\n",
    "avg_shapley_contributions = defaultdict(dict)\n",
    "avg_coefficients_contributions = defaultdict(dict)\n",
    "avg_weighted_avg_contributions = defaultdict(dict)\n",
    "avg_weighted_soft_avg_contributions = defaultdict(dict)\n",
    "\n",
    "# Collect Ramp Alarm\n",
    "list_ramp_alarm = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors=True).info(f'<blue>Start training: {start_training_timestamp} - End training: {end_training_timestamp}</blue>')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors = True).info(f'<blue>Start prediction: {start_prediction_timestamp} - End prediction: {end_prediction_timestamp}</blue>')\n",
    "\n",
    "    day_previous_start_prediction_timestamp = start_prediction_timestamp - pd.Timedelta('1day')\n",
    "    df_train = df_filtered[df_filtered.index.to_series().between(start_training_timestamp, end_training_timestamp)].iloc[:-1,:]\n",
    "    df_test = df_filtered[df_filtered.index.to_series().between(day_previous_start_prediction_timestamp, end_prediction_timestamp)].iloc[:-1,:]\n",
    "                                                                                                                            \n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of training data: {len(df_train)} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of test data: {len(df_test)} </blue>')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue> -----------------> Forecasters prediction submitted </blue>')\n",
    "\n",
    "# # ----------------------------> FORECASTERS PREDICTION SUBMISSION <----------------------------\n",
    "\n",
    "    df_market, df_train, df_test = submission_forecasters(sim_params, df_train, df_test)   \n",
    "\n",
    "# # ----------------------------> BUYERS DATA <----------------------------\n",
    "\n",
    "    df_buyer, forecast_range = prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "\n",
    "# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\n",
    "\n",
    "    results_ensemble_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                                            df_buyer=df_buyer, \n",
    "                                                            df_market=df_market,\n",
    "                                                            end_training_timestamp=end_training_timestamp,\n",
    "                                                            forecast_range = forecast_range,\n",
    "                                                            challenge_usecase='simulation',\n",
    "                                                            simulation=True)\n",
    "    \n",
    "\n",
    "\n",
    "    if sim_params['baselines_comparison']:\n",
    "        # # # ----------------------------> COMBINATION SCHEME DATA <----------------------------\n",
    "\n",
    "        df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var = process_combination_scheme(df_train, df_test, end_training_timestamp, day_previous_start_prediction_timestamp)\n",
    "        \n",
    "        df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']   \n",
    "        df_pred_ensemble.rename(columns={'q50_' + 'b1r1': '50_predictions', 'q10_' + 'b1r1': '10_predictions', 'q90_' + 'b1r1': '90_predictions', 'norm_' + 'b1r1': 'targets'}, inplace=True)\n",
    "        df_pred_ensemble['targets'] = day_previous_df_test_norm['norm_measured'].values[-96:]\n",
    "        df_var_ensemble = results_ensemble_forecasts['wind_power_ramp']['predictions']\n",
    "        df_var_ensemble.rename(columns={'q50_' + 'b1r1': '50_var_predictions', 'q10_' + 'b1r1': '10_var_predictions', 'q90_' + 'b1r1': '90_var_predictions', 'targets': 'targets'}, inplace=True)\n",
    "        df_var_ensemble['targets'] = day_previous_df_test_norm_var['norm_measured'].values[-96:]\n",
    "        \n",
    "        df_test_ensemble = pd.DataFrame(df_pred_ensemble['targets']) \n",
    "        df_2stage_test = pd.DataFrame(df_var_ensemble['targets'])\n",
    "\n",
    "    # # ----------------------------> PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        # performance ensemble\n",
    "        lst_rmse_ensemble, rmse_ensemble = collect_rmse_result(df_pred_ensemble, '50_predictions', lst_rmse_ensemble)\n",
    "\n",
    "        lst_pb_ensemble_q10, lst_pb_ensemble_q90, pinball_ensemble_q10, pinball_ensemble_q90 = collect_pb_result(df_pred_ensemble, \n",
    "                                                                                                                '10_predictions', '90_predictions', \n",
    "                                                                                                                lst_pb_ensemble_q10, lst_pb_ensemble_q90)\n",
    "        \n",
    "        # coverage ensemble\n",
    "        coverage_ensemble = calculate_coverage(df_pred_ensemble, '90_predictions', '10_predictions', 'targets')\n",
    "        lst_coverage_ensemble.append(round(coverage_ensemble, 3))\n",
    "\n",
    "        # performance variability ensemble\n",
    "        lst_rmse_var_ensemble, rmse_var_ensemble = collect_rmse_result(df_var_ensemble, '50_var_predictions', lst_rmse_var_ensemble)\n",
    "\n",
    "        # coverage ensemble variability\n",
    "        coverage_var_ensemble = calculate_coverage(df_var_ensemble, '90_var_predictions', '10_var_predictions', 'targets')\n",
    "        lst_coverage_ensemble.append(round(coverage_var_ensemble, 3))\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model_var = run_model_selection(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid = weight_avg_params['window_size_valid'], var=True)\n",
    "        lst_rmse_var_best_model, rmse_var_best_model = collect_rmse_result(df_best_model_var, 'mean_prediction', lst_rmse_var_best_model)\n",
    "\n",
    "        # performance weighted average\n",
    "        df_weighted_avg_var, dict_weights_var = calculate_weighted_avg(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid=weight_avg_params['window_size_valid'], var=True)\n",
    "        lst_rmse_var_weighted_avg, rmse_var_weighted_avg = collect_rmse_result(df_weighted_avg_var, 'mean_prediction', lst_rmse_var_weighted_avg)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft_var, dict_weights_soft_var = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], var=True, norm='softmax')\n",
    "        lst_rmse_var_weighted_avg_soft, rmse_var_weighted_avg_soft = collect_rmse_result(df_weighted_avg_soft_var, 'mean_prediction', lst_rmse_var_weighted_avg_soft)\n",
    "\n",
    "        # plot contribution weighted average\n",
    "        if ens_params['plot_importance_weighted_avg']:\n",
    "            plot_weight_avg_contributions(dict_weights_var, quantile=0.5, stage='Wind Power Variability', days= weight_avg_params['window_size_valid'])\n",
    "\n",
    "        # performance equal weights\n",
    "        df_equal_weights_var = calculate_equal_weights(day_previous_df_test_norm_var, start_prediction_timestamp)\n",
    "        lst_rmse_var_equal_weights, rmse_var_equal_weights = collect_rmse_result(df_equal_weights_var, 'mean_prediction', lst_rmse_var_equal_weights)\n",
    "\n",
    "        # performance day-ahead\n",
    "        df_dayahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead', start_prediction_timestamp)\n",
    "        lst_rmse_var_baseline_dayahead, rmse_var_dayahead = collect_rmse_result(df_dayahead_var, 'norm_dayaheadforecast', lst_rmse_var_baseline_dayahead)\n",
    "\n",
    "        # performance day-ahead-11h\n",
    "        df_dayahead_11h_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead11h', start_prediction_timestamp)\n",
    "        lst_rmse_var_baseline_dayahead11h, rmse_var_dayahead_11h = collect_rmse_result(df_dayahead_11h_var, 'norm_dayahead11hforecast', lst_rmse_var_baseline_dayahead11h)\n",
    "\n",
    "        # performance week ahead\n",
    "        df_week_ahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'weekahead', start_prediction_timestamp)\n",
    "        lst_rmse_var_baseline_week_ahead, rmse_var_week_ahead = collect_rmse_result(df_week_ahead_var, 'norm_weekaheadforecast', lst_rmse_var_baseline_week_ahead)\n",
    "\n",
    "        # performance most recent\n",
    "        if sim_params['most_recent']:\n",
    "            df_most_recent_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'mostrecent', start_prediction_timestamp)\n",
    "            lst_rmse_var_baseline_most_recent, rmse_var_most_recent = collect_rmse_result(df_most_recent_var, 'norm_mostrecentforecast', lst_rmse_var_baseline_most_recent)\n",
    "\n",
    "        # performance malicious\n",
    "        if sim_params['malicious']:\n",
    "            df_malicious_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'malicious', start_prediction_timestamp)\n",
    "            lst_rmse_var_baseline_malicious, rmse_var_malicious = collect_rmse_result(df_malicious_var, 'norm_maliciousforecast', lst_rmse_var_baseline_malicious)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            df_noisy_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'noisy', start_prediction_timestamp)\n",
    "            lst_rmse_var_baseline_noisy, rmse_var_noisy = collect_rmse_result(df_noisy_var, 'norm_noisyforecast', lst_rmse_var_baseline_noisy)\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model = run_model_selection(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        lst_rmse_best_model, rmse_best_model = collect_rmse_result(df_best_model, 'mean_prediction', lst_rmse_best_model)\n",
    "        lst_pb_best_model_q10, lst_pb_best_model_q90, pinball_best_model_q10, pinball_best_model_q90 = collect_pb_result(df_best_model,\n",
    "                                                                                                                        'Q10', 'Q90',\n",
    "                                                                                                                        lst_pb_best_model_q10, lst_pb_best_model_q90)\n",
    "\n",
    "        # performance weighted average\n",
    "        df_weighted_avg, dict_weights = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        lst_rmse_weighted_avg, rmse_weighted_avg = collect_rmse_result(df_weighted_avg, 'mean_prediction', lst_rmse_weighted_avg)\n",
    "        lst_pb_weighted_avg_q10, lst_pb_weighted_avg_q90, pinball_weighted_avg_q10, pinball_weighted_avg_q90 = collect_pb_result(df_weighted_avg, \n",
    "                                                                                                                                    'Q10', 'Q90', \n",
    "                                                                                                                                    lst_pb_weighted_avg_q10, lst_pb_weighted_avg_q90)\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft, dict_weights_soft = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], norm='softmax')\n",
    "        lst_rmse_weighted_avg_soft, rmse_weighted_avg_soft = collect_rmse_result(df_weighted_avg_soft, 'mean_prediction', lst_rmse_weighted_avg_soft)\n",
    "        lst_pb_weighted_avg_soft_q10, lst_pb_weighted_avg_soft_q90, pinball_weighted_avg_soft_q10, pinball_weighted_avg_soft_q90 = collect_pb_result(df_weighted_avg_soft,\n",
    "                                                                                                                                                    'Q10', 'Q90', \n",
    "                                                                                                                                                    lst_pb_weighted_avg_soft_q10, lst_pb_weighted_avg_soft_q90)\n",
    "        # plot forecasts weighted avg\n",
    "        if ens_params['plot_weighted_avg']:\n",
    "            plot_weighted_avg_forecasts(df_weighted_avg)\n",
    "\n",
    "        # plot contribution weighted average\n",
    "        if ens_params['plot_importance_weighted_avg']:\n",
    "            for quantile in ens_params['quantiles']:\n",
    "                plot_weight_avg_contributions(dict_weights, quantile, stage='Wind Power', days = weight_avg_params['window_size_valid'])\n",
    "\n",
    "        # performance equal weights\n",
    "        df_equal_weights = calculate_equal_weights(day_previous_df_test_norm, start_prediction_timestamp)\n",
    "        lst_rmse_equal_weights, rmse_equal_weights = collect_rmse_result(df_equal_weights, 'mean_prediction', lst_rmse_equal_weights)\n",
    "        lst_pb_equal_weights_q10, lst_pb_equal_weights_q90, pinball_equal_weights_q10, pinball_equal_weights_q90 = collect_pb_result(df_equal_weights, \n",
    "                                                                                                                                            'Q10', 'Q90', \n",
    "                                                                                                                                            lst_pb_equal_weights_q10, lst_pb_equal_weights_q90)\n",
    "        # performance day-ahead\n",
    "        df_dayahead = create_df_forecaster_first_stage(day_previous_df_test_norm, 'dayahead', start_prediction_timestamp)\n",
    "        lst_rmse_baseline_dayahead, rmse_dayahead = collect_rmse_result(df_dayahead, 'norm_dayaheadforecast', lst_rmse_baseline_dayahead)\n",
    "        lst_pb_dayahead_q10, lst_pb_dayahead_q90, pinball_dayahead_q10, pinball_dayahead_q90 = collect_pb_result(df_dayahead, \n",
    "                                                                                                                    'norm_dayaheadconfidence10', 'norm_dayaheadconfidence90', \n",
    "                                                                                                                    lst_pb_dayahead_q10, lst_pb_dayahead_q90)\n",
    "        # performance day-ahead-11h\n",
    "        df_dayahead_11h = create_df_forecaster_first_stage(day_previous_df_test_norm, 'dayahead11h', start_prediction_timestamp)\n",
    "        lst_rmse_baseline_dayahead11h, rmse_dayahead_11h = collect_rmse_result(df_dayahead_11h, 'norm_dayahead11hforecast', lst_rmse_baseline_dayahead11h)\n",
    "        lst_pb_dayahead_11h_q10, lst_pb_dayahead_11h_q90, pinball_dayahead_11h_q10, pinball_dayahead_11h_q90 = collect_pb_result(df_dayahead_11h, \n",
    "                                                                                                                                    'norm_dayahead11hconfidence10', 'norm_dayahead11hconfidence90', \n",
    "                                                                                                                                    lst_pb_dayahead_11h_q10, lst_pb_dayahead_11h_q90)\n",
    "        # performance week ahead\n",
    "        df_week_ahead = create_df_forecaster_first_stage(day_previous_df_test_norm, 'weekahead', start_prediction_timestamp)\n",
    "        lst_rmse_baseline_week_ahead, rmse_week_ahead = collect_rmse_result(df_week_ahead, 'norm_weekaheadforecast', lst_rmse_baseline_week_ahead)\n",
    "        lst_pb_week_ahead_q10, lst_pb_week_ahead_q90, pinball_week_ahead_q10, pinball_week_ahead_q90 = collect_pb_result(df_week_ahead, \n",
    "                                                                                                                            'norm_weekaheadconfidence10', 'norm_weekaheadconfidence90', \n",
    "                                                                                                                            lst_pb_week_ahead_q10, lst_pb_week_ahead_q90) \n",
    "        # performance most recent\n",
    "        if sim_params['most_recent']:\n",
    "            df_most_recent = create_df_forecaster_first_stage(day_previous_df_test_norm, 'mostrecent', start_prediction_timestamp)\n",
    "            lst_rmse_baseline_most_recent, rmse_most_recent = collect_rmse_result(df_most_recent, 'norm_mostrecentforecast', lst_rmse_baseline_most_recent)\n",
    "            lst_pb_most_recent_q10, lst_pb_most_recent_q90, pinball_most_recent_q10, pinball_most_recent_q90 = collect_pb_result(df_most_recent, \n",
    "                                                                                                                                    'norm_mostrecentconfidence10', 'norm_mostrecentconfidence90', \n",
    "                                                                                                                                    lst_pb_most_recent_q10, lst_pb_most_recent_q90) \n",
    "        # performance malicious cheat\n",
    "        if sim_params['malicious']:\n",
    "            df_malicious = create_df_forecaster_first_stage(day_previous_df_test_norm, 'malicious', start_prediction_timestamp)\n",
    "            lst_rmse_baseline_malicious, rmse_malicious = collect_rmse_result(df_malicious, 'norm_maliciousforecast', lst_rmse_baseline_malicious)\n",
    "            lst_pb_malicious_q10, lst_pb_malicious_q90, pinball_malicious_q10, pinball_malicious_q90 = collect_pb_result(df_malicious, \n",
    "                                                                                                                            'norm_maliciousconfidence10', 'norm_maliciousconfidence90', \n",
    "                                                                                                                            lst_pb_malicious_q10, lst_pb_malicious_q90)\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            df_noisy = create_df_forecaster_first_stage(day_previous_df_test_norm, 'noisy', start_prediction_timestamp)\n",
    "            lst_rmse_baseline_noisy, rmse_noisy = collect_rmse_result(df_noisy, 'norm_noisyforecast', lst_rmse_baseline_noisy)\n",
    "            lst_pb_noisy_q10, lst_pb_noisy_q90, pinball_noisy_q10, pinball_noisy_q90 = collect_pb_result(df_noisy, \n",
    "                                                                                                            'norm_noisyconfidence10', 'norm_noisyconfidence90', \n",
    "                                                                                                            lst_pb_noisy_q10, lst_pb_noisy_q90)\n",
    "        # plot forecasts\n",
    "        if ens_params['plt_wind_power_ensemble']:\n",
    "            plot_forecasts(df_pred_ensemble, df_test_ensemble, list_wind_ramps=[], title=f'Wind Power Forecasting - coverage {coverage_ensemble}')\n",
    "\n",
    "        # plot variability forecast results\n",
    "        if ens_params['plt_wind_power_variability_ensemble']:\n",
    "            plot_var_forecasts(df_var_ensemble, df_2stage_test, list_wind_ramps=[], title=f'Wind Power Variability Forecasting - coverage {coverage_var_ensemble}')\n",
    "\n",
    "        ## ----------------------------> DISPLAY METRICS <----------------------------\n",
    "        if sim_params['display_metrics']:\n",
    "            results_metrics = {'ensemble': {'rmse': rmse_ensemble, \n",
    "                                            'pb10': pinball_ensemble_q10, \n",
    "                                            'pb90': pinball_ensemble_q90, \n",
    "                                            'rmse_var': rmse_var_ensemble},\n",
    "                                'best_model': {'rmse': rmse_best_model,\n",
    "                                                'pb10': pinball_best_model_q10, \n",
    "                                                'pb90': pinball_best_model_q90, \n",
    "                                                'rmse_var': rmse_var_best_model},\n",
    "                                'weighted_avg': {'rmse': rmse_weighted_avg, \n",
    "                                                'pb10': pinball_weighted_avg_q10, \n",
    "                                                'pb90': pinball_weighted_avg_q90, \n",
    "                                                'rmse_var': rmse_var_weighted_avg},\n",
    "                                'weighted_avg_soft': {'rmse': rmse_weighted_avg_soft, \n",
    "                                                    'pb10': pinball_weighted_avg_soft_q10, \n",
    "                                                    'pb90': pinball_weighted_avg_soft_q90, \n",
    "                                                    'rmse_var': rmse_var_weighted_avg_soft},\n",
    "                                'equal_weights': {'rmse': rmse_equal_weights, \n",
    "                                                'pb10': pinball_equal_weights_q10, \n",
    "                                                'pb90': pinball_equal_weights_q90, \n",
    "                                                'rmse_var': rmse_var_equal_weights},\n",
    "                                'day_ahead': {'rmse': rmse_dayahead, \n",
    "                                            'pb10': pinball_dayahead_q10, \n",
    "                                            'pb90': pinball_dayahead_q90, \n",
    "                                            'rmse_var': rmse_var_dayahead},\n",
    "                                'day_ahead_11h': {'rmse': rmse_dayahead_11h, \n",
    "                                                'pb10': pinball_dayahead_11h_q10, \n",
    "                                                'pb90': pinball_dayahead_11h_q90, \n",
    "                                                'rmse_var': rmse_var_dayahead_11h},\n",
    "                                'week_ahead': {'rmse': rmse_week_ahead, \n",
    "                                            'pb10': pinball_week_ahead_q10, \n",
    "                                            'pb90': pinball_week_ahead_q90, \n",
    "                                            'rmse_var': rmse_var_week_ahead}\n",
    "                                }\n",
    "            if sim_params['most_recent']:\n",
    "                results_metrics['most_recent'] = {'rmse': rmse_most_recent, \n",
    "                                                'pb10': pinball_most_recent_q10, \n",
    "                                                'pb90': pinball_most_recent_q90, \n",
    "                                                'rmse_var': rmse_var_most_recent}\n",
    "            if sim_params['malicious']:\n",
    "                results_metrics['malicious'] = {'rmse': rmse_malicious, \n",
    "                                                        'pb10': pinball_malicious_q10, \n",
    "                                                        'pb90': pinball_malicious_q90, \n",
    "                                                        'rmse_var': rmse_var_malicious}\n",
    "            if sim_params['noisy']:\n",
    "                results_metrics['noisy'] = {'rmse': rmse_noisy, \n",
    "                                                'pb10': pinball_noisy_q10, \n",
    "                                                'pb90': pinball_noisy_q90, \n",
    "                                                'rmse_var': rmse_var_noisy}\n",
    "            \n",
    "            display_forecasting_metrics(sim_params=sim_params, ens_params=ens_params, dict_metrics = results_metrics)\n",
    "\n",
    "    if sim_params['contribution_comparison']:    \n",
    "\n",
    "        # # ----------------------------> FORECASTERS PERMUTATION CONTRIBUTIONS <----------------------------\n",
    "        ens_params['contribution_method'] = 'permutation'\n",
    "        contr_mthd = ens_params['contribution_method']\n",
    "        logger.info(' ')\n",
    "        logger.opt(colors = True).info(f'<blue> -----------------> Forecasters {contr_mthd} contributions computed </blue>')\n",
    "        y_test = df_test['measured'].values\n",
    "        iter_permutation_contributions = compute_forecasters_contributions(buyer_resource_name, ens_params, y_test, forecast_range)\n",
    "        avg_permutation_contributions = update_dict_weights(avg_permutation_contributions, iter_permutation_contributions, iteration=i)\n",
    "\n",
    "        # # ----------------------------> FORECASTERS SHAPLEY CONTRIBUTIONS <----------------------------\n",
    "        ens_params['contribution_method'] = 'shapley'\n",
    "        contr_mthd = ens_params['contribution_method']\n",
    "        logger.info(' ')\n",
    "        logger.opt(colors = True).info(f'<blue> -----------------> Forecasters {contr_mthd} contributions compute </blue>')\n",
    "        y_test = df_test['measured'].values\n",
    "        iter_shapley_contributions = compute_forecasters_contributions(buyer_resource_name, ens_params, y_test, forecast_range)\n",
    "        avg_shapley_contributions = update_dict_weights(avg_shapley_contributions, iter_shapley_contributions, iteration=i)\n",
    "\n",
    "        # # ----------------------------> FORECASTERS COEFFICIENTS CONTRIBUTIONS <----------------------------\n",
    "        if ens_params['model_type'] == 'LR':\n",
    "            logger.info(' ')\n",
    "            logger.opt(colors = True).info('<blue> -----------------> Forecasters coefficients contributions computed </blue>')\n",
    "            with open('/Users/gio/Desktop/Elia-RES-Forecasting/info_model/b1r1_previous_day.pickle', 'rb') as handle:\n",
    "                previous_day = pickle.load(handle)\n",
    "            iter_coefficients_contributions = compute_coefficients(previous_day)\n",
    "            avg_coefficients_contributions = update_dict_weights(avg_coefficients_contributions, \n",
    "                                                            iter_coefficients_contributions, \n",
    "                                                            iteration=i)\n",
    "\n",
    "        if sim_params['baseline_comparison']:\n",
    "            # # ----------------------------> FORECASTERS WEIGHTED AVERAGE CONTRIBUTIONS (SUM NORMALIZATION) <---------------------------- \n",
    "            logger.info(' ')\n",
    "            logger.opt(colors = True).info('<blue> -----------------> Forecasters weighted average contributions computed </blue>')\n",
    "            iter_weighted_avg_contributions = defaultdict(dict)\n",
    "            iter_weighted_avg_contributions['wind_power'] = dict_weights\n",
    "            iter_weighted_avg_contributions['wind_power_ramp'] = dict_weights_var\n",
    "            avg_weighted_avg_contributions = update_dict_weights(avg_weighted_avg_contributions, iter_weighted_avg_contributions, iteration=i)\n",
    "\n",
    "            ## ----------------------------> FORECASTERS WEIGHTED AVERAGE CONTRIBUTIONS (SOFTMAX NORMALIZATION) <----------------------------\n",
    "            logger.info(' ')\n",
    "            logger.opt(colors = True).info('<blue> -----------------> Forecasters weighted average contributions (softmax) computed </blue>')\n",
    "            iter_weighted_avg_soft_contributions = defaultdict(dict)\n",
    "            iter_weighted_avg_soft_contributions['wind_power'] = dict_weights_soft\n",
    "            iter_weighted_avg_soft_contributions['wind_power_ramp'] = dict_weights_soft_var\n",
    "            avg_weighted_soft_avg_contributions = update_dict_weights(avg_weighted_soft_avg_contributions, iter_weighted_avg_soft_contributions, iteration=i)\n",
    "\n",
    "    # Clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    import time\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most recent\n",
    "if not sim_params['most_recent']:\n",
    "    lst_rmse_baseline_most_recent = None\n",
    "    lst_pb_most_recent_q10 = None\n",
    "    lst_pb_most_recent_q90 = None\n",
    "    lst_rmse_var_baseline_most_recent = None\n",
    "    \n",
    "# malicious\n",
    "if not sim_params['malicious']:\n",
    "    lst_rmse_baseline_malicious = None\n",
    "    lst_pb_malicious_q10 = None\n",
    "    lst_pb_malicious_q90 = None\n",
    "    lst_rmse_var_baseline_malicious = None\n",
    "\n",
    "# noisy\n",
    "if not sim_params['noisy']:\n",
    "    lst_rmse_baseline_noisy = None\n",
    "    lst_pb_noisy_q10 = None\n",
    "    lst_pb_noisy_q90 = None\n",
    "    lst_rmse_var_baseline_noisy = None\n",
    "\n",
    "# plot statistical comparison q50\n",
    "title1='RMSE-based Statistical Significance'\n",
    "title2='RMSE-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q50, avg_rank_q50 = run_statistical_comparison_analysis(ens_params['model_type'],\n",
    "                                                                lst_rmse_ensemble,\n",
    "                                                                lst_rmse_best_model,\n",
    "                                                                lst_rmse_equal_weights, \n",
    "                                                                lst_rmse_weighted_avg,\n",
    "                                                                lst_rmse_weighted_avg_soft,\n",
    "                                                                lst_rmse_baseline_dayahead, \n",
    "                                                                lst_rmse_baseline_dayahead11h, \n",
    "                                                                lst_rmse_baseline_week_ahead,\n",
    "                                                                lst_rmse_baseline_most_recent,\n",
    "                                                                lst_rmse_baseline_malicious,\n",
    "                                                                lst_rmse_baseline_noisy,\n",
    "                                                                title1, title2)\n",
    "# plot statistical comparison q10\n",
    "title1 = 'Q10 Pinball loss-based Statistical Significance'\n",
    "title2 = 'Q10 Pinball loss-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q10, avg_rank_q10 = run_statistical_comparison_analysis(ens_params['model_type'],\n",
    "                                                            lst_pb_ensemble_q10, \n",
    "                                                            lst_pb_best_model_q10,\n",
    "                                                            lst_pb_equal_weights_q10, \n",
    "                                                            lst_pb_weighted_avg_q10, \n",
    "                                                            lst_pb_weighted_avg_soft_q10,\n",
    "                                                            lst_pb_dayahead_q10, \n",
    "                                                            lst_pb_dayahead_11h_q10, \n",
    "                                                            lst_pb_week_ahead_q10,\n",
    "                                                            lst_pb_most_recent_q10,\n",
    "                                                            lst_pb_malicious_q10,\n",
    "                                                            lst_pb_noisy_q10,\n",
    "                                                            title1, title2)\n",
    "# plot statistical comparison q90\n",
    "title1 = 'Q90 Pinball loss-based Statistical Significance'\n",
    "title2 = 'Q90 Pinball loss-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q90, avg_rank_q90 = run_statistical_comparison_analysis(ens_params['model_type'],\n",
    "                                                            lst_pb_ensemble_q90,\n",
    "                                                            lst_pb_best_model_q90,\n",
    "                                                            lst_pb_equal_weights_q90, \n",
    "                                                            lst_pb_weighted_avg_q90,\n",
    "                                                            lst_pb_weighted_avg_soft_q90, \n",
    "                                                            lst_pb_dayahead_q90, \n",
    "                                                            lst_pb_dayahead_11h_q90, \n",
    "                                                            lst_pb_week_ahead_q90,\n",
    "                                                            lst_pb_most_recent_q90,\n",
    "                                                            lst_pb_malicious_q90,\n",
    "                                                            lst_pb_noisy_q90,\n",
    "                                                            title1, title2)\n",
    "# plot statistical comparison variability\n",
    "title1 = 'RMSE-based Statistical Significance'\n",
    "title2 = 'RMSE-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q50_var, avg_rank_q50_var = run_statistical_comparison_analysis(ens_params['var_model_type'],\n",
    "                                                                lst_rmse_var_ensemble,\n",
    "                                                                lst_rmse_var_best_model, \n",
    "                                                                lst_rmse_var_equal_weights, \n",
    "                                                                lst_rmse_var_weighted_avg,\n",
    "                                                                lst_rmse_var_weighted_avg_soft, \n",
    "                                                                lst_rmse_var_baseline_dayahead, \n",
    "                                                                lst_rmse_var_baseline_dayahead11h, \n",
    "                                                                lst_rmse_var_baseline_week_ahead,\n",
    "                                                                lst_rmse_var_baseline_most_recent,\n",
    "                                                                lst_rmse_var_baseline_malicious,\n",
    "                                                                lst_rmse_var_baseline_noisy,\n",
    "                                                                title1, title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the styled DataFrame\n",
    "dfs = [data_q10, data_q50, data_q90, data_q50_var]\n",
    "prefixes = ['Q10', 'Q50', 'Q90', 'Q50_var']\n",
    "result, styled_result = display_table_metrics(dfs, prefixes)\n",
    "styled_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute percentage of improvement of the best\n",
    "perc_improvement_df = (result/np.min(result, axis=0)-1)*100\n",
    "perc_improvement_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_pivot = weighted_avg_pivot_data(sim_params, avg_weighted_avg_contributions)\n",
    "\n",
    "# # Plot the stacked bar chart\n",
    "df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "plt.xlabel('Key and Quantile')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Stacked Bar Chart of Average Weighted Avg Scheme Contributions')\n",
    "plt.show()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "plt.xlabel('Series')\n",
    "plt.ylabel('Key and Quantile')\n",
    "plt.title('Heatmap of Average Weighted Avg Scheme Contributions')\n",
    "plt.show()\n",
    "\n",
    "if sim_params['save_scenario_contributions']:\n",
    "    type_score = 'avg_scheme'\n",
    "    scenario = sim_params['scenario']\n",
    "    df_pivot.to_csv(f'/Users/gio/Desktop/Elia-RES-Forecasting/info_model/df_pivot_{scenario}_{type_score}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = weighted_avg_pivot_data(sim_params, avg_weighted_soft_avg_contributions)\n",
    "\n",
    "# # Plot the stacked bar chart\n",
    "df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "plt.xlabel('Key and Quantile')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Stacked Bar Chart of Average Weighted Soft Avg Scheme Contributions')\n",
    "plt.show()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "plt.xlabel('Series')\n",
    "plt.ylabel('Key and Quantile')\n",
    "plt.title('Heatmap of Average Weighted Soft Avg Scheme Contributions')\n",
    "plt.show()\n",
    "\n",
    "if sim_params['save_scenario_contributions']:\n",
    "    type_score = 'avg_scheme'\n",
    "    scenario = sim_params['scenario']\n",
    "    df_pivot.to_csv(f'/Users/gio/Desktop/Elia-RES-Forecasting/info_model/df_pivot_{scenario}_{type_score}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = permutation_pivot_data(sim_params, avg_permutation_contributions)\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "plt.xlabel('Key and Quantile')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Stacked Bar Chart of Average Permutation Contributions')\n",
    "plt.show()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "plt.xlabel('Series')\n",
    "plt.ylabel('Key and Quantile')\n",
    "plt.title('Heatmap of Average Permutation Contributions')\n",
    "plt.show()\n",
    "\n",
    "if sim_params['save_scenario_contributions']:\n",
    "    type_score = 'permutation'\n",
    "    scenario = sim_params['scenario']\n",
    "    df_pivot.to_csv(f'/Users/gio/Desktop/Elia-RES-Forecasting/info_model/df_pivot_{scenario}_{type_score}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = permutation_pivot_data(sim_params, avg_shapley_contributions)\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "plt.xlabel('Key and Quantile')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Stacked Bar Chart of Average Shapley Contributions')\n",
    "plt.show()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "plt.xlabel('Series')\n",
    "plt.ylabel('Key and Quantile')\n",
    "plt.title('Heatmap of Average Shapley Contributions')\n",
    "plt.show()\n",
    "\n",
    "if sim_params['save_scenario_contributions']:\n",
    "    type_score = 'permutation'\n",
    "    scenario = sim_params['scenario']\n",
    "    df_pivot.to_csv(f'/Users/gio/Desktop/Elia-RES-Forecasting/info_model/df_pivot_{scenario}_{type_score}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = lasso_coefs_pivot_data(sim_params, avg_coefficients_contributions)\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "plt.xlabel('Key and Quantile')\n",
    "plt.ylabel('Value')\n",
    "plt.title(\"Stacked Bar Chart of Average Lasso's Coefficients Contributions\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "plt.xlabel('Series')\n",
    "plt.ylabel('Key and Quantile')\n",
    "plt.title(\"Heatmap of Average Lasso's Coefficients Contributions\")\n",
    "plt.show()\n",
    "\n",
    "if sim_params['save_scenario_contributions']:\n",
    "    type_score = 'coefs'\n",
    "    scenario = sim_params['scenario']\n",
    "    df_pivot.to_csv(f'/Users/gio/Desktop/Elia-RES-Forecasting/info_model/df_pivot_{scenario}_{type_score}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_train[['mostrecentforecast', 'dayaheadforecast', 'dayahead11hforecast', 'weekaheadforecast']].corr()\n",
    "correlation_matrix.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_num = np.array([13, 5, 9, 34, 2])\n",
    "print('offline', np.mean(all_num))\n",
    "print('-----------------')\n",
    "for i, a in enumerate(all_num):\n",
    "    n = i+1\n",
    "    if n == 1:\n",
    "        mu = a\n",
    "    else:\n",
    "        mu = mu + (a - mu)/n\n",
    "    print('a:', a, 'n:', n, 'mu:', mu)\n",
    "print('online', mu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
