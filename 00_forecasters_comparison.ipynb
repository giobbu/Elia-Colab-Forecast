{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from source.utils.file_read import read_csv_file, filter_data, join_dataframes, replace_nan_values\n",
    "from source.utils.collect_results import create_df_forecaster_first_stage\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.simulation.submission_module import submission_forecasters\n",
    "from source.simulation.buyer_module import prepare_buyer_data\n",
    "from source.ensemble.combination_scheme.equal_weights import calculate_equal_weights\n",
    "from source.ensemble.combination_scheme.avg_weights import calculate_weighted_avg\n",
    "from source.ensemble.combination_scheme.model_selection import run_model_selection\n",
    "from source.plots.plot_forecasts import plot_forecasts\n",
    "from source.ml_engine import create_ensemble_forecasts\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "from IPython.display import clear_output\n",
    "from source.simulation.helpers_simulation import process_combination_scheme\n",
    "from source.utils.session_ml_info import delete_previous_day_pickle\n",
    "from config.simulation_setting import Simulation, WeightedAvg, Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "sim_params = Simulation.testing_period  # Simulation parameters\n",
    "weight_avg_params = WeightedAvg.params  # Weighted Average parameters\n",
    "ens_params = Stack.params  # QRA Ensemble parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Days:   1%|          | 19/2000 [01:16<2:20:16,  4.25s/it]\u001b[32m2024-12-09 15:18:28.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.generate_timestamp\u001b[0m:\u001b[36mgenerate_timestamps\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.generate_timestamp\u001b[0m:\u001b[36mgenerate_timestamps\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m\u001b[34m-------------------------------------------------------------------------------------------\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.generate_timestamp\u001b[0m:\u001b[36mgenerate_timestamps\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1m\u001b[34mStart training: 2021-01-20 00:00:00+00:00 - End training: 2021-02-19 00:00:00+00:00\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.generate_timestamp\u001b[0m:\u001b[36mgenerate_timestamps\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1m\u001b[34m-------------------------------------------------------------------------------------------\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.generate_timestamp\u001b[0m:\u001b[36mgenerate_timestamps\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1m\u001b[34mStart prediction: 2021-02-20 00:00:00+00:00 - End prediction: 2021-02-21 00:00:00+00:00\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.file_read\u001b[0m:\u001b[36mfilter_data\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\u001b[34m -----------------> Length of training data: 2880 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.file_read\u001b[0m:\u001b[36mfilter_data\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\u001b[34m -----------------> Length of testing data: 96 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.simulation.submission_module\u001b[0m:\u001b[36msubmission_forecasters\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.simulation.submission_module\u001b[0m:\u001b[36msubmission_forecasters\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1m\u001b[34m -----------------> Forecasters prediction submitted \u001b[0m\u001b[1m\u001b[0m\n",
      "/Users/gio/Desktop/Elia-RES-Forecasting/source/simulation/buyer_module.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_buyer = pd.concat([df_train_buyer, df_test_buyer], axis=0)\n",
      "\u001b[32m2024-12-09 15:18:28.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m PREDICO Machine Learning Engine \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Launch Time from 2021-02-19 00:00:00+00:00 \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Predictions from 2021-02-20 00:00:00+00:00 to 2021-02-21 00:00:00+00:00 \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Buyer Resource Name: b1r1 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mbuyer_scaler_statistics\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Mean Buyer: 1270.887173611111 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mbuyer_scaler_statistics\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Std Buyer: 761.9887343548493 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mbuyer_scaler_statistics\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Collecting forecasters prediction for ensemble learning - model: LR \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Forecasters Ensemble DataFrame \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mscale_forecasters_dataframe\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mscale_forecasters_dataframe\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Standardize DataFrame \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Augment DataFrame \u001b[0m\u001b[1m\u001b[0m\n",
      "/Users/gio/Desktop/Elia-RES-Forecasting/source/ensemble/stack_generalization/feature_engineering/data_augmentation.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.bfill(inplace=True)\n",
      "/Users/gio/Desktop/Elia-RES-Forecasting/source/ensemble/stack_generalization/feature_engineering/data_augmentation.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.bfill(inplace=True)\n",
      "/Users/gio/Desktop/Elia-RES-Forecasting/source/ensemble/stack_generalization/data_preparation/data_train_test.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_ensemble.loc[:, 'norm_targ'] = df_train[col_name_buyer].values[max_lag:]\n",
      "/Users/gio/Desktop/Elia-RES-Forecasting/source/ensemble/stack_generalization/data_preparation/data_train_test.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_ensemble.loc[:, 'norm_targ'] = df_test[col_name_buyer].values\n",
      "\u001b[32m2024-12-09 15:18:28.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Train and Test Dataframes \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mLength of Train DataFrame: 2878\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mLength of Test DataFrame: 96\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1mNumber of NaNs in the train ensemble: 0\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1mNumber of NaNs in the test ensemble: 96\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m207\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m208\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Iteration 19 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m211\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m212\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Compute Ensemble Predictions \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ensemble.stack_generalization.ensemble_model\u001b[0m:\u001b[36mpredico_ensemble_predictions_per_quantile\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ensemble.stack_generalization.ensemble_model\u001b[0m:\u001b[36mpredico_ensemble_predictions_per_quantile\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Run ensemble predictions for quantile 0.1 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-12-09 15:18:28.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ensemble.stack_generalization.ensemble_model\u001b[0m:\u001b[36mpredico_ensemble_predictions_per_quantile\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Using best hyperparameters from first iteration \u001b[0m\u001b[1m\u001b[0m\n",
      "Quantile Regression:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Testing Days:   1%|          | 19/2000 [01:17<2:15:08,  4.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m\n\u001b[1;32m     39\u001b[0m     df_buyer, forecast_range \u001b[38;5;241m=\u001b[39m prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     results_ensemble_forecasts \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ensemble_forecasts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mens_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mens_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mdf_buyer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_buyer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mdf_market\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_market\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mend_training_timestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_training_timestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mforecast_range\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecast_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mchallenge_usecase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msimulation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m## ----------------------------> SAVE to CSV <----------------------------\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# wind power\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     df_pred_ensemble \u001b[38;5;241m=\u001b[39m results_ensemble_forecasts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_power\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-Forecasting/source/ml_engine.py:226\u001b[0m, in \u001b[0;36mcreate_ensemble_forecasts\u001b[0;34m(ens_params, df_buyer, df_market, end_training_timestamp, forecast_range, challenge_usecase, simulation)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# # for conformalized quantile regression\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# if ens_params['conformalized_qr']:\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m#     conformalized_qr = {}\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Loop over quantiles\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m quantile \u001b[38;5;129;01min\u001b[39;00m tqdm(ens_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantiles\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantile Regression\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Run ensemble learning\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     results_per_quantile_wp \u001b[38;5;241m=\u001b[39m \u001b[43mpredico_ensemble_predictions_per_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mens_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mens_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_ensemble\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mbest_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mX_train_quantile10\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_quantile10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_quantile10\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_quantile10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mdf_train_ensemble_quantile10\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_ensemble_quantile10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mX_train_quantile90\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_quantile90\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_quantile90\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_quantile90\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mdf_train_ensemble_quantile90\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_ensemble_quantile90\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m results_per_quantile_wp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-Forecasting/source/ensemble/stack_generalization/ensemble_model.py:91\u001b[0m, in \u001b[0;36mpredico_ensemble_predictions_per_quantile\u001b[0;34m(ens_params, X_train, X_test, y_train, df_train_ensemble, predictions, quantile, best_results, iteration, X_train_quantile10, X_test_quantile10, df_train_ensemble_quantile10, X_train_quantile90, X_test_quantile90, df_train_ensemble_quantile90)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Compute p-values for the coefficients\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ens_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Compute p-values for the coefficients\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     coefs, p_values_permutation \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_quantile_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_augmented\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_permutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mens_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnr_pvalues_permutations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# Bonferroni correction\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     is_significant \u001b[38;5;241m=\u001b[39m p_values_permutation \u001b[38;5;241m<\u001b[39m ens_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(coefs)\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-Forecasting/source/ensemble/stack_generalization/hyperparam_optimization/optimization.py:122\u001b[0m, in \u001b[0;36mpermutation_quantile_regression\u001b[0;34m(best_params, solver, X, y, quantile, n_permutations)\u001b[0m\n\u001b[1;32m    120\u001b[0m coefs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Fit the model on the original dataset to get the observed coefficients\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m model_original \u001b[38;5;241m=\u001b[39m \u001b[43mQuantileRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m coefs_original \u001b[38;5;241m=\u001b[39m model_original\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_permutations):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Permute y (random shuffle)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/predico-research/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/predico-research/lib/python3.9/site-packages/sklearn/linear_model/_quantile.py:271\u001b[0m, in \u001b[0;36mQuantileRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    267\u001b[0m         A_eq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X, \u001b[38;5;241m-\u001b[39mX, eye, \u001b[38;5;241m-\u001b[39meye], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    269\u001b[0m b_eq \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m--> 271\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlinprog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mA_eq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA_eq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mb_eq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_eq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m solution \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/predico-research/lib/python3.9/site-packages/scipy/optimize/_linprog.py:641\u001b[0m, in \u001b[0;36mlinprog\u001b[0;34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0, integrality)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHiGHS solvers do not support the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback interface.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    638\u001b[0m highs_solvers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighs-ipm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighs-ds\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimplex\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    639\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 641\u001b[0m sol \u001b[38;5;241m=\u001b[39m \u001b[43m_linprog_highs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhighs_solvers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msolver_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m], sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    644\u001b[0m     _check_result(sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m], sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m], sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslack\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    645\u001b[0m                   sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcon\u001b[39m\u001b[38;5;124m'\u001b[39m], lp\u001b[38;5;241m.\u001b[39mbounds, tol, sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    646\u001b[0m                   integrality))\n\u001b[1;32m    647\u001b[0m sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/predico-research/lib/python3.9/site-packages/scipy/optimize/_linprog_highs.py:373\u001b[0m, in \u001b[0;36m_linprog_highs\u001b[0;34m(lp, solver, time_limit, presolve, disp, maxiter, dual_feasibility_tolerance, primal_feasibility_tolerance, ipm_optimality_tolerance, simplex_dual_edge_weight_strategy, mip_rel_gap, mip_max_nodes, **unknown_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     integrality \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(integrality)\n\u001b[0;32m--> 373\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_highs_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# HiGHS represents constraints as lhs/rhs, so\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Ax + s = b => Ax = b - s\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# and we need to split up s by A_ub and A_eq\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslack\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set random seed\n",
    "np.random.seed(sim_params['random_seed'])\n",
    "\n",
    "# read csv file\n",
    "df_processed = read_csv_file(sim_params['csv_filename'], sim_params['list_columns'], sim_params['starting_period'], sim_params['ending_period'])\n",
    "\n",
    "# replace NaN values\n",
    "if sim_params['replace_nan']:\n",
    "    df_processed = replace_nan_values(sim_params, df_processed)\n",
    "\n",
    "# remove previous day pickle file\n",
    "logger.info(' ')\n",
    "delete_previous_day_pickle()\n",
    "logger.opt(colors = True).warning('previous day pickle file removed')\n",
    "\n",
    "# save csv variables\n",
    "list_csv_to_save = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    if i >= ens_params['day_calibration'] and ens_params['conformalized_qr']:\n",
    "        day_calibration = ens_params['day_calibration']\n",
    "        start_training_timestamp = start_training_timestamp - pd.Timedelta(f'{day_calibration}day')\n",
    "\n",
    "    # trimming data for training and testing\n",
    "    df_train = filter_data(df_processed, start_training_timestamp, end_training_timestamp, string = 'training')\n",
    "    df_test = filter_data(df_processed, start_prediction_timestamp, end_prediction_timestamp, string = 'testing')\n",
    "\n",
    "# # ----------------------------> FORECASTERS SUBMISSION <----------------------------\n",
    "\n",
    "    df_market, df_train, df_test = submission_forecasters(sim_params, df_train, df_test)   \n",
    "\n",
    "# # ----------------------------> MARKET OPERATOR DATA <----------------------------\n",
    "\n",
    "    df_buyer, forecast_range = prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "\n",
    "# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\n",
    "\n",
    "    results_ensemble_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                                            df_buyer=df_buyer, \n",
    "                                                            df_market=df_market,\n",
    "                                                            end_training_timestamp=end_training_timestamp,\n",
    "                                                            forecast_range = forecast_range,\n",
    "                                                            challenge_usecase='simulation',\n",
    "                                                            simulation=True)\n",
    "    \n",
    "    ## ----------------------------> SAVE to CSV <----------------------------\n",
    "    # wind power\n",
    "    df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']\n",
    "    df_pred_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_predictions', \n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_predictions', \n",
    "                                        'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "    # create dataframes\n",
    "    df_test_ensemble = pd.DataFrame(df_test['measured']) \n",
    "    df_test_ensemble.rename(columns={'measured': 'targets'}, inplace=True)\n",
    "    \n",
    "    # drop targets column\n",
    "    df_pred_ensemble_clean = df_pred_ensemble.drop(columns=['targets'], axis=1)\n",
    "\n",
    "    # list dataframes wind power\n",
    "    list_df_wind_power = [df_test, df_pred_ensemble_clean]\n",
    "\n",
    "    if sim_params['baselines_comparison']:\n",
    "\n",
    "        # # # ----------------------------> COMBINATION SCHEME DATA <----------------------------\n",
    "\n",
    "        # process data for baselines combination schemes\n",
    "        df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var = process_combination_scheme(df_train, df_test, end_training_timestamp, start_prediction_timestamp)\n",
    "        \n",
    "        # # ----------------------------> PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        ## ----------------------------> WIND POWER <----------------------------\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model = run_model_selection(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_best_model_clean = df_best_model.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_best_model_clean)\n",
    "        \n",
    "        # performance weighted average\n",
    "        df_weighted_avg, dict_weights = calculate_weighted_avg(sim_params, \n",
    "                                                            df_train_norm, \n",
    "                                                            day_previous_df_test_norm, \n",
    "                                                            end_training_timestamp, \n",
    "                                                            start_prediction_timestamp, \n",
    "                                                            window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_weighted_avg_clean = df_weighted_avg.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_weighted_avg_clean)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft, dict_weights_soft = calculate_weighted_avg(sim_params, \n",
    "                                                                        df_train_norm, \n",
    "                                                                        day_previous_df_test_norm, \n",
    "                                                                        end_training_timestamp, \n",
    "                                                                        start_prediction_timestamp, \n",
    "                                                                        window_size_valid=weight_avg_params['window_size_valid'], \n",
    "                                                                        norm='softmax')\n",
    "        df_weighted_avg_soft_clean = df_weighted_avg_soft.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_weighted_avg_soft_clean)\n",
    "        \n",
    "        # performance equal weights\n",
    "        df_equal_weights = calculate_equal_weights(day_previous_df_test_norm, start_prediction_timestamp)\n",
    "        df_equal_weights_clean = df_equal_weights.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_equal_weights_clean)\n",
    "\n",
    "        # performance malicious cheat\n",
    "        if sim_params['malicious']:\n",
    "            df_malicious = create_df_forecaster_first_stage(day_previous_df_test_norm, 'malicious', start_prediction_timestamp)\n",
    "            list_df_wind_power.append(df_malicious)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            df_noisy = create_df_forecaster_first_stage(day_previous_df_test_norm, 'noisy', start_prediction_timestamp)\n",
    "            list_df_wind_power.append(df_noisy)\n",
    "\n",
    "        # plot forecasts\n",
    "        if ens_params['plt_wind_power_ensemble']:\n",
    "            plot_forecasts(df_pred_ensemble, df_test_ensemble, list_wind_ramps=[], title=f'Wind Power Forecasting')\n",
    "\n",
    "    # join dataframes wind power forecasters baseline\n",
    "    df_csv_wind_power = join_dataframes(*list_df_wind_power)\n",
    "    list_csv_to_save.append(df_csv_wind_power)\n",
    "\n",
    "    #Clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # import time\n",
    "    # time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_wind_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------> SAVE TO CSV <----------------------------\n",
    "# from list to dataframe\n",
    "df_csv = pd.concat(list_csv_to_save).to_csv('wp_forecasters_comparison_results_no_mostrecent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------> PLOT FORECASTS <----------------------------\n",
    "df_csv[['measured', '10_predictions', '50_predictions', '90_predictions']].iloc[:2000].plot(figsize=(20,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predico-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
