{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(sys.path[0]))\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import QuantileRegressor, LinearRegression\n",
    "from sklearn.metrics import mean_pinball_loss, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "from tqdm import tqdm\n",
    "from sklearn.inspection import permutation_importance\n",
    "import scikit_posthocs as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger_format = (\n",
    "#     \"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \"\n",
    "#     \"<level>{level: <8}</level> | \"\n",
    "#     \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | \"\n",
    "#     \"{extra[ip]} {extra[user]} - <level>{message}</level>\"\n",
    "# )\n",
    "# logger.configure(extra={\"ip\": \"\", \"user\": \"\"})  # Default values\n",
    "# logger.remove()\n",
    "# logger.add(sys.stderr, format=logger_format)\n",
    "\n",
    "# logger.add(sys.stderr, format=logger_format, level=\"TRACE\")\n",
    "\n",
    "# from loguru import logger\n",
    "# logger.add(\n",
    "#     'info.log',\n",
    "#     format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {module}:{function}:{line} - {message}\",\n",
    "#     level=\"INFO\",\n",
    "# )\n",
    "# def main():\n",
    "#     logger.debug(\"This is a debug message\")\n",
    "#     logger.info(\"This is an info message\")\n",
    "#     logger.warning(\"This is a warning message\")\n",
    "#     logger.error(\"This is an error message\")\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### UTILS FILE \n",
    "def filter_offshore(df, offshore_filter):\n",
    "    df = df[df.offshoreonshore == offshore_filter]  # filter by offshore/onshore\n",
    "    return df\n",
    "\n",
    "def set_index_datetiemUTC(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], utc=True)\n",
    "    df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_file(file, offshore_filter='Offshore'):\n",
    "    df = pd.read_json(file)\n",
    "    df = filter_offshore(df, offshore_filter)\n",
    "    df = set_index_datetiemUTC(df)\n",
    "    df[df['measured'] < 0] = 0\n",
    "    return df\n",
    "\n",
    "########################### UTILS DATA PROCESSING   \n",
    "def scale(df, col_name, max_cap):\n",
    "    df_ = df.copy()\n",
    "    values = df_[col_name].values\n",
    "    return values/max_cap\n",
    "\n",
    "def detect_ramp_event(df, ramp_threshold):\n",
    "    df['ramp_event'] = (np.abs(df['diff_norm_measured']) > ramp_threshold).astype(int)\n",
    "    df['ramp_event_up'] = (df['diff_norm_measured'] > ramp_threshold).astype(int)\n",
    "    df['ramp_event_down'] = (df['diff_norm_measured'] < -ramp_threshold).astype(int)\n",
    "    return df\n",
    "\n",
    "############################# UTILS PREDICTIONS\n",
    "def dict2df_predictions(prediction, col_name):\n",
    "    df_pred = pd.DataFrame.from_records(prediction)\n",
    "    df_pred.set_index('datetime', inplace=True)\n",
    "    df_pred.columns = [col_name + '_pred']\n",
    "    return df_pred\n",
    "\n",
    "def dict2df_quantiles10(prediction, col_name):\n",
    "    df_pred = pd.DataFrame.from_records(prediction)\n",
    "    df_pred.set_index('datetime', inplace=True)\n",
    "    df_pred.columns = [col_name + '_quantile10']\n",
    "    return df_pred\n",
    "\n",
    "def dict2df_quantiles90(prediction, col_name):\n",
    "    df_pred = pd.DataFrame.from_records(prediction)\n",
    "    df_pred.set_index('datetime', inplace=True)\n",
    "    df_pred.columns = [col_name + '_quantile90']\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timestamps(start_training, i, window_size):\n",
    "    # Generate timestamps for training and prediction\n",
    "    assert window_size > 0, \"Window size must be greater than 0\"\n",
    "    start_training_timestamp = pd.to_datetime(start_training, utc=True) + pd.Timedelta(days=i)\n",
    "    end_training_timestamp = pd.to_datetime(start_training, utc=True) + pd.Timedelta(days=i + window_size)\n",
    "    start_prediction_timestamp = pd.to_datetime(start_training, utc=True) + pd.Timedelta(days=i + window_size)\n",
    "    end_prediction_timestamp = pd.to_datetime(start_training, utc=True) + pd.Timedelta(days=i + window_size + 1)\n",
    "    return start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day ahead\n",
    "def create_day_ahead_predictions(df_val):\n",
    "    \" Create day ahead predictions \"\n",
    "    day_ahead_elia_prediction = []\n",
    "    for i in range(len(df_val)):\n",
    "        day_ahead_elia_prediction.append({'datetime': df_val.index[i],\n",
    "                                            'predictions': df_val.dayaheadforecast.iloc[i]})\n",
    "    df_day_ahead_pred = dict2df_predictions(day_ahead_elia_prediction, 'day_ahead')\n",
    "    return df_day_ahead_pred\n",
    "\n",
    "# day ahead 11\n",
    "def create_day_ahead_11_predictions(df_val):\n",
    "    \" Create day ahead 11 predictions\"\n",
    "    day_ahead_11_elia_prediction = []\n",
    "    for i in range(len(df_val)):\n",
    "        day_ahead_11_elia_prediction.append({'datetime': df_val.index[i],\n",
    "                                                'predictions': df_val.dayahead11hforecast.iloc[i]})\n",
    "    df_day_ahead11_pred = dict2df_predictions(day_ahead_11_elia_prediction, 'day_ahead11')\n",
    "    return df_day_ahead11_pred\n",
    "\n",
    "# week ahead\n",
    "def create_week_ahead_predictions(df_val):\n",
    "    \" Create week ahead predictions\"\n",
    "    week_ahead_elia_prediction = []\n",
    "    for i in range(len(df_val)):\n",
    "        week_ahead_elia_prediction.append({'datetime': df_val.index[i],\n",
    "                                            'predictions': df_val.weekaheadforecast.iloc[i]})\n",
    "    df_week_ahead_pred = dict2df_predictions(week_ahead_elia_prediction, 'week_ahead')\n",
    "    return df_week_ahead_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day ahead\n",
    "def create_day_ahead_quantiles10(df_val):\n",
    "    \" Create day ahead quantiles 10\"\n",
    "    day_ahead_elia_quantile10 = []\n",
    "    for i in range(len(df_val)):\n",
    "        day_ahead_elia_quantile10.append({'datetime': df_val.index[i],\n",
    "                                            'quantiles10': df_val.dayaheadconfidence10.iloc[i]})\n",
    "    df_day_ahead_quantile10 = dict2df_quantiles10(day_ahead_elia_quantile10, 'day_ahead')\n",
    "    return df_day_ahead_quantile10\n",
    "\n",
    "# day ahead 11\n",
    "def create_day_ahead_11_quantiles10(df_val):\n",
    "    \" Create day ahead 11 quantiles 10\"\n",
    "    day_ahead_11_elia_quantile10 = []\n",
    "    for i in range(len(df_val)):\n",
    "        day_ahead_11_elia_quantile10.append({'datetime': df_val.index[i],\n",
    "                                                'quantiles10': df_val.dayahead11hconfidence10.iloc[i]})\n",
    "    df_day_ahead11_quantile10 = dict2df_quantiles10(day_ahead_11_elia_quantile10, 'day_ahead11')\n",
    "    return df_day_ahead11_quantile10\n",
    "\n",
    "# week ahead\n",
    "def create_week_ahead_quantiles10(df_val):\n",
    "    \" Create week ahead quantiles 10\"\n",
    "    week_ahead_elia_quantile10 = []\n",
    "    for i in range(len(df_val)):\n",
    "        week_ahead_elia_quantile10.append({'datetime': df_val.index[i],\n",
    "                                            'quantiles10': df_val.weekaheadconfidence10.iloc[i]})\n",
    "    df_week_ahead_quantile10 = dict2df_quantiles10(week_ahead_elia_quantile10, 'week_ahead')\n",
    "    return df_week_ahead_quantile10\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# day ahead\n",
    "def create_day_ahead_quantiles90(df_val):\n",
    "    \" Create day ahead quantiles 90\"\n",
    "    day_ahead_elia_quantile90 = []\n",
    "    for i in range(len(df_val)):\n",
    "        day_ahead_elia_quantile90.append({'datetime': df_val.index[i],\n",
    "                                            'quantiles90': df_val.dayaheadconfidence90.iloc[i]})\n",
    "    df_day_ahead_quantile90 = dict2df_quantiles90(day_ahead_elia_quantile90, 'day_ahead')\n",
    "    return df_day_ahead_quantile90\n",
    "\n",
    "# day ahead 11\n",
    "def create_day_ahead_11_quantiles90(df_val):\n",
    "    \" Create day ahead 11 quantiles 90\"\n",
    "    day_ahead_11_elia_quantile90 = []\n",
    "    for i in range(len(df_val)):\n",
    "        day_ahead_11_elia_quantile90.append({'datetime': df_val.index[i],\n",
    "                                                'quantiles90': df_val.dayahead11hconfidence90.iloc[i]})\n",
    "    df_day_ahead11_quantile90 = dict2df_quantiles90(day_ahead_11_elia_quantile90, 'day_ahead11')\n",
    "    return df_day_ahead11_quantile90\n",
    "\n",
    "# week ahead\n",
    "def create_week_ahead_quantiles90(df_val):\n",
    "    \" Create week ahead quantiles 90\"\n",
    "    week_ahead_elia_quantile90 = []\n",
    "    for i in range(len(df_val)):\n",
    "        week_ahead_elia_quantile90.append({'datetime': df_val.index[i],\n",
    "                                            'quantiles90': df_val.weekaheadconfidence90.iloc[i]})\n",
    "    df_week_ahead_quantile90 = dict2df_quantiles90(week_ahead_elia_quantile90, 'week_ahead')\n",
    "    return df_week_ahead_quantile90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stacked Generalization (Quantile Regressor/ Quantile GB Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df, maximum_capacity):\n",
    "    \" Normalize dataframe by dividing by maximum capacity\"\n",
    "    assert maximum_capacity > 0, \"Maximum capacity must be greater than 0\"\n",
    "    df_normalized = df.copy()\n",
    "    for col in df_normalized.columns:\n",
    "        normalize_col = scale(df_normalized, col, maximum_capacity)\n",
    "        df_normalized[f'norm_{col}'] = normalize_col\n",
    "    return df_normalized.filter(like='norm')\n",
    "\n",
    "def differentiate_dataframe(df):\n",
    "    \" Differentiate dataframe by computing the absolute difference between consecutive values\"\n",
    "    df_differential = df.copy()\n",
    "    for col in df_differential.columns:\n",
    "        df_differential[f'diff_{col}'] = df_differential[col].diff()\n",
    "    return df_differential.filter(like='diff').iloc[1:]\n",
    "\n",
    "def create_augmented_dataframe(df, max_lags, forecasters_diversity=True, lagged=True, augmented=True, differenciate=True):\n",
    "    \" Create feature engineering dataframe with forecasters diversity, lagged, augmented and differenciate features\"\n",
    "    shifted_df_ensemble = pd.DataFrame()\n",
    "\n",
    "    if lagged:\n",
    "        \" Create lagged features\"\n",
    "        for lag in range(1, max_lags + 1):\n",
    "            for col in df.columns:\n",
    "                shifted_df_ensemble[col+'_t-'+str(lag)] = df[col].shift(lag)  # lagged\n",
    "    if augmented:\n",
    "        \" Create augmented features\"\n",
    "        for col in df.columns:\n",
    "            shifted_df_ensemble[col + \"_sqr\"] = df[col]**2  # squared\n",
    "            shifted_df_ensemble[col + \"_std\"] = df[col].rolling(max_lags).std()  # rolling standard deviation\n",
    "            shifted_df_ensemble[col + \"_var\"] = df[col].rolling(max_lags).var()  # rolling variance\n",
    "            if max_lags > 2:\n",
    "                shifted_df_ensemble[col + \"_lag-1_std\"] = df[col].shift(1).rolling(max_lags-1).std()  # rolling standard deviation on lag-1\n",
    "                shifted_df_ensemble[col + \"_lag-1_var\"] = df[col].shift(1).rolling(max_lags-1).var()  # rolling variance on lag-1\n",
    "    if differenciate:\n",
    "        \" Create differenciate features\"\n",
    "        for col in df.columns:\n",
    "            shifted_df_ensemble[col + \"_diff\"] = df[col].diff()  # difference\n",
    "            shifted_df_ensemble[col + \"_lag-1_diff\"] = df[col].shift(1).diff()  # difference on lag-1\n",
    "    if forecasters_diversity:\n",
    "        \" Create forecasters diversity features\"\n",
    "        forecast_cols = [name for name in df.columns if 'pred' in name]  # forecasters columns\n",
    "        shifted_df_ensemble[\"forecasters_std\"] = df[forecast_cols].std(axis=1)  # standard deviation among forecasters\n",
    "        shifted_df_ensemble[\"forecasters_var\"] = df[forecast_cols].var(axis=1)  # variance among forecasters\n",
    "    \" Concatenate the original dataframe with the shifted dataframe\"\n",
    "    df = pd.concat([df, shifted_df_ensemble], axis=1)\n",
    "    df = df.iloc[max_lags:,:]\n",
    "    return df\n",
    "\n",
    "def prepare_train_test_data(df_ensemble, df_val, df_test, start_predictions):\n",
    "    df_train_ensemble = df_ensemble[df_ensemble.index < start_predictions].copy()\n",
    "    df_train_ensemble.loc[:, 'diff_norm_targ'] = df_val['diff_norm_measured']\n",
    "    df_test_ensemble = df_ensemble[df_ensemble.index >= start_predictions].copy()\n",
    "    df_test_ensemble.loc[:, 'diff_norm_targ'] = df_test['diff_norm_measured']\n",
    "    return df_train_ensemble, df_test_ensemble\n",
    "\n",
    "def get_numpy_Xy_train_test(df_train_ensemble, df_test_ensemble):\n",
    "    X_train, y_train = df_train_ensemble.iloc[:, :-1].values, df_train_ensemble.iloc[:, -1].values\n",
    "    X_test, y_test = df_test_ensemble.iloc[:, :-1].values, df_test_ensemble.iloc[:, -1].values\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def augment_with_quantiles(X_train, X_test, df_train_ensemble, \n",
    "                            X_train_quantile10, X_test_quantile10, df_train_ensemble_quantile10,\n",
    "                            X_train_quantile90, X_test_quantile90, df_train_ensemble_quantile90,  \n",
    "                            quantile, augment_q50=False):\n",
    "    \" Augment the training and testing data with the quantiles predictions\"\n",
    "    quantile_data = {\n",
    "        0.1: (X_train_quantile10, X_test_quantile10, df_train_ensemble_quantile10),\n",
    "        0.5: (np.concatenate([X_train_quantile10, X_train_quantile90], axis=1),\n",
    "                np.concatenate([X_test_quantile10, X_test_quantile90], axis=1),\n",
    "                pd.concat([df_train_ensemble_quantile10, df_train_ensemble_quantile90], axis=1)),\n",
    "        0.9: (X_train_quantile90, X_test_quantile90, df_train_ensemble_quantile90)\n",
    "    }\n",
    "    if quantile not in quantile_data:\n",
    "        raise ValueError('Invalid quantile value. Must be 0.1, 0.5, or 0.9.')\n",
    "    \" Get the quantile data and augment the training and testing data with it\"\n",
    "    X_train_part, X_test_part, df_train_ensemble_part = quantile_data[quantile]\n",
    "    if quantile == 0.5 and not augment_q50:\n",
    "        \" Do not augment with augmented quantiles\"\n",
    "        return X_train, X_test, df_train_ensemble\n",
    "    X_train = np.concatenate([X_train, X_train_part], axis=1)\n",
    "    X_test = np.concatenate([X_test, X_test_part], axis=1)\n",
    "    df_train_ensemble = pd.concat([df_train_ensemble, df_train_ensemble_part], axis=1)\n",
    "    return X_train, X_test, df_train_ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparms QR Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Evaluate model using Pnball loss.\"\n",
    "def score_func_10(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return {\n",
    "        \"mean_pinball_loss\": mean_pinball_loss(y, y_pred, alpha=0.1),\n",
    "    }\n",
    "def score_func_50(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return {\n",
    "        \"mean_pinball_loss\": mean_squared_error(y, y_pred), # mean_pinball_loss(y, y_pred, alpha=0.5),\n",
    "    }\n",
    "def score_func_90(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return {\n",
    "        \"mean_pinball_loss\": mean_pinball_loss(y, y_pred, alpha=0.9),\n",
    "    }\n",
    "\n",
    "score_func = {0.1: score_func_10,\n",
    "                0.5: score_func_50,\n",
    "                0.9: score_func_90}\n",
    "\n",
    "def evaluate(model, X, y, cv, quantile, score_func):\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=score_func[quantile],\n",
    "        n_jobs=6\n",
    "    )\n",
    "    score_mean = cv_results['test_mean_pinball_loss'].mean()\n",
    "    return score_mean\n",
    "\n",
    "def optimize_gbr(X_train, y_train, quantile, nr_cv_splits, config_params, score_func):\n",
    "    \" Hyperparameter optimization for Quantile Gradient Boosting Regressor.\"\n",
    "    best_gbr_params = None\n",
    "    best_score=100000\n",
    "    ts_cv = TimeSeriesSplit(n_splits=nr_cv_splits)\n",
    "    for learning_rate in config_params['learning_rate']:\n",
    "        for subsample in config_params['max_features']:\n",
    "            for max_depth in config_params['max_depth']:\n",
    "                for n_estimators in config_params['max_iter']:\n",
    "                    gbr_params = dict(\n",
    "                        learning_rate=learning_rate,\n",
    "                        max_features = subsample,\n",
    "                        max_iter=n_estimators,\n",
    "                        max_depth=max_depth,\n",
    "                        random_state=42)\n",
    "                    if quantile == 0.5:\n",
    "                        gbr = HistGradientBoostingRegressor(**gbr_params)\n",
    "                    else:\n",
    "                        gbr = HistGradientBoostingRegressor(loss=\"quantile\", quantile=quantile, **gbr_params)\n",
    "                    mean_cv_score = evaluate(gbr, X_train, y_train, cv=ts_cv, quantile=quantile, score_func=score_func) \n",
    "                    if mean_cv_score < best_score:\n",
    "                        best_score = mean_cv_score\n",
    "                        best_gbr_params = gbr_params\n",
    "    return best_score, best_gbr_params\n",
    "\n",
    "def optimize_lr(X_train, y_train, quantile, nr_cv_splits, solver, config_params, score_func):\n",
    "    \" Hyperparameter optimization for Quantile Linear Regression. \"\n",
    "    best_lr_params = None\n",
    "    best_score=100000\n",
    "    ts_cv = TimeSeriesSplit(n_splits=nr_cv_splits)\n",
    "    for alpha in config_params['alpha']:\n",
    "        for fit_intercept in config_params['fit_intercept']:\n",
    "            if quantile == 0.5:\n",
    "                lr_params = dict(\n",
    "                fit_intercept=fit_intercept)\n",
    "                lr = LinearRegression(**lr_params)\n",
    "            else:\n",
    "                lr_params = dict(\n",
    "                alpha=alpha,\n",
    "                fit_intercept=fit_intercept)\n",
    "                lr = QuantileRegressor(quantile=quantile, solver=solver, **lr_params)\n",
    "            mean_cv_score = evaluate(lr, X_train, y_train, cv=ts_cv, quantile=quantile, score_func=score_func)  \n",
    "            if mean_cv_score < best_score:\n",
    "                best_score = mean_cv_score\n",
    "                best_lr_params = lr_params\n",
    "    return best_score, best_lr_params\n",
    "\n",
    "def optimize_model(X_train, y_train, quantile, nr_cv_splits, model_type, solver, gbr_config_params, lr_config_params, score_func, logger):\n",
    "    \" Optimize selected model hyperparameters.\"\n",
    "    if model_type == 'GBR':\n",
    "        best_score, best_params = optimize_gbr(X_train, y_train, quantile, nr_cv_splits, gbr_config_params, score_func)\n",
    "    elif model_type == 'LR':\n",
    "        best_score, best_params = optimize_lr(X_train, y_train, quantile, nr_cv_splits, solver, lr_config_params, score_func)\n",
    "    else:\n",
    "        raise ValueError('\"model_type\" is not valid')\n",
    "    logger.info(f'best_score {round(best_score, 3)}')\n",
    "    logger.info(f'best_params {best_params}')\n",
    "    return best_score, best_params\n",
    "\n",
    "def initialize_model(model_type, quantile, best_params):\n",
    "    \" Initialize selected model.\"\n",
    "    assert best_params is not None, \"Best parameters must be provided\"\n",
    "    if model_type == 'GBR':\n",
    "        if quantile == 0.5:\n",
    "            model = HistGradientBoostingRegressor(**best_params)\n",
    "        else:\n",
    "            model = HistGradientBoostingRegressor(loss=\"quantile\", quantile=quantile, **best_params)\n",
    "    elif model_type == 'LR':\n",
    "        if quantile == 0.5:\n",
    "            model = LinearRegression(**best_params)\n",
    "        else:\n",
    "            model = QuantileRegressor(quantile=quantile, solver=solver, **best_params)\n",
    "    else:\n",
    "        raise ValueError('\"model_type\" is not valid')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_quantile_ensemble_predictions(quantiles, test_data, predictions):\n",
    "    \" Collect quantile ensemble predictions as a list of dictionaries.\"\n",
    "    assert test_data.shape[0] == len(predictions[quantiles[0]]), \"Length mismatch between test data and predictions\"    \n",
    "    quantile_predictions_dict = {}\n",
    "    try:\n",
    "        for quantile in quantiles:\n",
    "            quantile_ensemble_predictions = []\n",
    "            if test_data.shape[0] != len(predictions[quantile]):\n",
    "                raise ValueError(\"Length mismatch between test data and predictions for quantile {}\".format(quantile))\n",
    "            for i in range(len(predictions[quantile])):\n",
    "                quantile_ensemble_predictions.append({'datetime': test_data.index[i],\n",
    "                                                        'predictions': predictions[quantile][i]})\n",
    "            quantile_predictions_dict[quantile] = quantile_ensemble_predictions\n",
    "    except Exception as e:\n",
    "        logger.exception(\"An error occurred:\", e)\n",
    "        return None\n",
    "    return quantile_predictions_dict\n",
    "\n",
    "def create_ensemble_dataframe(quantiles, quantile_predictions_dict, df_test):\n",
    "    \" Create ensemble dataframe from quantile predictions.\"\n",
    "    assert len(quantiles) == len(quantile_predictions_dict), \"Length mismatch between quantiles and quantile predictions\"\n",
    "    assert df_test.shape[0] == len(quantile_predictions_dict[quantiles[0]]), \"Length mismatch between test data and predictions\"\n",
    "    assert 'diff_norm_measured' in df_test.columns, 'diff_norm_measured column not found in test data'\n",
    "    for i, quantile in enumerate(quantiles):\n",
    "        if i == 0:\n",
    "            df_pred_ensemble = pd.DataFrame(quantile_predictions_dict[quantile])\n",
    "            df_pred_ensemble.columns = ['datetime', str(int(quantile*100))+'_predictions']\n",
    "            df_pred_ensemble.set_index('datetime', inplace=True)\n",
    "        else:\n",
    "            df_pred_quantile = pd.DataFrame(quantile_predictions_dict[quantile])\n",
    "            df_pred_quantile.columns = ['datetime', str(int(quantile*100))+'_predictions']\n",
    "            df_pred_quantile.set_index('datetime', inplace=True)\n",
    "            df_pred_ensemble = pd.concat([df_pred_ensemble, df_pred_quantile], axis=1)\n",
    "    df_pred_ensemble['diff_norm_measured'] = df_test['diff_norm_measured']\n",
    "    return df_pred_ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-stage dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_dataframe_2stage(df_2stage, order_diff, max_lags, augment=False):\n",
    "    \" Process 2-stage ensemble dataframe with lags.\"\n",
    "    assert order_diff > 0, \"Order of differentiation must be greater than 0\"\n",
    "    assert max_lags > 0, \"Maximum number of lags must be greater than 0\"\n",
    "    # Differentiate the dataframe\n",
    "    df_2stage_diff = df_2stage.diff(order_diff)\n",
    "    # Create lagged features\n",
    "    for lag in range(1, max_lags + 1):\n",
    "        df_2stage_diff[f'predictions_t-{lag}'] = df_2stage_diff['predictions'].shift(lag)\n",
    "    if augment:\n",
    "        for col in df_2stage_diff.columns:\n",
    "            if 'targets' not in col:\n",
    "                df_2stage_diff[f'{col}_sqr'] = df_2stage_diff[col]**2\n",
    "    # Drop rows with NaNs resulting from the shift operation\n",
    "    df_2stage_process = df_2stage_diff.iloc[max_lags:, :].dropna()\n",
    "    return df_2stage_process\n",
    "\n",
    "def create_2stage_dataframe(df_train_ensemble, df_test_ensemble, y_train, y_test, predictions_insample, predictions_outsample):\n",
    "    \" Create 2-stage ensemble dataframe.\"\n",
    "    # Creating DataFrame for in-sample predictions\n",
    "    df_insample = pd.DataFrame(predictions_insample, columns=['predictions'], index=df_train_ensemble.index)\n",
    "    df_insample['targets'] = y_train\n",
    "    # Creating DataFrame for out-sample predictions\n",
    "    df_outsample = pd.DataFrame(predictions_outsample, columns=['predictions'], index=df_test_ensemble.index)\n",
    "    df_outsample['targets'] = y_test\n",
    "    # Concatenating in-sample and out-sample DataFrames\n",
    "    df_2stage = pd.concat([df_insample, df_outsample], axis=0)\n",
    "    return df_2stage\n",
    "\n",
    "def create_var_ensemble_dataframe(quantiles, quantile_predictions_dict, df_test):\n",
    "    \" Create ensemble dataframe from quantile predictions.\"\n",
    "    assert len(quantiles) == len(quantile_predictions_dict), \"Length mismatch between quantiles and quantile predictions\"\n",
    "    assert df_test.shape[0] == len(quantile_predictions_dict[quantiles[0]]), \"Length mismatch between test data and predictions\"\n",
    "    for i, quantile in enumerate(quantiles):\n",
    "        if i == 0:\n",
    "            df_pred_ensemble = pd.DataFrame(quantile_predictions_dict[quantile])\n",
    "            df_pred_ensemble.columns = ['datetime', str(int(quantile*100))+'_var_predictions']\n",
    "            df_pred_ensemble.set_index('datetime', inplace=True)\n",
    "        else:\n",
    "            df_pred_quantile = pd.DataFrame(quantile_predictions_dict[quantile])\n",
    "            df_pred_quantile.columns = ['datetime', str(int(quantile*100))+'_var_predictions']\n",
    "            df_pred_quantile.set_index('datetime', inplace=True)\n",
    "            df_pred_ensemble = pd.concat([df_pred_ensemble, df_pred_quantile], axis=1)\n",
    "    df_pred_ensemble['targets'] = df_test['targets']\n",
    "    return df_pred_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_targ):\n",
    "    \" Compute Root Mean Squared Error.\"\n",
    "    assert len(y_pred) == len(y_targ), \"Length mismatch between predictions and targets\"\n",
    "    return np.sqrt(np.mean((y_pred - y_targ)**2))\n",
    "\n",
    "def calculate_rmse(df, pred_col, targ_col='diff_norm_measured'):\n",
    "    \" Calculate RMSE Loss.\"\n",
    "    assert pred_col in df.columns, \"prediction column is missing\"\n",
    "    assert targ_col in df.columns, \"target column is missing\"\n",
    "    rmse_loss = pd.DataFrame()\n",
    "    rmse_loss['rmse'] = np.array([rmse(df[pred_col], df[targ_col])])\n",
    "    return rmse_loss\n",
    "\n",
    "def calculate_pinball_losses(df, confidence_10_col, confidence_90_col, targ_col='diff_norm_measured'):\n",
    "    \" Calculate Pinball Losses for 10% and 90% quantiles.\"\n",
    "    assert 'diff_norm_measured' in df.columns, \"diff_norm_measured column is missing\"\n",
    "    pinball_losses = pd.DataFrame()\n",
    "    score_10 = mean_pinball_loss( list(df[targ_col].values),  list(df[confidence_10_col].values), alpha=0.1)\n",
    "    score_90 = mean_pinball_loss( list(df[targ_col].values),  list(df[confidence_90_col].values), alpha=0.9)\n",
    "    pinball_losses['pb_loss_10'] =  np.array([score_10]) \n",
    "    pinball_losses['pb_loss_90'] = np.array([score_90]) \n",
    "    return pinball_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scheme equal weights ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_equal_weights(df_test_norm_diff):\n",
    "    \" Calculate the mean prediction and quantiles using equal weights\"\n",
    "    assert 'diff_norm_measured' in df_test_norm_diff.columns, \"diff_norm_measured column is missing\"\n",
    "    Q10 = df_test_norm_diff[['diff_norm_weekaheadconfidence10', \n",
    "                                'diff_norm_dayaheadconfidence10', \n",
    "                                'diff_norm_dayahead11hconfidence10']].mean(axis=1)\n",
    "    MEAN = df_test_norm_diff[['diff_norm_weekaheadforecast', \n",
    "                                'diff_norm_dayaheadforecast', \n",
    "                                'diff_norm_dayahead11hforecast']].mean(axis=1)\n",
    "    Q90 = df_test_norm_diff[['diff_norm_weekaheadconfidence90', \n",
    "                                'diff_norm_dayaheadconfidence90', \n",
    "                                'diff_norm_dayahead11hconfidence90']].mean(axis=1)\n",
    "    df_equal_weights = pd.DataFrame({\n",
    "        'Q10': Q10,\n",
    "        'mean_prediction': MEAN,\n",
    "        'Q90': Q90\n",
    "    }, index=df_test_norm_diff.index)\n",
    "    df_equal_weights['diff_norm_measured'] = df_test_norm_diff['diff_norm_measured']\n",
    "    return df_equal_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weighted average ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(df_val_norm_diff):\n",
    "    \" Calculate weights based on the pinball loss of the forecasts\"\n",
    "    assert len(df_val_norm_diff) > 0, 'Dataframe is empty'\n",
    "    lst_cols = [name for name in list(df_val_norm_diff.columns) if 'mostrecent' not in name]\n",
    "    targ_col = [name for name in lst_cols if 'measured' in name]\n",
    "    targets =  df_val_norm_diff[targ_col[0]]\n",
    "    lst_cols_forecasts = [name for name in lst_cols if 'measured' not in name]\n",
    "    lst_q10_weight = []\n",
    "    lst_q50_weight = []\n",
    "    lst_q90_weight = []\n",
    "    for col in lst_cols_forecasts:\n",
    "        if 'forecast' in col:\n",
    "            forecast = df_val_norm_diff[col]\n",
    "            q50_pb_loss = mean_squared_error(targets.values,  forecast.values)  # mean_pinball_loss(targets.values,  forecast.values, alpha=0.5)\n",
    "            lst_q50_weight.append({col : 1/q50_pb_loss})\n",
    "        elif 'confidence10' in col:\n",
    "            forecast = df_val_norm_diff[col]\n",
    "            q10_pb_loss = mean_pinball_loss(targets.values,  forecast.values, alpha=0.1)\n",
    "            lst_q10_weight.append({col : 1/q10_pb_loss})\n",
    "        elif 'confidence90' in col:\n",
    "            forecast = df_val_norm_diff[col]\n",
    "            q90_pb_loss = mean_pinball_loss(targets.values,  forecast.values, alpha=0.9)\n",
    "            lst_q90_weight.append({col : 1/q90_pb_loss})\n",
    "        else:\n",
    "            raise ValueError('Not a valid column')\n",
    "    return lst_cols_forecasts, lst_q10_weight, lst_q50_weight, lst_q90_weight\n",
    "    \n",
    "def normalize_weights(lst_weight):\n",
    "    \" Normalize weights, the sum should be 1\"\n",
    "    assert len(lst_weight) > 0, 'List of weights is empty'  \n",
    "    total_sum = sum(list(loss.values())[0] for loss in lst_weight)\n",
    "    norm_lst_weight = [{key: value/total_sum for key, value in d.items()} for d in lst_weight]\n",
    "    return norm_lst_weight\n",
    "\n",
    "def calculate_combination_forecast(df_test_norm_diff, lst_cols_forecasts, norm_lst_q50_pb_loss, norm_lst_q10_pb_loss, norm_lst_q90_pb_loss):\n",
    "    \" Calculate the combination forecast based on the pinball loss-based weights\"\n",
    "    combination_forecast = np.zeros(len(df_test_norm_diff))\n",
    "    combination_quantile10 = np.zeros(len(df_test_norm_diff))\n",
    "    combination_quantile90 = np.zeros(len(df_test_norm_diff))\n",
    "    for col in lst_cols_forecasts:\n",
    "        if 'forecast' in col:\n",
    "            forecast = df_test_norm_diff[col]\n",
    "            weight = [list(weight.values())[0] for weight in norm_lst_q50_pb_loss if col in weight][0]\n",
    "            combination_forecast += forecast * weight\n",
    "        elif 'confidence10' in col:\n",
    "            forecast = df_test_norm_diff[col]\n",
    "            weight = [list(weight.values())[0] for weight in norm_lst_q10_pb_loss if col in weight][0]\n",
    "            combination_quantile10 += forecast * weight\n",
    "        elif 'confidence90' in col:\n",
    "            forecast = df_test_norm_diff[col]\n",
    "            weight = [list(weight.values())[0] for weight in norm_lst_q90_pb_loss if col in weight][0]\n",
    "            combination_quantile90 += forecast * weight\n",
    "        else:\n",
    "            raise ValueError('Not a valid column')\n",
    "    return combination_forecast, combination_quantile10, combination_quantile90\n",
    "\n",
    "def create_weighted_avg_df(df_test_norm_diff, combination_forecast, combination_quantile10, combination_quantile90):\n",
    "    \" Create dataframe with the weighted average forecast\"\n",
    "    assert len(df_test_norm_diff) == len(combination_forecast) == len(combination_quantile10) == len(combination_quantile90), 'Length mismatch'\n",
    "    df_weighted_avg = pd.DataFrame({\n",
    "        'Q10': combination_quantile10,\n",
    "        'mean_prediction': combination_forecast,\n",
    "        'Q90': combination_quantile90\n",
    "    }, index=df_test_norm_diff.index)\n",
    "    df_weighted_avg['diff_norm_measured'] = df_test_norm_diff['diff_norm_measured']\n",
    "    return df_weighted_avg\n",
    "\n",
    "def calculate_weighted_avg(df_train_norm_diff, df_test_norm_diff, start_predictions, window_size_valid=1, var=False):\n",
    "    \" Calculate the weights based on the pinball loss of the forecasts \"\n",
    "    if var:\n",
    "        df_diff = pd.concat([df_train_norm_diff, df_test_norm_diff], axis=0).diff().dropna()\n",
    "        df_train_norm_diff, df_test_norm_diff = df_diff[df_diff.index < start_predictions], df_diff[df_diff.index >= start_predictions]\n",
    "        window_validation =  pd.to_datetime(start_predictions, utc=True) - pd.Timedelta(days=window_size_valid)\n",
    "        df_val_norm_diff = df_train_norm_diff[df_train_norm_diff.index.to_series().between(window_validation, start_predictions)]\n",
    "        lst_cols_forecasts, lst_q10_weight, lst_q50_weight, lst_q90_weight = calculate_weights(df_val_norm_diff)\n",
    "        norm_lst_q50_weight = normalize_weights(lst_q50_weight) \n",
    "        norm_lst_q10_weight = normalize_weights(lst_q10_weight) \n",
    "        norm_lst_q90_weight = normalize_weights(lst_q90_weight) \n",
    "        combination_forecast, _, _ = calculate_combination_forecast(df_test_norm_diff, lst_cols_forecasts, norm_lst_q50_weight, norm_lst_q10_weight, norm_lst_q90_weight)\n",
    "        df_weighted_avg = pd.DataFrame({\n",
    "                'mean_prediction': combination_forecast,\n",
    "            }, index=df_test_norm_diff.index)\n",
    "        df_weighted_avg['diff_norm_measured'] = df_test_norm_diff['diff_norm_measured']\n",
    "        return df_weighted_avg\n",
    "    window_validation =  pd.to_datetime(start_predictions, utc=True) - pd.Timedelta(days=window_size_valid)\n",
    "    df_val_norm_diff = df_train_norm_diff[df_train_norm_diff.index.to_series().between(window_validation, start_predictions)]\n",
    "    lst_cols_forecasts, lst_q10_weight, lst_q50_weight, lst_q90_weight = calculate_weights(df_val_norm_diff)\n",
    "    norm_lst_q50_weight = normalize_weights(lst_q50_weight) \n",
    "    norm_lst_q10_weight = normalize_weights(lst_q10_weight) \n",
    "    norm_lst_q90_weight = normalize_weights(lst_q90_weight) \n",
    "    combination_forecast, combination_quantile10, combination_quantile90 = calculate_combination_forecast(df_test_norm_diff, lst_cols_forecasts, norm_lst_q50_weight, norm_lst_q10_weight, norm_lst_q90_weight)\n",
    "    df_weighted_avg = pd.DataFrame({\n",
    "            'Q10': combination_quantile10,\n",
    "            'mean_prediction': combination_forecast,\n",
    "            'Q90': combination_quantile90\n",
    "        }, index=df_test_norm_diff.index)\n",
    "    df_weighted_avg['diff_norm_measured'] = df_test_norm_diff['diff_norm_measured']\n",
    "    return df_weighted_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permutation importance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_permutation_importances(fitted_model, X_test_augmented, y_test, score_func, quantile, df_train_ensemble_augmented):\n",
    "    \" Compute permutation importances.\"\n",
    "    r = permutation_importance(\n",
    "        fitted_model, X_test_augmented, y_test,\n",
    "        scoring=score_func[quantile],\n",
    "        n_repeats=1000,\n",
    "        random_state=0\n",
    "    )\n",
    "    feature_names = df_train_ensemble_augmented.drop(columns=['diff_norm_targ']).columns\n",
    "    sorted_importances_idx = r['mean_pinball_loss']['importances_mean'].argsort()[::-1]\n",
    "    importances = pd.DataFrame(\n",
    "        r['mean_pinball_loss']['importances'][sorted_importances_idx].T,\n",
    "        columns=feature_names[sorted_importances_idx]\n",
    "    )\n",
    "    importances[importances > 0] = 0  # Set positive importances to 0\n",
    "    abs_importances = importances.abs()  # Get absolute values\n",
    "    return abs_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elia_forecasts(df, which = 'norm_dayahead'):\n",
    "    \" Plot ELIA forecasts \"\n",
    "    assert which in ['norm_dayahead', 'norm_weekahead', 'norm_dayahead11h'], 'which not in [norm_dayahead, norm_weekahead, norm_dayahead11h]'\n",
    "    list_cols = [which + 'forecast', which + 'confidence10', which + 'confidence90']\n",
    "    df[list_cols].plot(color='blue', linestyle='--')\n",
    "    df['diff_norm_measured'].plot(color='red')\n",
    "\n",
    "def plot_ensemble_forecasts(df_pred_ensemble, df_ensemble):\n",
    "    \" Plot ensemble forecasts \"\n",
    "    assert 'diff_norm_targ' in list(df_ensemble), 'diff_norm_targ not in df_ensemble'\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, ax = plt.subplots()\n",
    "    # Plot '10_predictions' and '90_predictions' on the same axes with blue dashed lines\n",
    "    df_plot = df_pred_ensemble[['10_predictions', '90_predictions']]\n",
    "    df_plot.columns = ['Q10', 'Q90']\n",
    "    df_plot.plot(ax=ax, color='blue', linestyle='--')\n",
    "    # Plot '50_predictions' on the same axes with a solid blue line\n",
    "    df_plot_mean = df_pred_ensemble[['50_predictions']]\n",
    "    df_plot_mean.columns = ['MEAN']\n",
    "    df_plot_mean.plot(ax=ax, color='blue')\n",
    "    df_target = df_ensemble[['diff_norm_targ']]\n",
    "    df_target.columns = ['target']\n",
    "    df_target.plot(ax=ax, color='red')\n",
    "\n",
    "def plot_var_ensemble_forecasts(df_pred_ensemble, df_ensemble):\n",
    "    \" Plot ensemble forecasts \"\n",
    "    assert 'targets' in list(df_ensemble), 'targets not in df_ensemble'\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, ax = plt.subplots()\n",
    "    # Plot '10_predictions' and '90_predictions' on the same axes with blue dashed lines\n",
    "    df_plot = df_pred_ensemble[['10_var_predictions', '90_var_predictions']]\n",
    "    df_plot.columns = ['Q10_variability', 'Q90_variability']\n",
    "    df_plot.plot(ax=ax, color='blue', linestyle='--')\n",
    "    # Plot '50_predictions' on the same axes with a solid blue line\n",
    "    df_plot_mean = df_pred_ensemble[['50_var_predictions']]\n",
    "    df_plot_mean.columns = ['MEAN_variability']\n",
    "    df_plot_mean.plot(ax=ax, color='blue')\n",
    "    df_target = df_ensemble[['targets']]\n",
    "    df_target.columns = ['target_variability']\n",
    "    df_target.plot(ax=ax, color='red')\n",
    "\n",
    "def plot_ramp_events(df_test_norm_diff, ABS_DIFFERENCIATE):\n",
    "    \"Plot ramp events\"\n",
    "    if ABS_DIFFERENCIATE:\n",
    "        plt.axhline(0.3, color='black', linestyle='--')\n",
    "    else:\n",
    "        wind_power_changes = df_test_norm_diff['diff_norm_measured'].diff().fillna(0)\n",
    "        df_test_norm_diff.loc[:, 'ramp'] = (np.abs(wind_power_changes) > 0.3).astype(int)\n",
    "        # Add vertical lines for ramp events\n",
    "        ramp_indices = df_test_norm_diff[df_test_norm_diff['ramp'] == 1].index.values\n",
    "        for idx in ramp_indices:\n",
    "            plt.axvline(idx, color='k', linestyle='--')\n",
    "\n",
    "def plot_feature_importance(feature_importance, df_train_ensemble):\n",
    "    \"Plot feature importance\"\n",
    "    assert  len(feature_importance) == len(list(df_train_ensemble)), 'feature_importance and df_train_ensemble have different lengths'\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "    _ = plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "    plt.yticks(pos, np.array(df_train_ensemble.columns)[sorted_idx])\n",
    "    plt.title(\"Feature Importance (training set)\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_permutation_importances(importances, quantile):\n",
    "        \" Plot permutation importances\"\n",
    "        assert importances is not None, 'importances is None'\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        importances.plot.box(vert=False, whis=10)\n",
    "        plt.title(f\"Permutation Importances (test set)\")\n",
    "        plt.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "        if (quantile == 0.1) or (quantile == 0.9):\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.xlabel(\"Decrease in Pinball loss performance\")\n",
    "            return plt.show()\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel(\"Increase in RMSE loss performance\")\n",
    "        plt.show()\n",
    "\n",
    "def transform_loss_lists_to_df(lst_loss_gbr_ensemble, lst_loss_equal_weights, lst_loss_weighted_avg, lst_loss_baseline_dayahead, lst_loss_baseline_dayahead11h, lst_loss_baseline_weekahead):\n",
    "    \" Transform the loss lists into a DataFrame\"\n",
    "    assert len(lst_loss_gbr_ensemble) == len(lst_loss_equal_weights) == len(lst_loss_weighted_avg) == len(lst_loss_baseline_dayahead) == len(lst_loss_baseline_dayahead11h) == len(lst_loss_baseline_weekahead), 'Length mismatch'\n",
    "    # Construct the dictionary from the input lists\n",
    "    dict_data = {\n",
    "        'gbr_ensemble': lst_loss_gbr_ensemble,\n",
    "        'eq_weights': lst_loss_equal_weights,\n",
    "        'weighted_avg': lst_loss_weighted_avg,\n",
    "        'dayahead': lst_loss_baseline_dayahead,\n",
    "        'dayahead11h': lst_loss_baseline_dayahead11h,\n",
    "        'weekahead': lst_loss_baseline_weekahead,\n",
    "    }\n",
    "    # Transform the dictionary into a DataFrame\n",
    "    data = (\n",
    "        pd.DataFrame(dict_data)\n",
    "        .rename_axis('days')  # Set the index name to 'days'\n",
    "        .melt(                # Melt the DataFrame to long format\n",
    "            var_name='model',\n",
    "            value_name='rmse',\n",
    "            ignore_index=False,\n",
    "        )\n",
    "        .reset_index()        # Reset the index to include 'days' as a column\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def plot_statistical_comparison(pc, avg_rank, title1, title2):\n",
    "    \" Plot the statistical comparison\"\n",
    "    # Define the colormap and heatmap arguments\n",
    "    cmap = ['1', '#fb6a4a',  '#08306b',  '#4292c6', '#c6dbef']\n",
    "    heatmap_args = {\n",
    "        'cmap': cmap,\n",
    "        'linewidths': 0.25,\n",
    "        'linecolor': '0.5',\n",
    "        'clip_on': False,\n",
    "        'square': True,\n",
    "        'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]\n",
    "    }\n",
    "    # Plot the heatmap\n",
    "    plt.title(title1)\n",
    "    sp.sign_plot(pc, **heatmap_args)\n",
    "    plt.show()\n",
    "    # Plot the title for the critical difference diagram\n",
    "    plt.title(title2)\n",
    "    # Plot the critical difference diagram\n",
    "    sp.critical_difference_diagram(avg_rank, pc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble_predictions_per_quantile(abs_differenciate, X_train, X_test, y_train, df_train_ensemble, \n",
    "                                    X_train_quantile10, X_test_quantile10, df_train_ensemble_quantile10, \n",
    "                                    X_train_quantile90, X_test_quantile90, df_train_ensemble_quantile90, \n",
    "                                    predictions, quantile, iteration, add_quantiles, augment_q50,\n",
    "                                    nr_cv_splits, model_type, solver, \n",
    "                                    gbr_update_every_days, gbr_config_params, lr_config_params,\n",
    "                                    score_func, PLOT_IMPORT_GBR, best_results, logger):\n",
    "    \" Run ensemble predictions for a specific quantile.\"\n",
    "    logger.info('   ')\n",
    "    logger.opt(colors=True).info(f'<fg 250,128,114> Run ensemble predictions for quantile {quantile} </fg 250,128,114>')\n",
    "    X_train_augmented, X_test_augmented, df_train_ensemble_augmented = X_train, X_test, df_train_ensemble\n",
    "\n",
    "    # Augment the training and testing data with the quantiles predictions\n",
    "    if add_quantiles:\n",
    "        logger.opt(colors=True).info(f'<fg 250,128,114> Augmenting training and testing data with quantiles </fg 250,128,114>')\n",
    "        X_train_augmented, X_test_augmented, df_train_ensemble_augmented = augment_with_quantiles(\n",
    "            X_train, X_test, df_train_ensemble,\n",
    "            X_train_quantile10, X_test_quantile10, df_train_ensemble_quantile10,\n",
    "            X_train_quantile90, X_test_quantile90, df_train_ensemble_quantile90,\n",
    "            quantile, augment_q50=augment_q50)\n",
    "        \n",
    "    # Optimize model hyperparameters\n",
    "    if iteration % gbr_update_every_days == 0:  # Optimize hyperparameters every gbr_update_every_days\n",
    "        logger.opt(colors=True).info(f'<fg 250,128,114> Optimizing model hyperparameters - updating every {gbr_update_every_days} days</fg 250,128,114>')\n",
    "        best_score, best_params = optimize_model(X_train_augmented, y_train, quantile,\n",
    "                                                    nr_cv_splits, model_type, solver, gbr_config_params,\n",
    "                                                    lr_config_params, score_func, logger)\n",
    "        best_results[quantile] = [('best_score', best_score), ('params', best_params)]\n",
    "    else:\n",
    "        logger.opt(colors=True).info(f'<fg 250,128,114> Using best hyperparameters from first iteration </fg 250,128,114>')\n",
    "        best_params = best_results[quantile][1][1]\n",
    "        \n",
    "    # Initialize model\n",
    "    model = initialize_model(model_type, quantile, best_params)\n",
    "    # Fit model\n",
    "    fitted_model = model.fit(X_train_augmented, y_train)\n",
    "    if PLOT_IMPORT_GBR and model_type == 'GBR':\n",
    "        logger.opt(colors=True).info(f'<fg 250,128,114> GBR feature importance </fg 250,128,114>')\n",
    "        plot_feature_importance(fitted_model.feature_importances_,\n",
    "                                df_train_ensemble_augmented.drop(columns=['diff_norm_targ']))\n",
    "    # Make predictions\n",
    "    raw_predictions = fitted_model.predict(X_test_augmented)\n",
    "    if not abs_differenciate:\n",
    "        raw_predictions[raw_predictions < 0] = 0  # Set negative predictions to 0\n",
    "    predictions[quantile] = raw_predictions  # Store predictions\n",
    "    return predictions, best_results, fitted_model, X_train_augmented, X_test_augmented, df_train_ensemble_augmented\n",
    "\n",
    "\n",
    "def run_ensemble_variability_predictions(X_train_2stage, y_train_2stage, X_test_2stage, quantiles, nr_cv_splits, var_model_type, solver, var_gbr_config_params, var_lr_config_params, gbr_update_every_days, score_func, logger, iteration, best_results_var):\n",
    "    \" Run ensemble variability predictions\"\n",
    "    assert var_model_type in ['GBR', 'LR'], 'Invalid model type'\n",
    "    variability_predictions = {}\n",
    "    for quantile in tqdm(quantiles, desc='Quantile Regression'):\n",
    "        logger.opt(colors=True).info(f'<fg 72,201,176> Run ensemble variability predictions for quantile {quantile} </fg 72,201,176>')\n",
    "        # Optimize model hyperparameters\n",
    "        if iteration % gbr_update_every_days == 0:  # Optimize hyperparameters every gbr_update_every_days\n",
    "            logger.opt(colors=True).info(f'<fg 72,201,176> Optimizing model hyperparameters - updating every {gbr_update_every_days} days</fg 72,201,176>')\n",
    "            best_score, best_params_var = optimize_model(X_train_2stage, y_train_2stage, quantile, nr_cv_splits, var_model_type, solver, var_gbr_config_params, var_lr_config_params, score_func, logger)\n",
    "            best_results_var[quantile] = [('best_score', best_score), ('params', best_params_var)]\n",
    "        else:\n",
    "            logger.opt(colors=True).info(f'<fg 72,201,176> Using best hyperparameters from first iteration </fg 72,201,176>')\n",
    "            best_params_var = best_results_var[quantile][1][1]\n",
    "        model = initialize_model(var_model_type, quantile, best_params_var)  # Initialize model\n",
    "        fitted_model = model.fit(X_train_2stage, y_train_2stage)  # Fit model\n",
    "        raw_variability_predictions = fitted_model.predict(X_test_2stage)  # Make predictions\n",
    "        variability_predictions[quantile] = raw_variability_predictions  # Store predictions\n",
    "    return variability_predictions, best_results_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass\n",
    "\n",
    "# @dataclass(frozen=True)\n",
    "# class Simulation:\n",
    "#     testing_period = dict( \n",
    "#         file_0 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/01.json'\n",
    "#         file_1 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/02.json'\n",
    "#         file_2 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/03.json'\n",
    "#         file_3 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/04.json'\n",
    "#         file_4 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/05.json'\n",
    "\n",
    "#         i = 0\n",
    "#         window_size = 30\n",
    "#         start_training = '2023-01-05'\n",
    "#         num_test_days = 80\n",
    "\n",
    "#         ABS_DIFFERENCIATE = False\n",
    "#         ADD_QUANTILES = True\n",
    "#         augment_q50 = False\n",
    "\n",
    "#         # prediction pipeline\n",
    "#         max_lags = 3\n",
    "#         nr_cv_splits = 3\n",
    "#         quantiles = [0.1, 0.5, 0.9]\n",
    "\n",
    "#         forecasters_diversity = False\n",
    "#         lagged = True\n",
    "#         augment = False\n",
    "#         differenciate = True\n",
    "\n",
    "#         baseline_model = 'diff_norm_dayahead'\n",
    "\n",
    "#         # Ensemble Learning\n",
    "#         model_type = 'GBR'  # 'GBR' or 'LR'\n",
    "#         var_model_type = 'GBR'  # 'GBR' or 'LR'\n",
    "\n",
    "#         gbr_update_every_days = 30\n",
    "\n",
    "#         # forecasts model parameters\n",
    "#         gbr_config_params = {'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.101],\n",
    "#                                 'subsample' : [.8, .85, .95],\n",
    "#                                 'max_depth': [2, 3, 4, 5],\n",
    "#                                 'n_estimators': [200, 500]}\n",
    "#         lr_config_params = {'alpha': [0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.7, 0.9, 1],\n",
    "#                             'fit_intercept' : [True, False]}\n",
    "\n",
    "#         # variability forecasts model parameters\n",
    "#         order_diff = 1\n",
    "#         var_gbr_config_params = {'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.101],\n",
    "#                                     'subsample' : [.8, .85, .95],\n",
    "#                                     'max_depth': [2, 3, 4, 5],\n",
    "#                                     'n_estimators': [200, 500]}\n",
    "#         var_lr_config_params = {'alpha': [0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.7, 0.9, 1],\n",
    "#                                 'fit_intercept' : [True, False]}\n",
    "\n",
    "#         SECOND_STAGE = True  # activate the second stage of the ensemble learning\n",
    "#         PLOT_IMPORT_GBR = False  # plot the feature importances for the GBR model\n",
    "#         PLOT_IMPORT_PERM = False  # plot the permutation importances\n",
    "#         ZOOM_VARIABILITY = False # zoom in the variability forecasts\n",
    "#     )\n",
    "\n",
    "# sim_params = Simulation.testing_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_0 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/01.json'\n",
    "file_1 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/02.json'\n",
    "file_2 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/03.json'\n",
    "file_3 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/04.json'\n",
    "file_4 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/05.json'\n",
    "file_5 = '/Users/gio/Desktop/elia_group/dataset_elia/2023/07.json'\n",
    "\n",
    "i = 0\n",
    "window_size = 30\n",
    "start_training = '2023-01-01'\n",
    "num_test_days = 90\n",
    "\n",
    "ABS_DIFFERENCIATE = False\n",
    "ADD_QUANTILES = True\n",
    "augment_q50 = True\n",
    "\n",
    "# prediction pipeline\n",
    "nr_cv_splits = 5\n",
    "quantiles = [0.1, 0.5, 0.9]\n",
    "\n",
    "# params for 1st stage\n",
    "max_lags = 3\n",
    "forecasters_diversity = False\n",
    "lagged = True\n",
    "augment = True\n",
    "differenciate = True\n",
    "\n",
    "# params for 2nd stage\n",
    "max_lags_var = 3\n",
    "augment_var=True\n",
    "\n",
    "baseline_model = 'diff_norm_dayahead'\n",
    "\n",
    "# Ensemble Learning\n",
    "model_type = 'GBR'  # 'GBR' or 'LR'\n",
    "var_model_type = 'GBR'  # 'GBR' or 'LR'\n",
    "\n",
    "gbr_update_every_days = 30\n",
    "\n",
    "# forecasts model parameters\n",
    "gbr_config_params = {'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "                        'max_features' : [.8, .85, .95, 1.0],\n",
    "                        'max_depth': [2, 3, 4],\n",
    "                        'max_iter': [900, 1000]}\n",
    "lr_config_params = {'alpha': [0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.7, 0.9, 1],\n",
    "                    'fit_intercept' : [True, False]}\n",
    "\n",
    "# variability forecasts model parameters\n",
    "order_diff = 1\n",
    "var_gbr_config_params = {'learning_rate': [0.001, 0.005, 0.01,  0.05, 0.1],\n",
    "                            'max_features' : [.8, .85, .95, 1.0],\n",
    "                            'max_depth': [2, 3, 4],\n",
    "                            'max_iter': [200, 350, 500]}\n",
    "var_lr_config_params = {'alpha': [0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.7, 0.9, 1],\n",
    "                        'fit_intercept' : [True, False]}\n",
    "\n",
    "SECOND_STAGE = True  # activate the second stage of the ensemble learning\n",
    "PLOT_IMPORT_GBR = False  # plot the feature importances for the GBR model\n",
    "PLOT_IMPORT_PERM = False  # plot the permutation importances\n",
    "ZOOM_VARIABILITY = True # zoom in the variability forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider two months of wind power data\n",
    "df_01 = process_file(file_0, offshore_filter='Offshore')\n",
    "df_02 = process_file(file_1, offshore_filter='Offshore')\n",
    "df_03 = process_file(file_2, offshore_filter='Offshore')\n",
    "df_04 = process_file(file_3, offshore_filter='Offshore')\n",
    "df_05 = process_file(file_4, offshore_filter='Offshore')\n",
    "df_06 = process_file(file_5, offshore_filter='Offshore')\n",
    "df = pd.concat([df_01, df_02, df_03, df_04, df_05, df_06], axis=0)\n",
    "\n",
    "# get the maximum capacity\n",
    "maximum_capacity = df.measured.max()\n",
    "\n",
    "lst_forecasts = [name for name in list(df.columns) if 'forecast' in name]  # get all forecast columns\n",
    "lst_confidence10 = [name for name in list(df.columns) if 'confidence10' in name]  # get all confidence10 columns\n",
    "lst_confidence90 = [name for name in list(df.columns) if 'confidence90' in name]  # get all confidence90 columns\n",
    "\n",
    "# list of columns to keep\n",
    "lst_cols = ['measured'] + lst_forecasts + lst_confidence10 + lst_confidence90\n",
    "df_filtered = df[lst_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# loss quantile gradient boosting regressor\n",
    "lst_rmse_gbr_ensemble = []\n",
    "# loss equal weights scheme\n",
    "lst_rmse_equal_weights = []\n",
    "# loss weighted average scheme\n",
    "lst_rmse_weighted_avg = []\n",
    "# loss baseline day ahead\n",
    "lst_rmse_baseline_dayahead = []\n",
    "# loss baseline day ahead 11\n",
    "lst_rmse_baseline_dayahead11h = []\n",
    "# loss baseline week ahead\n",
    "lst_rmse_baseline_week_ahead = []\n",
    "\n",
    "\n",
    "if not ABS_DIFFERENCIATE:\n",
    "    \n",
    "    # loss var gradient boosting regressor\n",
    "    lst_rmse_var_gbr_ensemble = []\n",
    "    # loss var equal weights scheme\n",
    "    lst_rmse_var_equal_weights = []\n",
    "    # loss var weighted average scheme\n",
    "    lst_rmse_var_weighted_avg = []\n",
    "    # loss var baseline day ahead\n",
    "    lst_rmse_var_baseline_dayahead = []\n",
    "    # loss var baseline day ahead 11\n",
    "    lst_rmse_var_baseline_dayahead11h = []\n",
    "    # loss var baseline week ahead\n",
    "    lst_rmse_var_baseline_week_ahead = []\n",
    "\n",
    "    # loss quantile gradient boosting regressor\n",
    "    lst_pb_gbr_ensemble_q10 = []\n",
    "    lst_pb_gbr_ensemble_q90 = []\n",
    "    # loss equal weights scheme\n",
    "    lst_pb_weighted_avg_q10 = []\n",
    "    lst_pb_weighted_avg_q90 = []\n",
    "    # loss weighted average scheme\n",
    "    lst_pb_equal_weights_q10 = []\n",
    "    lst_pb_equal_weights_q90 = []\n",
    "    # loss baseline day ahead\n",
    "    lst_pb_dayahead_q10 = []\n",
    "    lst_pb_dayahead_q90  = []\n",
    "    # loss baseline day ahead 11\n",
    "    lst_pb_dayahead_11h_q10 = []\n",
    "    lst_pb_dayahead_11h_q90 = []\n",
    "    # loss baseline week ahead\n",
    "    lst_pb_week_ahead_q10 = []\n",
    "    lst_pb_week_ahead_q90 = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(num_test_days), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(start_training, i, window_size)\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors = True).info(f'<blue>Start prediction: {start_prediction_timestamp} - End prediction: {end_prediction_timestamp}</blue>')\n",
    "\n",
    "    df_train = df_filtered[df_filtered.index.to_series().between(start_training_timestamp, end_training_timestamp)].iloc[:-1,:]\n",
    "    df_test = df_filtered[df_filtered.index.to_series().between(start_prediction_timestamp, end_prediction_timestamp)].iloc[:-1,:]\n",
    "\n",
    "    logger.opt(colors = True).info('<blue>Forecasters predictions</blue>')\n",
    "    \n",
    "    # forecaster - day ahead forecast\n",
    "    df_day_ahead_pred_train = create_day_ahead_predictions(df_train)\n",
    "    df_day_ahead_pred_test = create_day_ahead_predictions(df_test)\n",
    "\n",
    "    # forecaster - day ahead 11 forecast\n",
    "    df_day_ahead11_pred_train = create_day_ahead_11_predictions(df_train)\n",
    "    df_day_ahead11_pred_test = create_day_ahead_11_predictions(df_test)\n",
    "\n",
    "    # forecaster - week ahead forecast\n",
    "    df_week_ahead_pred_train = create_week_ahead_predictions(df_train)\n",
    "    df_week_ahead_pred_test = create_week_ahead_predictions(df_test)\n",
    "\n",
    "    # forecaster - day ahead quantile-10\n",
    "    df_day_ahead_q10_train = create_day_ahead_quantiles10(df_train)\n",
    "    df_day_ahead_q10_test = create_day_ahead_quantiles10(df_test)\n",
    "\n",
    "    # forecaster - day ahead 11 quantile-10\n",
    "    df_day_ahead11_q10_train = create_day_ahead_11_quantiles10(df_train)\n",
    "    df_day_ahead11_q10_test = create_day_ahead_11_quantiles10(df_test)\n",
    "\n",
    "    # forecaster - week ahead quantile-10\n",
    "    df_week_ahead_q10_train = create_week_ahead_quantiles10(df_train)\n",
    "    df_week_ahead_q10_test = create_week_ahead_quantiles10(df_test)\n",
    "\n",
    "    # forecaster - day ahead quantile-90\n",
    "    df_day_ahead_q90_train = create_day_ahead_quantiles90(df_train)\n",
    "    df_day_ahead_q90_test = create_day_ahead_quantiles90(df_test)\n",
    "\n",
    "    # forecaster - day ahead 11 quantile-90\n",
    "    df_day_ahead11_q90_train = create_day_ahead_11_quantiles90(df_train)\n",
    "    df_day_ahead11_q90_test = create_day_ahead_11_quantiles90(df_test)\n",
    "\n",
    "    # forecaster - week ahead quantile-90\n",
    "    df_week_ahead_q90_train = create_week_ahead_quantiles90(df_train)\n",
    "    df_week_ahead_q90_test = create_week_ahead_quantiles90(df_test)\n",
    "\n",
    "    logger.opt(colors = True).info('<blue>Collecting forecasters prediction for ensemble learning </blue>')\n",
    "    # make esemble dataframe \n",
    "    df_train_ensemble = pd.concat([df_day_ahead_pred_train, df_day_ahead11_pred_train, df_week_ahead_pred_train], axis=1) \n",
    "    df_test_ensemble = pd.concat([df_day_ahead_pred_test, df_day_ahead11_pred_test, df_week_ahead_pred_test], axis=1)\n",
    "    df_ensemble = pd.concat([df_train_ensemble, df_test_ensemble], axis=0)\n",
    "\n",
    "    if ADD_QUANTILES:\n",
    "        df_train_ensemble_quantile10 = pd.concat([df_day_ahead_q10_train, df_day_ahead11_q10_train, df_week_ahead_q10_train], axis=1)\n",
    "        df_train_ensemble_quantile90 = pd.concat([df_day_ahead_q90_train, df_day_ahead11_q90_train, df_week_ahead_q90_train], axis=1)\n",
    "        df_test_ensemble_quantile10 = pd.concat([df_day_ahead_q10_test, df_day_ahead11_q10_test, df_week_ahead_q10_test], axis=1)\n",
    "        df_test_ensemble_quantile90 = pd.concat([df_day_ahead_q90_test, df_day_ahead11_q90_test, df_week_ahead_q90_test], axis=1)\n",
    "        df_ensemble_quantile10 = pd.concat([df_train_ensemble_quantile10, df_test_ensemble_quantile10], axis=0)\n",
    "        df_ensemble_quantile90 = pd.concat([df_train_ensemble_quantile90, df_test_ensemble_quantile90], axis=0)\n",
    "\n",
    "    df_ensemble_normalized = normalize_dataframe(df_ensemble, maximum_capacity)\n",
    "    if ADD_QUANTILES:\n",
    "        df_ensemble_normalized_quantile10 = normalize_dataframe(df_ensemble_quantile10, maximum_capacity)\n",
    "        df_ensemble_normalized_quantile90 = normalize_dataframe(df_ensemble_quantile90, maximum_capacity)\n",
    "\n",
    "    df_ensemble_normalized_lag = create_augmented_dataframe(df_ensemble_normalized, max_lags=max_lags, forecasters_diversity=forecasters_diversity, lagged=lagged, augmented=augment, differenciate=differenciate)\n",
    "    if ADD_QUANTILES:\n",
    "        df_ensemble_normalized_lag_quantile10 = create_augmented_dataframe(df_ensemble_normalized_quantile10, max_lags=max_lags, forecasters_diversity=forecasters_diversity, lagged=lagged, augmented=augment, differenciate=differenciate)\n",
    "        df_ensemble_normalized_lag_quantile90 = create_augmented_dataframe(df_ensemble_normalized_quantile90, max_lags=max_lags, forecasters_diversity=forecasters_diversity, lagged=lagged, augmented=augment, differenciate=differenciate)\n",
    "\n",
    "    # concatenate train and test dataframes\n",
    "    df_process = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "    # normalize dataframe\n",
    "    df_process_norm = normalize_dataframe(df_process, maximum_capacity)\n",
    "\n",
    "    # differenciate dataframe\n",
    "    if ABS_DIFFERENCIATE:\n",
    "        df_process_norm_diff = differentiate_dataframe(df_process_norm)\n",
    "    else:\n",
    "        df_process_norm_diff = df_process_norm.copy()\n",
    "        lst_cols_diff = ['diff_' + name for name in list(df_process_norm.columns)]\n",
    "        df_process_norm_diff.columns = lst_cols_diff\n",
    "\n",
    "    df_train_norm_diff, df_test_norm_diff = df_process_norm_diff[df_process_norm_diff.index < start_prediction_timestamp], df_process_norm_diff[df_process_norm_diff.index >= start_prediction_timestamp]\n",
    "    df_train_ensemble, df_test_ensemble = prepare_train_test_data(df_ensemble_normalized_lag, df_train_norm_diff, df_test_norm_diff, start_prediction_timestamp)\n",
    "    if ADD_QUANTILES:\n",
    "        df_train_ensemble_quantile10, df_test_ensemble_quantile10 = df_ensemble_normalized_lag_quantile10[df_ensemble_normalized_lag_quantile10.index< start_prediction_timestamp], df_ensemble_normalized_lag_quantile10[df_ensemble_normalized_lag_quantile10.index>= start_prediction_timestamp]\n",
    "        df_train_ensemble_quantile90, df_test_ensemble_quantile90 = df_ensemble_normalized_lag_quantile90[df_ensemble_normalized_lag_quantile90.index< start_prediction_timestamp], df_ensemble_normalized_lag_quantile90[df_ensemble_normalized_lag_quantile90.index>= start_prediction_timestamp]\n",
    "\n",
    "    # assert df_test match df_ensemble_test\n",
    "    assert (df_test_norm_diff['diff_norm_measured'] == df_test_ensemble['diff_norm_targ']).all()\n",
    "\n",
    "    # make X-y train and test sets\n",
    "    X_train, y_train, X_test, y_test = get_numpy_Xy_train_test(df_train_ensemble, df_test_ensemble)\n",
    "\n",
    "    if ADD_QUANTILES:\n",
    "        X_train_quantile10, X_test_quantile10 = df_train_ensemble_quantile10.values, df_test_ensemble_quantile10.values\n",
    "        X_train_quantile90, X_test_quantile90 = df_train_ensemble_quantile90.values, df_test_ensemble_quantile90.values\n",
    "\n",
    "    # assert do not have nans (should do it before in processing file)\n",
    "    assert df_train_ensemble.isna().sum().sum() == 0\n",
    "\n",
    "    # run ensemble learning\n",
    "    logger.info('   ')\n",
    "    logger.opt(colors=True).info(f'<fg 250,128,114> Compute Predictions </fg 250,128,114>')\n",
    "    predictions = {}\n",
    "    if i==0:\n",
    "        best_results = {}\n",
    "    for quantile in tqdm(quantiles, desc='Quantile Regression'):\n",
    "\n",
    "        # run ensemble predictions\n",
    "        predictions, best_results, fitted_model, X_train_augmented, X_test_augmented, df_train_ensemble_augmented = run_ensemble_predictions_per_quantile(abs_differenciate=ABS_DIFFERENCIATE,X_train=X_train, X_test=X_test, y_train=y_train, df_train_ensemble=df_train_ensemble, \n",
    "                                    X_train_quantile10=X_train_quantile10, X_test_quantile10=X_test_quantile10, df_train_ensemble_quantile10=df_train_ensemble_quantile10, \n",
    "                                    X_train_quantile90=X_train_quantile90, X_test_quantile90=X_test_quantile90, df_train_ensemble_quantile90=df_train_ensemble_quantile90, \n",
    "                                    predictions=predictions, quantile=quantile, add_quantiles=ADD_QUANTILES, augment_q50=augment_q50,\n",
    "                                    nr_cv_splits=nr_cv_splits, model_type=model_type, solver=solver, \n",
    "                                    gbr_update_every_days=gbr_update_every_days, gbr_config_params=gbr_config_params, lr_config_params=lr_config_params,\n",
    "                                    score_func=score_func, PLOT_IMPORT_GBR=PLOT_IMPORT_GBR, best_results=best_results, iteration=i, logger=logger)\n",
    "\n",
    "        if PLOT_IMPORT_PERM:\n",
    "            logger.info('   ')\n",
    "            logger.opt(colors=True).info(f'<fg 250,128,114> EX-Post Payments with loss-based importance </fg 250,128,114>')\n",
    "            abs_importances = compute_permutation_importances(fitted_model, X_test_augmented, y_test, score_func, quantile, df_train_ensemble_augmented)\n",
    "            plot_permutation_importances(abs_importances, quantile)\n",
    "            logger.info('   ')\n",
    "\n",
    "        if not ABS_DIFFERENCIATE:\n",
    "            if SECOND_STAGE and quantile == 0.5:\n",
    "                logger.info('   ')\n",
    "                logger.opt(colors=True).info(f'<fg 72,201,176> Compute Variability Predictions </fg 72,201,176>')\n",
    "                # make predictions for variability\n",
    "                predictions_insample = fitted_model.predict(X_train_augmented)\n",
    "                predictions_outsample = fitted_model.predict(X_test_augmented)\n",
    "                # create 2-stage dataframe\n",
    "                df_2stage = create_2stage_dataframe(df_train_ensemble, df_test_ensemble, y_train, y_test, predictions_insample, predictions_outsample)\n",
    "                # differenciate dataframe with lags\n",
    "                df_2stage_process = create_augmented_dataframe_2stage(df_2stage, order_diff, max_lags=max_lags_var, augment=augment_var)\n",
    "                # split train and test\n",
    "                df_2stage_train, df_2stage_test = df_2stage_process[df_2stage_process.index < start_prediction_timestamp], df_2stage_process[df_2stage_process.index >= start_prediction_timestamp]\n",
    "                # make X-y train and test sets for 2-stage model\n",
    "                X_train_2stage, y_train_2stage, X_test_2stage, y_test_2stage = df_2stage_train.drop(columns=['targets']).values, df_2stage_train['targets'].values, df_2stage_test.drop(columns=['targets']).values, df_2stage_test['targets'].values\n",
    "                # run ensemble learning\n",
    "                if i == 0:\n",
    "                    best_results_var = {}\n",
    "                # run variability predictions\n",
    "                variability_predictions, best_results_var = run_ensemble_variability_predictions(X_train_2stage = X_train_2stage, y_train_2stage=y_train_2stage, X_test_2stage=X_test_2stage, \n",
    "                                                                                                    quantiles=quantiles, nr_cv_splits=nr_cv_splits, var_model_type=var_model_type, solver=solver, \n",
    "                                                                                                    var_gbr_config_params=var_gbr_config_params, var_lr_config_params=var_lr_config_params, gbr_update_every_days=gbr_update_every_days, \n",
    "                                                                                                    score_func=score_func, logger=logger, iteration=i, best_results_var=best_results_var)\n",
    "                # collect results as dictionary\n",
    "                var_predictions_dict = collect_quantile_ensemble_predictions(quantiles, df_2stage_test, variability_predictions)\n",
    "                df_var_ensemble = create_var_ensemble_dataframe(quantiles, var_predictions_dict, df_2stage_test)\n",
    "\n",
    "        logger.info('   ')\n",
    "        del X_train_augmented, X_test_augmented, df_train_ensemble_augmented\n",
    "        gc.collect()\n",
    "\n",
    "    # collect results as dictionary\n",
    "    quantile_predictions_dict = collect_quantile_ensemble_predictions(quantiles, df_test_norm_diff, predictions)\n",
    "    \n",
    "    # collect results as dataframe\n",
    "    df_pred_ensemble = create_ensemble_dataframe(quantiles, quantile_predictions_dict, df_test_norm_diff)\n",
    "\n",
    "    # performance ensemble\n",
    "    rmse_ensemble = round(calculate_rmse(df_pred_ensemble, '50_predictions').values[0][0], 3)\n",
    "    lst_rmse_gbr_ensemble.append(rmse_ensemble)\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        pinball_ensemble = calculate_pinball_losses(df_pred_ensemble, '10_predictions', '90_predictions')\n",
    "        pinball_ensemble_q10 = round(pinball_ensemble['pb_loss_10'].values[0], 3)\n",
    "        pinball_ensemble_q90 = round(pinball_ensemble['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_gbr_ensemble_q10.append(pinball_ensemble_q10)\n",
    "        lst_pb_gbr_ensemble_q90.append(pinball_ensemble_q90)\n",
    "\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "\n",
    "        # performance variability ensemble\n",
    "        rmse_var_ensemble = round(calculate_rmse(df_var_ensemble, '50_var_predictions', targ_col='targets').values[0][0], 3)\n",
    "        lst_rmse_var_gbr_ensemble.append(rmse_var_ensemble)\n",
    "\n",
    "        df_weighted_avg_var = calculate_weighted_avg(df_train_norm_diff, df_test_norm_diff, start_prediction_timestamp, window_size_valid=1, var=True)\n",
    "        rmse_var_weighted_avg = round(calculate_rmse(df_weighted_avg_var, 'mean_prediction').values[0][0], 3)\n",
    "        lst_rmse_var_weighted_avg.append(rmse_var_weighted_avg)\n",
    "\n",
    "        # concatenate last training row with test data\n",
    "        df_test_norm_var = pd.concat([df_train_norm_diff.iloc[-1:, :], df_test_norm_diff], axis=0).diff().iloc[1:, :]\n",
    "\n",
    "        df_equal_weights_var = calculate_equal_weights(df_test_norm_var)\n",
    "        rmse_var_equal_weights = round(calculate_rmse(df_equal_weights_var, 'mean_prediction').values[0][0], 3)\n",
    "        lst_rmse_var_equal_weights.append(rmse_var_equal_weights)\n",
    "\n",
    "        df_dayahead_var = df_test_norm_var[['diff_norm_dayaheadforecast', 'diff_norm_measured']]\n",
    "        rmse_var_dayahead = round(calculate_rmse(df_dayahead_var, 'diff_norm_dayaheadforecast').values[0][0], 3)\n",
    "        lst_rmse_var_baseline_dayahead.append(rmse_var_dayahead)\n",
    "\n",
    "        df_dayahead_11h_var = df_test_norm_var[['diff_norm_dayahead11hforecast', 'diff_norm_measured']]\n",
    "        rmse_var_dayahead_11h = round(calculate_rmse(df_dayahead_11h_var, 'diff_norm_dayahead11hforecast').values[0][0], 3)\n",
    "        lst_rmse_var_baseline_dayahead11h.append(rmse_var_dayahead_11h)\n",
    "\n",
    "        # performance week ahead\n",
    "        df_week_ahead_var = df_test_norm_var[['diff_norm_weekaheadforecast', 'diff_norm_measured']]\n",
    "        rmse_var_week_ahead = round(calculate_rmse(df_week_ahead_var, 'diff_norm_weekaheadforecast').values[0][0], 3)\n",
    "        lst_rmse_var_baseline_week_ahead.append(rmse_var_week_ahead)\n",
    "\n",
    "    # performance weighted average\n",
    "    df_weighted_avg = calculate_weighted_avg(df_train_norm_diff, df_test_norm_diff, start_prediction_timestamp, window_size_valid=1)\n",
    "    rmse_weighted_avg = round(calculate_rmse(df_weighted_avg, 'mean_prediction').values[0][0], 3)\n",
    "    lst_rmse_weighted_avg.append(rmse_weighted_avg)\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        pinball_weighted_avg = calculate_pinball_losses(df_weighted_avg, 'Q10', 'Q90')\n",
    "        pinball_weighted_avg_q10 = round(pinball_weighted_avg['pb_loss_10'].values[0], 3)\n",
    "        pinball_weighted_avg_q90 = round(pinball_weighted_avg['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_weighted_avg_q10.append(pinball_weighted_avg_q10)\n",
    "        lst_pb_weighted_avg_q90.append(pinball_weighted_avg_q90)\n",
    "\n",
    "    # performance equal weights\n",
    "    df_equal_weights = calculate_equal_weights(df_test_norm_diff)\n",
    "    rmse_equal_weights = round(calculate_rmse(df_equal_weights, 'mean_prediction').values[0][0], 3)\n",
    "    lst_rmse_equal_weights.append(rmse_equal_weights)\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        pinball_equal_weights = calculate_pinball_losses(df_equal_weights, 'Q10', 'Q90')\n",
    "        pinball_equal_weights_q10 = round(pinball_equal_weights['pb_loss_10'].values[0], 3)\n",
    "        pinball_equal_weights_q90 = round(pinball_equal_weights['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_equal_weights_q10.append(pinball_equal_weights_q10)\n",
    "        lst_pb_equal_weights_q90.append(pinball_equal_weights_q90)\n",
    "\n",
    "    # performance day-ahead\n",
    "    df_dayahead = df_test_norm_diff[['diff_norm_dayaheadforecast', 'diff_norm_dayaheadconfidence10', 'diff_norm_dayaheadconfidence90', 'diff_norm_measured']]\n",
    "    rmse_dayahead = round(calculate_rmse(df_dayahead, 'diff_norm_dayaheadforecast').values[0][0], 3)\n",
    "    lst_rmse_baseline_dayahead.append(rmse_dayahead)\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        pinball_dayahead = calculate_pinball_losses(df_dayahead, 'diff_norm_dayaheadconfidence10', 'diff_norm_dayaheadconfidence90')\n",
    "        pinball_dayahead_q10 = round(pinball_dayahead['pb_loss_10'].values[0], 3)\n",
    "        pinball_dayahead_q90 = round(pinball_dayahead['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_dayahead_q10.append(pinball_dayahead_q10)\n",
    "        lst_pb_dayahead_q90.append(pinball_dayahead_q90)\n",
    "    \n",
    "    # performance day-ahead-11h\n",
    "    df_dayahead_11h = df_test_norm_diff[['diff_norm_dayahead11hforecast', 'diff_norm_dayahead11hconfidence10', 'diff_norm_dayahead11hconfidence90', 'diff_norm_measured']]\n",
    "    rmse_dayahead_11h = round(calculate_rmse(df_dayahead_11h, 'diff_norm_dayahead11hforecast').values[0][0], 3)\n",
    "    lst_rmse_baseline_dayahead11h.append(rmse_dayahead_11h)\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        pinball_dayahead_11h = calculate_pinball_losses(df_dayahead_11h, 'diff_norm_dayahead11hconfidence10', 'diff_norm_dayahead11hconfidence90')\n",
    "        pinball_dayahead_11h_q10 = round(pinball_dayahead_11h['pb_loss_10'].values[0], 3)\n",
    "        pinball_dayahead_11h_q90 = round(pinball_dayahead_11h['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_dayahead_11h_q10.append(pinball_dayahead_11h_q10)\n",
    "        lst_pb_dayahead_11h_q90.append(pinball_dayahead_11h_q90)\n",
    "\n",
    "    # performance week ahead\n",
    "    df_week_ahead = df_test_norm_diff[['diff_norm_weekaheadforecast', 'diff_norm_weekaheadconfidence10', 'diff_norm_weekaheadconfidence90', 'diff_norm_measured']]\n",
    "    rmse_week_ahead = round(calculate_rmse(df_week_ahead, 'diff_norm_weekaheadforecast').values[0][0], 3)\n",
    "    lst_rmse_baseline_week_ahead.append(rmse_week_ahead)\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        pinball_week_ahead = calculate_pinball_losses(df_week_ahead, 'diff_norm_weekaheadconfidence10', 'diff_norm_weekaheadconfidence90')\n",
    "        pinball_week_ahead_q10 = round(pinball_week_ahead['pb_loss_10'].values[0], 3)\n",
    "        pinball_week_ahead_q90 = round(pinball_week_ahead['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_week_ahead_q10.append(pinball_week_ahead_q10)\n",
    "        lst_pb_week_ahead_q90.append(pinball_week_ahead_q90)\n",
    "\n",
    "    # plot forecasts\n",
    "    plot_ensemble_forecasts(df_pred_ensemble, df_test_ensemble)\n",
    "    nr_previous_days = len(pd.date_range(start=start_training_timestamp, end=end_training_timestamp, freq='1D')) - 1\n",
    "    plt.title(f'Ensemble Forecasts - Quantile {model_type}')\n",
    "    plot_ramp_events(df_test_norm_diff, ABS_DIFFERENCIATE)\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        plt.ylim(-0.01, 1)\n",
    "    plt.show()\n",
    "\n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        # plot variability forecast results\n",
    "        plot_var_ensemble_forecasts(df_var_ensemble, df_2stage_test)\n",
    "        nr_previous_days = len(pd.date_range(start=start_training_timestamp, end=end_training_timestamp, freq='1D')) - 1\n",
    "        plt.title(f'Ensemble Variability Forecasts - Quantile {model_type}')\n",
    "        plot_ramp_events(df_test_norm_diff, ABS_DIFFERENCIATE)\n",
    "        if not ZOOM_VARIABILITY:\n",
    "            plt.ylim(-0.6, 0.6)\n",
    "        plt.show()\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.info('------------- Wind Power Froecasting ------------------------------')\n",
    "    logger.info(f'----------------- RMSE -----------------')\n",
    "    logger.info(f'GBR Stacked {rmse_ensemble}')\n",
    "    logger.info(f'Weighted Average {rmse_weighted_avg}')\n",
    "    logger.info(f'Equal Weights {rmse_equal_weights}')\n",
    "    logger.info(f'Day-Ahead {rmse_dayahead}')\n",
    "    logger.info(f'Day-Ahead-11h {rmse_dayahead_11h}')\n",
    "    logger.info(f'Week-Ahead {rmse_week_ahead}')\n",
    "    logger.info('   ')\n",
    "    \n",
    "    if not ABS_DIFFERENCIATE:\n",
    "        logger.info(f'----------------- PB Q10 -----------------')\n",
    "        logger.info(f'PB Q10 GBR Stacked {pinball_ensemble_q10}')\n",
    "        logger.info(f'PB Q10 Weig Avg {pinball_weighted_avg_q10}')\n",
    "        logger.info(f'PB Q10 Eq Weig {pinball_weighted_avg_q10}')\n",
    "        logger.info(f'PB Q10 Day-Ahead {pinball_dayahead_q10}')\n",
    "        logger.info(f'PB Q10 Day-Ahead-11h {pinball_dayahead_11h_q10}')\n",
    "        logger.info(f'PB Q10 Week-Ahead {pinball_week_ahead_q10}')\n",
    "        logger.info('   ')\n",
    "        logger.info(f'----------------- PB Q90 -----------------')\n",
    "        logger.info(f'GBR Stacked {pinball_ensemble_q90}')\n",
    "        logger.info(f'Weig Avg {pinball_weighted_avg_q90}')\n",
    "        logger.info(f'Eq Weig {pinball_weighted_avg_q90}')\n",
    "        logger.info(f'Day-Ahead {pinball_dayahead_q90}')\n",
    "        logger.info(f'Day-Ahead-11h {pinball_dayahead_11h_q90}')\n",
    "        logger.info(f'Week-Ahead {pinball_week_ahead_q90}')\n",
    "        logger.info('   ')\n",
    "        logger.info(f'----------------- Wind Power Variability Forecast -----------------')\n",
    "        logger.info(f'----------------- RMSE -----------------')\n",
    "        logger.info(f'GBR Stacked {rmse_var_ensemble}')\n",
    "        logger.info(f'Weighted Average {rmse_var_weighted_avg}')\n",
    "        logger.info(f'Equal Weights {rmse_var_equal_weights}')\n",
    "        logger.info(f'Day-Ahead {rmse_var_dayahead}')\n",
    "        logger.info(f'Day-Ahead-11h {rmse_var_dayahead_11h}')\n",
    "        logger.info(f'Week-Ahead {rmse_var_week_ahead}')\n",
    "        logger.info('   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = transform_loss_lists_to_df(lst_rmse_gbr_ensemble, lst_rmse_equal_weights, lst_rmse_weighted_avg, lst_rmse_baseline_dayahead, lst_rmse_baseline_dayahead11h, lst_rmse_baseline_week_ahead)\n",
    "avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "plot_statistical_comparison(pc, avg_rank,\n",
    "                            title1 = 'RMSE-based Statistical Significance',\n",
    "                            title2 = 'RMSE-based Statistical Comparison: critical difference diagram of ranks')\n",
    "\n",
    "if not ABS_DIFFERENCIATE:\n",
    "\n",
    "    data = transform_loss_lists_to_df(lst_pb_gbr_ensemble_q10, lst_pb_equal_weights_q10, lst_pb_weighted_avg_q10, lst_pb_dayahead_q10, lst_pb_dayahead_11h_q10, lst_pb_week_ahead_q10)\n",
    "    avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "    pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "    plot_statistical_comparison(pc, avg_rank,\n",
    "                                title1 = 'Q10 Pinball loss-based Statistical Significance',\n",
    "                                title2 = 'Q10 Pinball loss-based Statistical Comparison: critical difference diagram of ranks')\n",
    "    \n",
    "    data = transform_loss_lists_to_df(lst_pb_gbr_ensemble_q90, lst_pb_equal_weights_q90, lst_pb_weighted_avg_q90, lst_pb_dayahead_q90, lst_pb_dayahead_11h_q90, lst_pb_dayahead_11h_q90)\n",
    "    avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "    pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "    plot_statistical_comparison(pc, avg_rank,\n",
    "                                title1 = 'Q90 Pinball loss-based Statistical Significance',\n",
    "                                title2 = 'Q90 Pinball loss-based Statistical Comparison: critical difference diagram of ranks')\n",
    "    \n",
    "    data = transform_loss_lists_to_df(lst_rmse_var_gbr_ensemble, lst_rmse_var_equal_weights, lst_rmse_var_weighted_avg, lst_rmse_var_baseline_dayahead, lst_rmse_var_baseline_dayahead11h, lst_rmse_var_baseline_week_ahead)\n",
    "    avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "    pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "    plot_statistical_comparison(pc, avg_rank, \n",
    "                                title1 = 'RMSE-based Statistical Significance',\n",
    "                                title2 = 'RMSE-based Statistical Comparison: critical difference diagram of ranks')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a7c91581aa0a78bf28325e7d08cc358580605c20167dbd02b70ea52b9f09d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.19 ('elia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
