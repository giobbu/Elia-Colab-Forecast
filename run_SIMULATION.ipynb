{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from matplotlib import pyplot as plt\n",
    "from source.utils.file_read import process_and_concat_files \n",
    "from source.utils.file_read import filter_df\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.forecasters.deterministic import create_day_ahead_predictions, create_day_ahead_11_predictions, create_week_ahead_predictions\n",
    "from source.forecasters.probabilistic import create_day_ahead_quantiles10, create_day_ahead_11_quantiles10, create_week_ahead_quantiles10\n",
    "from source.forecasters.probabilistic import create_day_ahead_quantiles90, create_day_ahead_11_quantiles90, create_week_ahead_quantiles90\n",
    "from source.ensemble.stack_generalization.utils.display_results import display_forecasting_metrics\n",
    "from source.ensemble.combination_scheme.equal_weights import calculate_equal_weights\n",
    "from source.ensemble.combination_scheme.avg_weights import calculate_weighted_avg\n",
    "from source.ensemble.utils.metrics import calculate_rmse, calculate_pinball_losses\n",
    "from source.plots.plot_forecasts import plot_ensemble_forecasts, plot_var_ensemble_forecasts, plot_ramp_events, plot_weighted_avg_forecasts\n",
    "from source.plots.plot_hypothesis_testing import plot_statistical_comparison, transform_loss_lists_to_df\n",
    "from source.ensemble.combination_scheme.weight_avg_plot_importance import plot_weight_avg_contributions\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.simulation_setting import Simulation, WeightedAvg, Stack\n",
    "\n",
    "sim_params = Simulation.testing_period\n",
    "weight_avg_params = WeightedAvg.params\n",
    "ens_params = Stack.params\n",
    "ens_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.data_preprocess import normalize_dataframe\n",
    "\n",
    "def process_combination_scheme(df_train, df_test, df_buyer, start_prediction_timestamp):\n",
    "    \" Process data for the combination scheme\"\n",
    "    # Concatenate train and test dataframes\n",
    "    df_comb_scheme = pd.concat([df_train, df_test], axis=0)\n",
    "    # Get the maximum capacity\n",
    "    maximum_capacity = df_buyer['b1r1'].max()\n",
    "    # Normalize dataframe\n",
    "    df_comb_scheme_norm = normalize_dataframe(df_comb_scheme, maximum_capacity)\n",
    "    # Differentiate dataframe\n",
    "    df_comb_scheme_norm_diff = df_comb_scheme_norm.copy()\n",
    "    lst_cols_diff = ['diff_' + name for name in df_comb_scheme_norm.columns]\n",
    "    df_comb_scheme_norm_diff.columns = lst_cols_diff\n",
    "    # Split train and test dataframes\n",
    "    df_train_norm_diff = df_comb_scheme_norm_diff[df_comb_scheme_norm_diff.index < start_prediction_timestamp]\n",
    "    df_test_norm_diff = df_comb_scheme_norm_diff[df_comb_scheme_norm_diff.index >= start_prediction_timestamp]\n",
    "    return df_train_norm_diff, df_test_norm_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "files = [sim_params['file_0'], sim_params['file_1'], sim_params['file_2'], sim_params['file_3'], sim_params['file_4']]\n",
    "df = process_and_concat_files(files)\n",
    "\n",
    "# get the maximum capacity\n",
    "maximum_capacity = df.measured.max()\n",
    "\n",
    "df_filtered = filter_df(df, sim_params['forecasts_col'], sim_params['measured_col'])\n",
    "\n",
    "# loss quantile gradient boosting regressor\n",
    "lst_rmse_gbr_ensemble = []\n",
    "# loss equal weights scheme\n",
    "lst_rmse_equal_weights = []\n",
    "# loss weighted average scheme\n",
    "lst_rmse_weighted_avg = []\n",
    "# loss baseline day ahead\n",
    "lst_rmse_baseline_dayahead = []\n",
    "# loss baseline day ahead 11\n",
    "lst_rmse_baseline_dayahead11h = []\n",
    "# loss baseline week ahead\n",
    "lst_rmse_baseline_week_ahead = []\n",
    "\n",
    "\n",
    "if not ens_params['compute_abs_difference']:\n",
    "    \n",
    "    # loss var gradient boosting regressor\n",
    "    lst_rmse_var_gbr_ensemble = []\n",
    "    # loss var equal weights scheme\n",
    "    lst_rmse_var_equal_weights = []\n",
    "    # loss var weighted average scheme\n",
    "    lst_rmse_var_weighted_avg = []\n",
    "    # loss var baseline day ahead\n",
    "    lst_rmse_var_baseline_dayahead = []\n",
    "    # loss var baseline day ahead 11\n",
    "    lst_rmse_var_baseline_dayahead11h = []\n",
    "    # loss var baseline week ahead\n",
    "    lst_rmse_var_baseline_week_ahead = []\n",
    "\n",
    "    # loss quantile gradient boosting regressor\n",
    "    lst_pb_gbr_ensemble_q10 = []\n",
    "    lst_pb_gbr_ensemble_q90 = []\n",
    "    # loss equal weights scheme\n",
    "    lst_pb_weighted_avg_q10 = []\n",
    "    lst_pb_weighted_avg_q90 = []\n",
    "    # loss weighted average scheme\n",
    "    lst_pb_equal_weights_q10 = []\n",
    "    lst_pb_equal_weights_q90 = []\n",
    "    # loss baseline day ahead\n",
    "    lst_pb_dayahead_q10 = []\n",
    "    lst_pb_dayahead_q90  = []\n",
    "    # loss baseline day ahead 11\n",
    "    lst_pb_dayahead_11h_q10 = []\n",
    "    lst_pb_dayahead_11h_q90 = []\n",
    "    # loss baseline week ahead\n",
    "    lst_pb_week_ahead_q10 = []\n",
    "    lst_pb_week_ahead_q90 = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors = True).info(f'<blue>Start prediction: {start_prediction_timestamp} - End prediction: {end_prediction_timestamp}</blue>')\n",
    "\n",
    "    df_train = df_filtered[df_filtered.index.to_series().between(start_training_timestamp, end_training_timestamp)].iloc[:-1,:]\n",
    "    df_test = df_filtered[df_filtered.index.to_series().between(start_prediction_timestamp, end_prediction_timestamp)].iloc[:-1,:]\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue> -----------------> Forecasters prediction submitted </blue>')\n",
    "    \n",
    "    # forecaster - day ahead forecast\n",
    "    df_day_ahead_pred_train = create_day_ahead_predictions(df_train)\n",
    "    df_day_ahead_pred_test = create_day_ahead_predictions(df_test)\n",
    "\n",
    "    # forecaster - day ahead 11 forecast\n",
    "    df_day_ahead11_pred_train = create_day_ahead_11_predictions(df_train)\n",
    "    df_day_ahead11_pred_test = create_day_ahead_11_predictions(df_test)\n",
    "\n",
    "    # forecaster - week ahead forecast\n",
    "    df_week_ahead_pred_train = create_week_ahead_predictions(df_train)\n",
    "    df_week_ahead_pred_test = create_week_ahead_predictions(df_test)\n",
    "\n",
    "    # forecaster - day ahead quantile-10\n",
    "    df_day_ahead_q10_train = create_day_ahead_quantiles10(df_train)\n",
    "    df_day_ahead_q10_test = create_day_ahead_quantiles10(df_test)\n",
    "\n",
    "    # forecaster - day ahead 11 quantile-10\n",
    "    df_day_ahead11_q10_train = create_day_ahead_11_quantiles10(df_train)\n",
    "    df_day_ahead11_q10_test = create_day_ahead_11_quantiles10(df_test)\n",
    "\n",
    "    # forecaster - week ahead quantile-10\n",
    "    df_week_ahead_q10_train = create_week_ahead_quantiles10(df_train)\n",
    "    df_week_ahead_q10_test = create_week_ahead_quantiles10(df_test)\n",
    "\n",
    "    # forecaster - day ahead quantile-90\n",
    "    df_day_ahead_q90_train = create_day_ahead_quantiles90(df_train)\n",
    "    df_day_ahead_q90_test = create_day_ahead_quantiles90(df_test)\n",
    "\n",
    "    # forecaster - day ahead 11 quantile-90\n",
    "    df_day_ahead11_q90_train = create_day_ahead_11_quantiles90(df_train)\n",
    "    df_day_ahead11_q90_test = create_day_ahead_11_quantiles90(df_test)\n",
    "\n",
    "    # forecaster - week ahead quantile-90\n",
    "    df_week_ahead_q90_train = create_week_ahead_quantiles90(df_train)\n",
    "    df_week_ahead_q90_test = create_week_ahead_quantiles90(df_test)\n",
    "\n",
    "\n",
    "    from source.ml_engine import create_ensemble_forecasts\n",
    "\n",
    "# # ----------------------------> SELLERS DATA <----------------------------\n",
    "    # sellers data\n",
    "    df_train_ensemble_quantile50 = pd.concat([df_day_ahead_pred_train, df_day_ahead11_pred_train, df_week_ahead_pred_train], axis=1)\n",
    "    df_test_ensemble_quantile50 = pd.concat([df_day_ahead_pred_test, df_day_ahead11_pred_test, df_week_ahead_pred_test], axis=1)\n",
    "    df_ensemble_quantile50 = pd.concat([df_train_ensemble_quantile50, df_test_ensemble_quantile50], axis=0)\n",
    "\n",
    "    df_train_ensemble_quantile10 = pd.concat([df_day_ahead_q10_train, df_day_ahead11_q10_train, df_week_ahead_q10_train], axis=1)\n",
    "    df_test_ensemble_quantile10 = pd.concat([df_day_ahead_q10_test, df_day_ahead11_q10_test, df_week_ahead_q10_test], axis=1)\n",
    "    df_ensemble_quantile10 = pd.concat([df_train_ensemble_quantile10, df_test_ensemble_quantile10], axis=0)\n",
    "\n",
    "    df_train_ensemble_quantile90 = pd.concat([df_day_ahead_q90_train, df_day_ahead11_q90_train, df_week_ahead_q90_train], axis=1)\n",
    "    df_test_ensemble_quantile90 = pd.concat([df_day_ahead_q90_test, df_day_ahead11_q90_test, df_week_ahead_q90_test], axis=1)\n",
    "    df_ensemble_quantile90 = pd.concat([df_train_ensemble_quantile90, df_test_ensemble_quantile90], axis=0)\n",
    "\n",
    "    df_ensemble_quantile50.columns = ['s1_q50_b1r1', 's2_q50_b1r1', 's3_q50_b1r1']\n",
    "    df_ensemble_quantile10.columns = ['s1_q10_b1r1', 's2_q10_b1r1', 's3_q10_b1r1']\n",
    "    df_ensemble_quantile90.columns = ['s1_q90_b1r1', 's2_q90_b1r1', 's3_q90_b1r1']\n",
    "\n",
    "    df_market = pd.concat([df_ensemble_quantile50, df_ensemble_quantile10, df_ensemble_quantile90], axis=1)\n",
    "\n",
    "# # ----------------------------> BUYERS DATA <----------------------------\n",
    "    df_train_buyer = pd.DataFrame(df_train['measured'])\n",
    "    df_test_buyer = pd.DataFrame(df_test['measured'])\n",
    "    forecast_range = pd.date_range(start=start_prediction_timestamp, end=end_prediction_timestamp, freq='15min')\n",
    "    #df_test['measured'] = [None for i in range(len(df_test))]\n",
    "    df_buyer = pd.concat([df_train_buyer, df_test_buyer], axis=0)\n",
    "    df_buyer['b1r1'] = df_buyer['measured']\n",
    "    df_buyer.drop(columns=['measured'], inplace=True)\n",
    "\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "    results_ensemble_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                    df_buyer=df_buyer, \n",
    "                                    df_market=df_market,\n",
    "                                    forecast_range = forecast_range,\n",
    "                                    challenge_usecase='simulation',\n",
    "                                    simulation=True)\n",
    "    \n",
    "    df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']\n",
    "    df_pred_ensemble.rename(columns={'q50_' + 'b1r1': '50_predictions', 'q10_' + 'b1r1': '10_predictions', 'q90_' + 'b1r1': '90_predictions', 'diff_norm_' + 'b1r1': 'target'}, inplace=True)\n",
    "    df_var_ensemble = results_ensemble_forecasts['wind_power_variability']['predictions']\n",
    "    df_var_ensemble.rename(columns={'q50_' + 'b1r1': '50_var_predictions', 'q10_' + 'b1r1': '10_var_predictions', 'q90_' + 'b1r1': '90_var_predictions', 'targets': 'target'}, inplace=True)\n",
    "    df_test_ensemble = results_ensemble_forecasts['wind_power']['df_test']\n",
    "    df_2stage_test = results_ensemble_forecasts['wind_power_variability']['df_test']\n",
    "\n",
    "# # ----------------------------> COMBINATION SCHEME DATA <----------------------------\n",
    "    df_train_norm_diff, df_test_norm_diff = process_combination_scheme(df_train, df_test, df_buyer, start_prediction_timestamp)\n",
    "\n",
    "\n",
    "# # ----------------------------> PERFORMANCE METRICS <----------------------------\n",
    "    # performance ensemble\n",
    "    rmse_ensemble = round(calculate_rmse(df_pred_ensemble, '50_predictions').values[0][0], 3)\n",
    "    lst_rmse_gbr_ensemble.append(rmse_ensemble)\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        pinball_ensemble = calculate_pinball_losses(df_pred_ensemble, '10_predictions', '90_predictions')\n",
    "        pinball_ensemble_q10 = round(pinball_ensemble['pb_loss_10'].values[0], 3)\n",
    "        pinball_ensemble_q90 = round(pinball_ensemble['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_gbr_ensemble_q10.append(pinball_ensemble_q10)\n",
    "        lst_pb_gbr_ensemble_q90.append(pinball_ensemble_q90)\n",
    "\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        # performance variability ensemble\n",
    "        rmse_var_ensemble = round(calculate_rmse(df_var_ensemble, '50_var_predictions', targ_col='target').values[0][0], 3)\n",
    "        lst_rmse_var_gbr_ensemble.append(rmse_var_ensemble)\n",
    "\n",
    "        df_weighted_avg_var, dict_weights_var = calculate_weighted_avg(df_train_norm_diff , df_test_norm_diff, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], var=True)\n",
    "        rmse_var_weighted_avg = round(calculate_rmse(df_weighted_avg_var, 'mean_prediction').values[0][0], 3)\n",
    "        lst_rmse_var_weighted_avg.append(rmse_var_weighted_avg)\n",
    "\n",
    "        # plot contribution weighted average\n",
    "        if ens_params['plot_importance_weighted_avg']:\n",
    "            plot_weight_avg_contributions(dict_weights_var, quantile=0.5, stage='Wind Power Variability', days= weight_avg_params['window_size_valid'])\n",
    "\n",
    "        # concatenate last training row with test data\n",
    "        df_test_norm_var = pd.concat([df_train_norm_diff.iloc[-1:, :], df_test_norm_diff], axis=0).diff().iloc[1:, :]\n",
    "\n",
    "        df_equal_weights_var = calculate_equal_weights(df_test_norm_var)\n",
    "        rmse_var_equal_weights = round(calculate_rmse(df_equal_weights_var, 'mean_prediction').values[0][0], 3)\n",
    "        lst_rmse_var_equal_weights.append(rmse_var_equal_weights)\n",
    "\n",
    "        df_dayahead_var = df_test_norm_var[['diff_norm_dayaheadforecast', 'diff_norm_measured']]\n",
    "        df_dayahead_var = df_dayahead_var.copy()\n",
    "        df_dayahead_var.loc[:, 'target'] = df_dayahead_var['diff_norm_measured']\n",
    "        rmse_var_dayahead = round(calculate_rmse(df_dayahead_var, 'diff_norm_dayaheadforecast').values[0][0], 3)\n",
    "        lst_rmse_var_baseline_dayahead.append(rmse_var_dayahead)\n",
    "\n",
    "        df_dayahead_11h_var = df_test_norm_var[['diff_norm_dayahead11hforecast', 'diff_norm_measured']]\n",
    "        df_dayahead_11h_var = df_dayahead_11h_var.copy()\n",
    "        df_dayahead_11h_var.loc[:, 'target'] = df_dayahead_11h_var['diff_norm_measured']\n",
    "        rmse_var_dayahead_11h = round(calculate_rmse(df_dayahead_11h_var, 'diff_norm_dayahead11hforecast').values[0][0], 3)\n",
    "        lst_rmse_var_baseline_dayahead11h.append(rmse_var_dayahead_11h)\n",
    "\n",
    "        # performance week ahead\n",
    "        df_week_ahead_var = df_test_norm_var[['diff_norm_weekaheadforecast', 'diff_norm_measured']]\n",
    "        df_week_ahead_var = df_week_ahead_var.copy()\n",
    "        df_week_ahead_var.loc[:, 'target'] = df_week_ahead_var['diff_norm_measured']\n",
    "        rmse_var_week_ahead = round(calculate_rmse(df_week_ahead_var, 'diff_norm_weekaheadforecast').values[0][0], 3)\n",
    "        lst_rmse_var_baseline_week_ahead.append(rmse_var_week_ahead)\n",
    "\n",
    "    # performance weighted average\n",
    "    df_weighted_avg, dict_weights = calculate_weighted_avg(df_train_norm_diff, df_test_norm_diff, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "    rmse_weighted_avg = round(calculate_rmse(df_weighted_avg, 'mean_prediction').values[0][0], 3)\n",
    "    lst_rmse_weighted_avg.append(rmse_weighted_avg)\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        pinball_weighted_avg = calculate_pinball_losses(df_weighted_avg, 'Q10', 'Q90')\n",
    "        pinball_weighted_avg_q10 = round(pinball_weighted_avg['pb_loss_10'].values[0], 3)\n",
    "        pinball_weighted_avg_q90 = round(pinball_weighted_avg['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_weighted_avg_q10.append(pinball_weighted_avg_q10)\n",
    "        lst_pb_weighted_avg_q90.append(pinball_weighted_avg_q90)\n",
    "    \n",
    "    # plot forecasts weighted avg\n",
    "    if ens_params['plot_weighted_avg']:\n",
    "        plot_weighted_avg_forecasts(df_weighted_avg)\n",
    "\n",
    "    # plot contribution weighted average\n",
    "    if ens_params['plot_importance_weighted_avg']:\n",
    "        for quantile in ens_params['quantiles']:\n",
    "            plot_weight_avg_contributions(dict_weights, quantile, stage='Wind Power', days = weight_avg_params['window_size_valid'])\n",
    "\n",
    "    # performance equal weights\n",
    "    df_equal_weights = calculate_equal_weights(df_test_norm_diff)\n",
    "    rmse_equal_weights = round(calculate_rmse(df_equal_weights, 'mean_prediction').values[0][0], 3)\n",
    "    lst_rmse_equal_weights.append(rmse_equal_weights)\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        pinball_equal_weights = calculate_pinball_losses(df_equal_weights, 'Q10', 'Q90')\n",
    "        pinball_equal_weights_q10 = round(pinball_equal_weights['pb_loss_10'].values[0], 3)\n",
    "        pinball_equal_weights_q90 = round(pinball_equal_weights['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_equal_weights_q10.append(pinball_equal_weights_q10)\n",
    "        lst_pb_equal_weights_q90.append(pinball_equal_weights_q90)\n",
    "\n",
    "    # performance day-ahead\n",
    "    df_dayahead = df_test_norm_diff[['diff_norm_dayaheadforecast', 'diff_norm_dayaheadconfidence10', 'diff_norm_dayaheadconfidence90', 'diff_norm_measured']]\n",
    "    df_dayahead = df_dayahead.copy()\n",
    "    df_dayahead.loc[:, 'target'] = df_dayahead['diff_norm_measured']\n",
    "    rmse_dayahead = round(calculate_rmse(df_dayahead, 'diff_norm_dayaheadforecast').values[0][0], 3)\n",
    "    lst_rmse_baseline_dayahead.append(rmse_dayahead)\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        pinball_dayahead = calculate_pinball_losses(df_dayahead, 'diff_norm_dayaheadconfidence10', 'diff_norm_dayaheadconfidence90')\n",
    "        pinball_dayahead_q10 = round(pinball_dayahead['pb_loss_10'].values[0], 3)\n",
    "        pinball_dayahead_q90 = round(pinball_dayahead['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_dayahead_q10.append(pinball_dayahead_q10)\n",
    "        lst_pb_dayahead_q90.append(pinball_dayahead_q90)\n",
    "    \n",
    "    # performance day-ahead-11h\n",
    "    df_dayahead_11h = df_test_norm_diff[['diff_norm_dayahead11hforecast', 'diff_norm_dayahead11hconfidence10', 'diff_norm_dayahead11hconfidence90', 'diff_norm_measured']]\n",
    "    df_dayahead_11h  = df_dayahead_11h .copy()\n",
    "    df_dayahead_11h.loc[:, 'target'] = df_dayahead_11h['diff_norm_measured']\n",
    "    rmse_dayahead_11h = round(calculate_rmse(df_dayahead_11h, 'diff_norm_dayahead11hforecast').values[0][0], 3)\n",
    "    lst_rmse_baseline_dayahead11h.append(rmse_dayahead_11h)\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        pinball_dayahead_11h = calculate_pinball_losses(df_dayahead_11h, 'diff_norm_dayahead11hconfidence10', 'diff_norm_dayahead11hconfidence90')\n",
    "        pinball_dayahead_11h_q10 = round(pinball_dayahead_11h['pb_loss_10'].values[0], 3)\n",
    "        pinball_dayahead_11h_q90 = round(pinball_dayahead_11h['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_dayahead_11h_q10.append(pinball_dayahead_11h_q10)\n",
    "        lst_pb_dayahead_11h_q90.append(pinball_dayahead_11h_q90)\n",
    "\n",
    "    # performance week ahead\n",
    "    df_week_ahead = df_test_norm_diff[['diff_norm_weekaheadforecast', 'diff_norm_weekaheadconfidence10', 'diff_norm_weekaheadconfidence90', 'diff_norm_measured']]\n",
    "    df_week_ahead = df_week_ahead.copy()\n",
    "    df_week_ahead.loc[:, 'target'] = df_week_ahead['diff_norm_measured']\n",
    "    rmse_week_ahead = round(calculate_rmse(df_week_ahead, 'diff_norm_weekaheadforecast').values[0][0], 3)\n",
    "    lst_rmse_baseline_week_ahead.append(rmse_week_ahead)\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        pinball_week_ahead = calculate_pinball_losses(df_week_ahead, 'diff_norm_weekaheadconfidence10', 'diff_norm_weekaheadconfidence90')\n",
    "        pinball_week_ahead_q10 = round(pinball_week_ahead['pb_loss_10'].values[0], 3)\n",
    "        pinball_week_ahead_q90 = round(pinball_week_ahead['pb_loss_90'].values[0], 3)\n",
    "        lst_pb_week_ahead_q10.append(pinball_week_ahead_q10)\n",
    "        lst_pb_week_ahead_q90.append(pinball_week_ahead_q90)\n",
    "\n",
    "    # plot forecasts\n",
    "    plot_ensemble_forecasts(df_pred_ensemble, df_test_ensemble)\n",
    "    nr_previous_days = len(pd.date_range(start=start_training_timestamp, end=end_training_timestamp, freq='1D')) - 1\n",
    "    plt.title(f'Ensemble Forecasts - Quantile {ens_params[\"model_type\"]}')\n",
    "    plot_ramp_events(df_test_norm_diff, ens_params['compute_abs_difference'])\n",
    "    if not ens_params['zoom_in_variability']:  # zoom in the variability forecasts\n",
    "        plt.ylim(-0.01, 1)\n",
    "    plt.show()\n",
    "\n",
    "    if not ens_params['compute_abs_difference']:\n",
    "        # plot variability forecast results\n",
    "        plot_var_ensemble_forecasts(df_var_ensemble, df_2stage_test)\n",
    "        nr_previous_days = len(pd.date_range(start=start_training_timestamp, end=end_training_timestamp, freq='1D')) - 1\n",
    "        plt.title(f'Ensemble Variability Forecasts - Quantile {ens_params[\"var_model_type\"]}')\n",
    "        plot_ramp_events(df_test_norm_diff, ens_params['compute_abs_difference'])\n",
    "        if not ens_params['zoom_in_variability']:  # zoom in the variability forecasts\n",
    "            plt.ylim(-0.6, 0.6)\n",
    "        plt.show()\n",
    "\n",
    "    if sim_params['display_metrics']:\n",
    "        display_forecasting_metrics(ens_params=ens_params, \n",
    "                                    rmse_ensemble=rmse_ensemble, rmse_weighted_avg=rmse_weighted_avg, rmse_equal_weights=rmse_equal_weights,\n",
    "                                    rmse_dayahead=rmse_dayahead, rmse_dayahead_11h=rmse_dayahead_11h, rmse_week_ahead=rmse_week_ahead,\n",
    "                                    pinball_ensemble_q10=pinball_ensemble_q10, pinball_weighted_avg_q10=pinball_weighted_avg_q10, pinball_equal_weights_q10=pinball_equal_weights_q10,\n",
    "                                    pinball_dayahead_q10=pinball_dayahead_q10, pinball_dayahead_11h_q10=pinball_dayahead_11h_q10, pinball_week_ahead_q10=pinball_week_ahead_q10,\n",
    "                                    pinball_ensemble_q90=pinball_ensemble_q90, pinball_weighted_avg_q90=pinball_weighted_avg_q90, pinball_equal_weights_q90=pinball_equal_weights_q90,\n",
    "                                    pinball_dayahead_q90=pinball_dayahead_q90, pinball_dayahead_11h_q90=pinball_dayahead_11h_q90, pinball_week_ahead_q90=pinball_week_ahead_q90,\n",
    "                                    rmse_var_ensemble=rmse_var_ensemble, rmse_var_weighted_avg=rmse_var_weighted_avg, rmse_var_equal_weights=rmse_var_equal_weights,\n",
    "                                    rmse_var_dayahead=rmse_var_dayahead, rmse_var_dayahead_11h=rmse_var_dayahead_11h, rmse_var_week_ahead=rmse_var_week_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "data = transform_loss_lists_to_df(lst_rmse_gbr_ensemble, lst_rmse_equal_weights, lst_rmse_weighted_avg, lst_rmse_baseline_dayahead, lst_rmse_baseline_dayahead11h, lst_rmse_baseline_week_ahead)\n",
    "avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "plot_statistical_comparison(pc, avg_rank,\n",
    "                            title1 = 'RMSE-based Statistical Significance',\n",
    "                            title2 = 'RMSE-based Statistical Comparison: critical difference diagram of ranks')\n",
    "\n",
    "if not ens_params['compute_abs_difference']:\n",
    "\n",
    "    data = transform_loss_lists_to_df(lst_pb_gbr_ensemble_q10, lst_pb_equal_weights_q10, lst_pb_weighted_avg_q10, lst_pb_dayahead_q10, lst_pb_dayahead_11h_q10, lst_pb_week_ahead_q10)\n",
    "    avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "    pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "    plot_statistical_comparison(pc, avg_rank,\n",
    "                                title1 = 'Q10 Pinball loss-based Statistical Significance',\n",
    "                                title2 = 'Q10 Pinball loss-based Statistical Comparison: critical difference diagram of ranks')\n",
    "    \n",
    "    data = transform_loss_lists_to_df(lst_pb_gbr_ensemble_q90, lst_pb_equal_weights_q90, lst_pb_weighted_avg_q90, lst_pb_dayahead_q90, lst_pb_dayahead_11h_q90, lst_pb_dayahead_11h_q90)\n",
    "    avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "    pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "    plot_statistical_comparison(pc, avg_rank,\n",
    "                                title1 = 'Q90 Pinball loss-based Statistical Significance',\n",
    "                                title2 = 'Q90 Pinball loss-based Statistical Comparison: critical difference diagram of ranks')\n",
    "    \n",
    "    data = transform_loss_lists_to_df(lst_rmse_var_gbr_ensemble, lst_rmse_var_equal_weights, lst_rmse_var_weighted_avg, lst_rmse_var_baseline_dayahead, lst_rmse_var_baseline_dayahead11h, lst_rmse_var_baseline_week_ahead)\n",
    "    avg_rank = data.groupby('days').rmse.rank(pct=True).groupby(data.model).mean()\n",
    "    pc = sp.posthoc_nemenyi_friedman(data, y_col='rmse', block_col='days', group_col='model', melted=True)\n",
    "    plot_statistical_comparison(pc, avg_rank, \n",
    "                                title1 = 'RMSE-based Statistical Significance',\n",
    "                                title2 = 'RMSE-based Statistical Comparison: critical difference diagram of ranks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
