{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from source.utils.file_read import read_csv_file, filter_data, join_dataframes, replace_nan_values\n",
    "from source.utils.collect_results import create_df_forecaster_first_stage\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.simulation.submission_module import submission_forecasters\n",
    "from source.simulation.buyer_module import prepare_buyer_data\n",
    "from source.ensemble.combination_scheme.equal_weights import calculate_equal_weights\n",
    "from source.ensemble.combination_scheme.avg_weights import calculate_weighted_avg\n",
    "from source.ensemble.combination_scheme.model_selection import run_model_selection\n",
    "from source.plots.plot_forecasts import plot_forecasts\n",
    "from source.ml_engine import create_ensemble_forecasts\n",
    "from source.simulation.helpers_simulation import process_combination_scheme\n",
    "from source.utils.session_ml_info import delete_previous_day_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "from config.simulation_setting import Simulation, WeightedAvg, Stack\n",
    "\n",
    "sim_params = Simulation.testing_period  # Simulation parameters\n",
    "weight_avg_params = WeightedAvg.params  # Weighted Average parameters\n",
    "ens_params = Stack.params  # QRA Ensemble parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(sim_params['random_seed'])\n",
    "\n",
    "# read csv file\n",
    "df_processed = read_csv_file(sim_params['csv_filename'], sim_params['list_columns'], sim_params['starting_period'], sim_params['ending_period'])\n",
    "\n",
    "# replace NaN values\n",
    "if sim_params['replace_nan']:\n",
    "    df_processed = replace_nan_values(sim_params, df_processed)\n",
    "\n",
    "# remove previous day pickle file\n",
    "logger.info(' ')\n",
    "delete_previous_day_pickle()\n",
    "\n",
    "# save csv variables\n",
    "list_csv_to_save = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    if i >= ens_params['day_calibration'] and ens_params['conformalized_qr']:\n",
    "        day_calibration = ens_params['day_calibration']\n",
    "        start_training_timestamp = start_training_timestamp - pd.Timedelta(f'{day_calibration}day')\n",
    "\n",
    "    # trimming data for training and testing\n",
    "    df_train = filter_data(df_processed, start_training_timestamp, end_training_timestamp, string = 'training')\n",
    "    df_test = filter_data(df_processed, start_prediction_timestamp, end_prediction_timestamp, string = 'testing')\n",
    "\n",
    "# # ----------------------------> FORECASTERS SUBMISSION <----------------------------\n",
    "\n",
    "    df_market, df_train, df_test = submission_forecasters(sim_params, df_train, df_test)   \n",
    "\n",
    "# # ----------------------------> MARKET OPERATOR DATA <----------------------------\n",
    "\n",
    "    df_buyer, forecast_range = prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "\n",
    "# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\n",
    "\n",
    "    results_ensemble_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                                            df_buyer=df_buyer, \n",
    "                                                            df_market=df_market,\n",
    "                                                            end_training_timestamp=end_training_timestamp,\n",
    "                                                            forecast_range = forecast_range,\n",
    "                                                            challenge_usecase='simulation',\n",
    "                                                            simulation=True)\n",
    "    \n",
    "    ## ----------------------------> SAVE to CSV <----------------------------\n",
    "    # wind power\n",
    "    df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']\n",
    "    df_pred_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_predictions', \n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_predictions', \n",
    "                                        'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "    # create dataframes\n",
    "    df_test_ensemble = pd.DataFrame(df_test['measured']) \n",
    "    df_test_ensemble.rename(columns={'measured': 'targets'}, inplace=True)\n",
    "    \n",
    "    # drop targets column\n",
    "    df_pred_ensemble_clean = df_pred_ensemble.drop(columns=['targets'], axis=1)\n",
    "\n",
    "    # list dataframes wind power\n",
    "    list_df_wind_power = [df_test, df_pred_ensemble_clean]\n",
    "\n",
    "    if sim_params['baselines_comparison']:\n",
    "\n",
    "        # # # ----------------------------> COMBINATION SCHEME DATA <----------------------------\n",
    "\n",
    "        # process data for baselines combination schemes\n",
    "        df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var = process_combination_scheme(df_train, df_test, end_training_timestamp, start_prediction_timestamp)\n",
    "        \n",
    "        # # ----------------------------> PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        ## ----------------------------> WIND POWER <----------------------------\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model = run_model_selection(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_best_model_clean = df_best_model.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_best_model_clean)\n",
    "        \n",
    "        # performance weighted average\n",
    "        df_weighted_avg, dict_weights = calculate_weighted_avg(sim_params, \n",
    "                                                            df_train_norm, \n",
    "                                                            day_previous_df_test_norm, \n",
    "                                                            end_training_timestamp, \n",
    "                                                            start_prediction_timestamp, \n",
    "                                                            window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_weighted_avg_clean = df_weighted_avg.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_weighted_avg_clean)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft, dict_weights_soft = calculate_weighted_avg(sim_params, \n",
    "                                                                        df_train_norm, \n",
    "                                                                        day_previous_df_test_norm, \n",
    "                                                                        end_training_timestamp, \n",
    "                                                                        start_prediction_timestamp, \n",
    "                                                                        window_size_valid=weight_avg_params['window_size_valid'], \n",
    "                                                                        norm='softmax')\n",
    "        df_weighted_avg_soft_clean = df_weighted_avg_soft.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_weighted_avg_soft_clean)\n",
    "        \n",
    "        # performance equal weights\n",
    "        df_equal_weights = calculate_equal_weights(day_previous_df_test_norm, start_prediction_timestamp)\n",
    "        df_equal_weights_clean = df_equal_weights.drop(columns=['targets'], axis=1)\n",
    "        list_df_wind_power.append(df_equal_weights_clean)\n",
    "\n",
    "        # performance malicious cheat\n",
    "        if sim_params['malicious']:\n",
    "            df_malicious = create_df_forecaster_first_stage(day_previous_df_test_norm, 'malicious', start_prediction_timestamp)\n",
    "            list_df_wind_power.append(df_malicious)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            df_noisy = create_df_forecaster_first_stage(day_previous_df_test_norm, 'noisy', start_prediction_timestamp)\n",
    "            list_df_wind_power.append(df_noisy)\n",
    "\n",
    "        # plot forecasts\n",
    "        if ens_params['plt_wind_power_ensemble']:\n",
    "            plot_forecasts(df_pred_ensemble, df_test_ensemble, list_wind_ramps=[], title=f'Wind Power Forecasting')\n",
    "\n",
    "    # join dataframes wind power forecasters baseline\n",
    "    df_csv_wind_power = join_dataframes(*list_df_wind_power)\n",
    "    list_csv_to_save.append(df_csv_wind_power)\n",
    "\n",
    "    #Clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # import time\n",
    "    # time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------> SAVE TO CSV <----------------------------\n",
    "# from list to dataframe\n",
    "df_csv = pd.concat(list_csv_to_save).to_csv('wp_forecasters_comparison_results_no_mostrecent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------> PLOT FORECASTS <----------------------------\n",
    "df_csv[['measured', '10_predictions', '50_predictions', '90_predictions']].iloc[:2000].plot(figsize=(20,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predico-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
