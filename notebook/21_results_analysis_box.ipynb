{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.getenv(\"PATH_CURRENT\"))\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from source.ensemble.stack_generalization.ramp_detection.utils_plot import plot_ramp_events\n",
    "from source.ensemble.stack_generalization.ramp_detection.utils_plot import plot_ramp_confusion_matrix\n",
    "\n",
    "# Set parameters\n",
    "max_consecutive_points = 3\n",
    "plot_results = 'TP'\n",
    "cluster_color = False\n",
    "k = 1.8\n",
    "q3_q1 = (0.75, 0.25)\n",
    "plot_prediction = True\n",
    "plot_iqw = False\n",
    "\n",
    "def load_and_append_results(file_paths, key_names):\n",
    "    \"\"\"\n",
    "    Load data from the provided pickle file paths and extract the required keys.\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        result_list += [{key: entry[key] for key in key_names} for entry in data]\n",
    "    return result_list\n",
    "\n",
    "def plot_heatmap(data_list, value_col, title, cmap=sns.diverging_palette(10, 133, as_cmap=True)):\n",
    "    \"\"\"\n",
    "    Converts a list of dictionaries to a DataFrame, pivots the table, and plots a heatmap.\n",
    "    \"\"\"\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df_results = pd.DataFrame(data_list)\n",
    "    # Determine column names based on value_col\n",
    "    columns = df_results.columns.tolist()\n",
    "    columns[columns.index(value_col)] = value_col\n",
    "    df_results.columns = columns\n",
    "    # Pivot table\n",
    "    df_results_pivot = df_results.pivot(index='q3_q1', columns='k', values=value_col)\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_results_pivot, annot=True, fmt=\".2f\", cmap=cmap)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_k_values = [1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8]\n",
    "str_most_recent = f'{max_consecutive_points}_consecutive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths for symmetric and asymmetric datasets\n",
    "file_paths_sym_f1 = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_f1_symmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_f1 = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_f1_asymmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_roc = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_roc_auc_asymmetric.pkl' for k in list_k_values]\n",
    "file_paths_sym_roc = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_roc_auc_symmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_cis = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_csi_asymmetric.pkl' for k in list_k_values]\n",
    "file_paths_sym_cis = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_csi_symmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_bs = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_bs_asymmetric.pkl' for k in list_k_values]\n",
    "file_paths_sym_bs = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_bs_symmetric.pkl' for k in list_k_values]\n",
    "\n",
    "list_results_sym_f1 = load_and_append_results(file_paths_sym_f1, ['q3_q1', 'k', 'f1'])\n",
    "list_results_asym_f1 = load_and_append_results(file_paths_asym_f1, ['q3_q1', 'k', 'f1'])\n",
    "list_results_asym_roc = load_and_append_results(file_paths_asym_roc, ['q3_q1', 'k', 'roc_auc'])\n",
    "list_results_sym_roc = load_and_append_results(file_paths_sym_roc, ['q3_q1', 'k', 'roc_auc'])\n",
    "list_results_asym_cis = load_and_append_results(file_paths_asym_cis, ['q3_q1', 'k', 'csi'])\n",
    "list_results_sym_cis = load_and_append_results(file_paths_sym_cis, ['q3_q1', 'k', 'csi'])\n",
    "list_results_asym_bs = load_and_append_results(file_paths_asym_bs, ['q3_q1', 'k', 'bs'])\n",
    "list_results_sym_bs = load_and_append_results(file_paths_sym_bs, ['q3_q1', 'k', 'bs'])\n",
    "\n",
    "plot_heatmap(list_results_sym_f1, 'f1', 'F1 Score - Symmetric - DAY')\n",
    "plot_heatmap(list_results_asym_f1, 'f1', 'F1 Score - Asymmetric - DAY')\n",
    "plot_heatmap(list_results_sym_roc, 'roc_auc', 'ROC AUC - Symmetric - DAY')\n",
    "plot_heatmap(list_results_asym_roc, 'roc_auc', 'ROC AUC - Asymmetric - DAY')\n",
    "plot_heatmap(list_results_sym_cis, 'csi', 'CSI - Symmetric - DAY')\n",
    "plot_heatmap(list_results_asym_cis, 'csi', 'CSI - Asymmetric - DAY')\n",
    "plot_heatmap(list_results_sym_bs, 'bs', 'Bias Score - Symmetric - DAY', cmap=sns.diverging_palette(133, 10, as_cmap=True))\n",
    "plot_heatmap(list_results_asym_bs, 'bs', 'Bias Score - Asymmetric - DAY', cmap=sns.diverging_palette(133, 10, as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths for symmetric and asymmetric datasets\n",
    "file_paths_sym_f1 = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_f1_symmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_f1 = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_f1_asymmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_roc = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_roc_auc_asymmetric.pkl' for k in list_k_values]\n",
    "file_paths_sym_roc = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_roc_auc_symmetric.pkl' for k in list_k_values]\n",
    "file_paths_sym_cis = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_csi_symmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_cis = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_csi_asymmetric.pkl' for k in list_k_values]\n",
    "file_paths_sym_bs = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_bs_symmetric.pkl' for k in list_k_values]\n",
    "file_paths_asym_bs = [f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_bs_asymmetric.pkl' for k in list_k_values]\n",
    "\n",
    "list_results_sym_f1 = load_and_append_results(file_paths_sym_f1, ['q3_q1', 'k', 'f1_intraday'])\n",
    "list_results_asym_f1 = load_and_append_results(file_paths_asym_f1, ['q3_q1', 'k', 'f1_intraday'])\n",
    "list_results_asym_roc = load_and_append_results(file_paths_asym_roc, ['q3_q1', 'k', 'roc_auc_intraday'])\n",
    "list_results_sym_roc = load_and_append_results(file_paths_sym_roc, ['q3_q1', 'k', 'roc_auc_intraday'])\n",
    "list_results_asym_cis = load_and_append_results(file_paths_asym_cis, ['q3_q1', 'k', 'csi_intraday'])\n",
    "list_results_sym_cis = load_and_append_results(file_paths_sym_cis, ['q3_q1', 'k', 'csi_intraday'])\n",
    "list_results_asym_bs = load_and_append_results(file_paths_asym_bs, ['q3_q1', 'k', 'bs_intraday'])\n",
    "list_results_sym_bs = load_and_append_results(file_paths_sym_bs, ['q3_q1', 'k', 'bs_intraday'])\n",
    "\n",
    "plot_heatmap(list_results_sym_f1, 'f1_intraday', 'F1 Score - Symmetric - INTRADAY')\n",
    "plot_heatmap(list_results_asym_f1, 'f1_intraday', 'F1 Score - Asymmetric - INTRADAY')\n",
    "plot_heatmap(list_results_sym_roc, 'roc_auc_intraday', 'ROC AUC - Symmetric - INTRADAY')\n",
    "plot_heatmap(list_results_asym_roc, 'roc_auc_intraday', 'ROC AUC - Asymmetric - INTRADAY')\n",
    "plot_heatmap(list_results_sym_cis, 'csi_intraday', 'CSI - Symmetric - INTRADAY')\n",
    "plot_heatmap(list_results_asym_cis, 'csi_intraday', 'CSI - Asymmetric - INTRADAY')\n",
    "plot_heatmap(list_results_sym_bs, 'bs_intraday', 'Bias Score - Symmetric - INTRADAY', cmap=sns.diverging_palette(133, 10, as_cmap=True))\n",
    "plot_heatmap(list_results_asym_bs, 'bs_intraday', 'Bias Score - Asymmetric - INTRADAY', cmap=sns.diverging_palette(133, 10, as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_q1 = (0.775, 0.5)\n",
    "k = 1.4\n",
    "\n",
    "\n",
    "# Load results for F1 scores\n",
    "with open(f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_f1_asymmetric.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Retrieve ramp events by date\n",
    "ramp_events_by_date = [data[i]['ramp_events_by_intraday'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "\n",
    "# Plot confusion matrix\n",
    "f1, roc_auc, cis, bs, fpr, tpr = plot_ramp_confusion_matrix(ramp_events_by_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_q1 = (0.775, 0.5)\n",
    "k = 1.4\n",
    "\n",
    "# Load results for F1 scores\n",
    "with open(f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_f1_asymmetric.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Retrieve ramp events by date\n",
    "ramp_events_by_intraday = [data[i]['ramp_events_by_intraday'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "\n",
    "from config.ramp_calib_setting import Simulation\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from loguru import logger\n",
    "from source.utils.file_read import process_and_concat_files \n",
    "\n",
    "sim_params = Simulation.testing_period\n",
    "\n",
    "# process and concatenate files\n",
    "files = [sim_params['file_1'], sim_params['file_2'], sim_params['file_3'], sim_params['file_4'], \n",
    "            sim_params['file_5'], sim_params['file_6'], sim_params['file_7'], sim_params['file_8'], \n",
    "            sim_params['file_9'], sim_params['file_10'], sim_params['file_11'], sim_params['file_12']]\n",
    "\n",
    "df = process_and_concat_files(files)\n",
    "df_variability = abs(df['measured'].diff()).to_frame()\n",
    "\n",
    "# add true positive if \"predicted\" == 1 and \"ramp_event\"==1\n",
    "ramp_events_by_intraday['tp'] = (ramp_events_by_intraday['predicted_ramps'] == 1) & (ramp_events_by_intraday['ramp_events'] == 1)\n",
    "# add false positive if \"predicted\" == 1 and \"ramp_event\"==0\n",
    "ramp_events_by_intraday['fp'] = (ramp_events_by_intraday['predicted_ramps'] == 1) & (ramp_events_by_intraday['ramp_events'] == 0)\n",
    "# add true negative if \"predicted\" == 0 and \"ramp_event\"==0\n",
    "ramp_events_by_intraday['tn'] = (ramp_events_by_intraday['predicted_ramps'] == 0) & (ramp_events_by_intraday['ramp_events'] == 0)\n",
    "# add false negative if \"predicted\" == 0 and \"ramp_event\"==1\n",
    "ramp_events_by_intraday['fn'] = (ramp_events_by_intraday['predicted_ramps'] == 0) & (ramp_events_by_intraday['ramp_events'] == 1)\n",
    "\n",
    "# groupby 8-hours and compute mean\n",
    "df_variability_intraday = df_variability.groupby(pd.Grouper(freq='8h')).mean()\n",
    "\n",
    "# # join with ramp_events_by_date by datetime on ramp_events_by_date\n",
    "ramp_events_by_intraday = ramp_events_by_intraday.set_index('datetime')\n",
    "\n",
    "df_variability_intraday = df_variability_intraday.join(ramp_events_by_intraday, how='inner')\n",
    "\n",
    "# stack plot boxplot of variability by ramp event for true positive, false positive, true negative, false negative\n",
    "df_variability_tp = df_variability_intraday[df_variability_intraday['tp'] == True]\n",
    "df_variability_fp = df_variability_intraday[df_variability_intraday['fp'] == True]\n",
    "df_variability_tn = df_variability_intraday[df_variability_intraday['tn'] == True]\n",
    "df_variability_fn = df_variability_intraday[df_variability_intraday['fn'] == True]\n",
    "\n",
    "df_variability_tp = df_variability_tp[['measured']]\n",
    "df_variability_fp = df_variability_fp[['measured']]\n",
    "df_variability_tn = df_variability_tn[['measured']]\n",
    "df_variability_fn = df_variability_fn[['measured']]\n",
    "\n",
    "df_variability_tp['type'] = 'TP'\n",
    "df_variability_fp['type'] = 'FP'\n",
    "df_variability_tn['type'] = 'TN'\n",
    "df_variability_fn['type'] = 'FN'\n",
    "\n",
    "df_variability = pd.concat([df_variability_tp, df_variability_fp, df_variability_tn, df_variability_fn])\n",
    "\n",
    "# plot bar chart with standard error\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.boxplot(x='type', y='measured', data=df_variability, whis=1.5)\n",
    "plt.ylabel('Measured Variability')\n",
    "plt.xlabel('Confusion Matrix Outcame')\n",
    "plt.title('Measured Variability by Confusion Matrix Outcame')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_q1 = (0.775, 0.5)\n",
    "k = 1.4\n",
    "\n",
    "# Load results for F1 scores\n",
    "with open(f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_f1_asymmetric.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Retrieve ramp events by date\n",
    "ramp_events_by_intraday = [data[i]['ramp_events_by_intraday'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "# Retrieve ramp alarm days\n",
    "list_ramp_alarm_days = [data[i]['alarms_days'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "\n",
    "from config.ramp_calib_setting import Simulation\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from loguru import logger\n",
    "from source.utils.file_read import process_and_concat_files \n",
    "\n",
    "sim_params = Simulation.testing_period\n",
    "\n",
    "sim_params = Simulation.testing_period\n",
    "\n",
    "# process and concatenate files\n",
    "files = [sim_params['file_1'], sim_params['file_2'], sim_params['file_3'], sim_params['file_4'], \n",
    "            sim_params['file_5'], sim_params['file_6'], sim_params['file_7'], sim_params['file_8'], \n",
    "            sim_params['file_9'], sim_params['file_10'], sim_params['file_11'], sim_params['file_12']]\n",
    "\n",
    "df = process_and_concat_files(files)\n",
    "df_variability = df['measured'].diff().to_frame()\n",
    "\n",
    "# add true positive if \"predicted\" == 1 and \"ramp_event\"==1\n",
    "ramp_events_by_intraday['tp'] = (ramp_events_by_intraday['predicted_ramps'] == 1) & (ramp_events_by_intraday['ramp_events'] == 1)\n",
    "# add false positive if \"predicted\" == 1 and \"ramp_event\"==0\n",
    "ramp_events_by_intraday['fp'] = (ramp_events_by_intraday['predicted_ramps'] == 1) & (ramp_events_by_intraday['ramp_events'] == 0)\n",
    "# add true negative if \"predicted\" == 0 and \"ramp_event\"==0\n",
    "ramp_events_by_intraday['tn'] = (ramp_events_by_intraday['predicted_ramps'] == 0) & (ramp_events_by_intraday['ramp_events'] == 0)\n",
    "# add false negative if \"predicted\" == 0 and \"ramp_event\"==1\n",
    "ramp_events_by_intraday['fn'] = (ramp_events_by_intraday['predicted_ramps'] == 0) & (ramp_events_by_intraday['ramp_events'] == 1)\n",
    "\n",
    "# groupby 8-hours and compute max and min\n",
    "df_variability_intraday_max = df_variability.groupby(pd.Grouper(freq='8h')).agg({'measured': 'max'})\n",
    "df_variability_intraday_min = df_variability.groupby(pd.Grouper(freq='8h')).agg({'measured': 'min'})\n",
    "df_variability_intraday_max_min = df_variability_intraday_max.join(df_variability_intraday_min, lsuffix='_max', rsuffix='_min')\n",
    "\n",
    "# # join with ramp_events_by_date by datetime on ramp_events_by_date\n",
    "ramp_events_by_intraday = ramp_events_by_intraday.set_index('datetime')\n",
    "\n",
    "df_variability_intraday = df_variability_intraday_max_min.join(ramp_events_by_intraday, how='inner')\n",
    "\n",
    "df_variability_intraday['measured'] = df_variability_intraday.apply(lambda x: x['measured_max'] if abs(x['measured_max']) > abs(x['measured_min']) else x['measured_min'], axis=1)\n",
    "\n",
    "# stack plot boxplot of variability by ramp event for true positive, false positive, true negative, false negative\n",
    "df_variability_tp = df_variability_intraday[df_variability_intraday['tp'] == True]\n",
    "\n",
    "# concatenate all list_ramp_alarm_days[i][0] for i in range(len(list_ramp_alarm_days))\n",
    "list_ramp = [list_ramp_alarm_days[i][0] for i in range(len(list_ramp_alarm_days))]\n",
    "df_is_anomalous = pd.concat([list_ramp_alarm_days[i][0] for i in range(len(list_ramp_alarm_days))])\n",
    "df_is_anomalous = df_is_anomalous[df_is_anomalous['is_anomalous'] == True]\n",
    "# get max Q90 and min Q10 for each 8-hour period\n",
    "df_all = df_is_anomalous.groupby(pd.Grouper(freq='8h')).agg({'Q90': 'max', 'Q10': 'min'})\n",
    "df_dropna = df_all.dropna()\n",
    "# join df_variability_tp and df_dropna by datetime on df_variability_tp\n",
    "df_variability_tp = df_variability_tp.join(df_dropna, how='inner')\n",
    "df_variability_tp['direction'] = df_variability_tp.apply(lambda x: 'up' if abs(x['Q90']) > abs(x['Q10']) else 'down', axis=1) \n",
    "# if \"measured\" is positive and \"direction\" is \"up\" or \"measured\" is negative and \"direction\" is \"down\" then \"correct\" is True\n",
    "df_variability_tp['correct'] = (df_variability_tp['measured'] > 0) & (df_variability_tp['direction'] == 'up') | (df_variability_tp['measured'] < 0) & (df_variability_tp['direction'] == 'down')\n",
    "# count in percentage the number of correct predictions\n",
    "df_variability_tp['correct'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve ramp events by date\n",
    "ramp_events_by_date = [data[i]['ramp_events_by_date'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "# Retrieve ramp alarm days\n",
    "list_ramp_alarm_days = [data[i]['alarms_days'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "# Retrieve ramp threshold\n",
    "ramp_threshold = [data[i]['ramp_threshold'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "\n",
    "# Load results for ROC AUC scores\n",
    "with open(f'/Users/gio/Desktop/Elia-RES-Forecasting/results/box/{str_most_recent}/{max_consecutive_points}_{k}_roc_auc_asymmetric.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Retrieve ROC AUC score\n",
    "roc_auc = [data[i]['roc_auc'] for i in range(len(data)) if data[i]['q3_q1'] == q3_q1][0]\n",
    "\n",
    "df_ramp_events_detected, list_mean_distance = plot_ramp_events(ramp_events_by_date, \n",
    "                                                            list_ramp_alarm_days, \n",
    "                                                            ramp_threshold, \n",
    "                                                            plot_results=plot_results, \n",
    "                                                            max_consecutive_points=max_consecutive_points, \n",
    "                                                            plot_prediction=plot_prediction, \n",
    "                                                            plot_iqw=plot_iqw, \n",
    "                                                            cluster_color = cluster_color,\n",
    "                                                            intraday=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(list_mean_distance) !=0:\n",
    "    df_distance = pd.DataFrame(list_mean_distance)\n",
    "    df_distance.columns = ['mean_distance_per_day', 'num_ramp', 'num_clusters']\n",
    "    print(' ')\n",
    "    print(df_distance)\n",
    "    print('')\n",
    "    print('Intraday Analysis: 8-hours time window')\n",
    "    print('Error Phase', df_distance['mean_distance_per_day'].mean())\n",
    "    print('Tot Number of Ramps Detected', df_distance['num_clusters'].sum())\n",
    "    print('Tot Number of Ramps Observed', df_distance['num_ramp'].sum())\n",
    "    # number of days with at least one ramp event\n",
    "    print('Number of days with at least one ramp event', len(df_distance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ramp_events_detected[0][0]\n",
    "\n",
    "#insert a new column with \"up\" if abs(Q90) > abs(Q10) and \"down\" otherwise\n",
    "df['direction'] = df.apply(lambda x: 'up' if abs(x['Q90']) > abs(x['Q10']) else 'down', axis=1) \n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
