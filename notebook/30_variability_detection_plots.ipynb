{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append(os.getenv(\"PATH_CURRENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from source.utils.file_read import process_and_concat_files \n",
    "from source.utils.file_read import filter_df\n",
    "from source.simulation.submission_module import submission_forecasters\n",
    "from source.simulation.buyer_module import prepare_buyer_data\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.ml_engine import create_ensemble_forecasts\n",
    "from source.simulation.helpers_simulation import process_combination_scheme\n",
    "from source.ensemble.stack_generalization.ramp_detection.boxplot_detector import detect_wind_ramp_boxplot\n",
    "from source.ensemble.stack_generalization.ramp_detection.lof_detector import detect_wind_ramp_lof\n",
    "from source.ensemble.stack_generalization.ramp_detection.kde_detector import detect_wind_ramp_kde\n",
    "from source.ensemble.stack_generalization.ramp_detection.eq_detector import detect_wind_ramp_eq\n",
    "from source.ensemble.stack_generalization.ramp_detection.utils import process_ramp_events\n",
    "\n",
    "from source.plots.plot_forecasts import plot_forecasts, plot_var_forecasts, plot_ramp_detection\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.ramp_calib_setting import Simulation, WeightedAvg, Stack\n",
    "from source.utils.session_ml_info import delete_previous_day_pickle\n",
    "sim_params = Simulation.testing_period\n",
    "weight_avg_params = WeightedAvg.params\n",
    "ens_params = Stack.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_wind_ramp_events_day(df, list_ramp_alarm, i):\n",
    "    \"\"\"\n",
    "    Checks for wind ramp events in a specific day and returns their occurrences.\n",
    "    \"\"\"\n",
    "    # Get the datetime from the ramp alarm list\n",
    "    datetime = list_ramp_alarm[i][0]\n",
    "    # Process ramp events and get the updated dataframe and threshold\n",
    "    df, _ = process_ramp_events(df)\n",
    "    # Filter the dataframe for measurements within the specific day\n",
    "    df_day_measurements = df.loc[datetime : datetime + pd.Timedelta(days=1)]\n",
    "    # Check if there are any wind ramp events for the day\n",
    "    wind_ramp = df_day_measurements['ramp_events'].sum() > 0\n",
    "    # If wind ramp events exist, get their indices\n",
    "    list_wind_ramps = []\n",
    "    if wind_ramp:\n",
    "        list_wind_ramps = df_day_measurements[df_day_measurements['ramp_events'] == 1].index.tolist()\n",
    "    return list_wind_ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_stacked_bar_chart(df_pivot, title):\n",
    "    \"\"\"\n",
    "    Plots a stacked bar chart using the provided pivot DataFrame.\n",
    "    \"\"\"\n",
    "    # Plot the stacked bar chart\n",
    "    df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "    plt.xlabel('Key and Quantile')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f\"Stacked Bar Chart of {title} Contributions\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_heatmap(df_pivot, title):\n",
    "    \"\"\"\n",
    "    Plots a heatmap using the provided pivot DataFrame.\n",
    "    \"\"\"\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "    plt.xlabel('Series')\n",
    "    plt.ylabel('Key and Quantile')\n",
    "    plt.title(f\"Heatmap of {title} Contributions\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-15 14:58:22.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:22.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mLoad Files: ['/Users/gio/Desktop/elia_group/dataset_elia/2023/01.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/02.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/03.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/04.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/05.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/06.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/07.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/08.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/09.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/10.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/11.json', '/Users/gio/Desktop/elia_group/dataset_elia/2023/12.json']\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[33m\u001b[1mReplacing NaN values with 0s\u001b[0m\n",
      "/var/folders/k7/l3pjpdtn7fg19hrh291yqwjw0000gn/T/ipykernel_10483/2267389280.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.fillna(0, inplace=True)\n",
      "\u001b[32m2024-10-15 14:58:23.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[33m\u001b[1mprevious day pickle file removed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measured                    22\n",
      "mostrecentforecast           0\n",
      "dayahead11hforecast          0\n",
      "dayaheadforecast             0\n",
      "weekaheadforecast          288\n",
      "mostrecentconfidence10       0\n",
      "dayahead11hconfidence10     96\n",
      "dayaheadconfidence10         0\n",
      "weekaheadconfidence10      288\n",
      "mostrecentconfidence90       0\n",
      "dayahead11hconfidence90     96\n",
      "dayaheadconfidence90         0\n",
      "weekaheadconfidence90      288\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Days:   0%|          | 0/300 [00:00<?, ?it/s]\u001b[32m2024-10-15 14:58:23.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1m\u001b[34m-------------------------------------------------------------------------------------------\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1m\u001b[34mStart training: 2023-10-08 00:00:00+00:00 - End training: 2023-11-07 00:00:00+00:00\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1m\u001b[34m-------------------------------------------------------------------------------------------\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m\u001b[34mStart prediction: 2023-11-08 00:00:00+00:00 - End prediction: 2023-11-09 00:00:00+00:00\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1m\u001b[34m -----------------> Length of training data: 2880 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1m\u001b[34m -----------------> Length of test data: 192 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1m\u001b[34m -----------------> Forecasters prediction submitted \u001b[0m\u001b[1m\u001b[0m\n",
      "/Users/gio/Desktop/Elia-RES-forecasting/source/simulation/buyer_module.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_buyer = pd.concat([df_train_buyer, df_test_buyer], axis=0)\n",
      "\u001b[32m2024-10-15 14:58:23.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m PREDICO Machine Learning Engine \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Launch Time from 2023-11-07 00:00:00+00:00 \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Predictions from 2023-11-08 00:00:00+00:00 to 2023-11-09 00:00:00+00:00 \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Buyer Resource Name: b1r1 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mbuyer_scaler_statistics\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Mean Buyer: 1236.9101840277779 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mbuyer_scaler_statistics\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Std Buyer: 774.3443470821472 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mbuyer_scaler_statistics\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Collecting forecasters prediction for ensemble learning - model: LR \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1m  \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Forecasters Ensemble DataFrame \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mscale_forecasters_dataframe\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mscale_forecasters_dataframe\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Standardize DataFrame \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.utils.data_preprocess\u001b[0m:\u001b[36mscale_forecasters_dataframe\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m -- Add quantile predictions \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Augment DataFrame \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m -- Augment quantile predictions \u001b[0m\u001b[1m\u001b[0m\n",
      "/Users/gio/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/data_preparation/data_train_test.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_ensemble.loc[:, 'norm_targ'] = df_train[col_name_buyer].values[max_lag:]\n",
      "/Users/gio/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/data_preparation/data_train_test.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_ensemble.loc[:, 'norm_targ'] = df_test[col_name_buyer].values\n",
      "/Users/gio/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/data_preparation/data_train_test.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_ensemble_pre.loc[:, 'norm_targ'] = df_test_targ_pre['norm_' + buyer_name].values\n",
      "\u001b[32m2024-10-15 14:58:23.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Train and Test Dataframes \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mLength of Train DataFrame: 2877\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mLength of Test DataFrame: 96\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Iteration 0 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ml_engine\u001b[0m:\u001b[36mcreate_ensemble_forecasts\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Compute Ensemble Predictions \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ensemble.stack_generalization.ensemble_model\u001b[0m:\u001b[36mpredico_ensemble_predictions_per_quantile\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1m   \u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ensemble.stack_generalization.ensemble_model\u001b[0m:\u001b[36mpredico_ensemble_predictions_per_quantile\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Run ensemble predictions for quantile 0.1 \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ensemble.stack_generalization.ensemble_model\u001b[0m:\u001b[36mpredico_ensemble_predictions_per_quantile\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Augmenting training and testing data with quantiles \u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[32m2024-10-15 14:58:23.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msource.ensemble.stack_generalization.ensemble_model\u001b[0m:\u001b[36mpredico_ensemble_predictions_per_quantile\u001b[0m:\u001b[36m93\u001b[0m - \u001b[1m\u001b[38;2;250;128;114m Optimizing model hyperparameters - updating every 15 days\u001b[0m\u001b[1m\u001b[0m\n",
      "/Users/gio/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/hyperparam_optimization/models/quantile_lr.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  best_score=np.exp(1000000)\n",
      "Quantile Regression:   0%|          | 0/3 [00:08<?, ?it/s]\n",
      "Testing Days:   0%|          | 0/300 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 75\u001b[0m\n\u001b[1;32m     69\u001b[0m     df_buyer, forecast_range \u001b[38;5;241m=\u001b[39m prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     results_predico_forecasts \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ensemble_forecasts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mens_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mens_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mdf_buyer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_buyer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mdf_market\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_market\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mend_training_timestamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_training_timestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mforecast_range\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mforecast_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mchallenge_usecase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msimulation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# # ----------------------------> TARGET VARIABILITY<----------------------------\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var \u001b[38;5;241m=\u001b[39m process_combination_scheme(df_train, df_test, end_training_timestamp, day_previous_start_prediction_timestamp)\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-forecasting/source/ml_engine.py:176\u001b[0m, in \u001b[0;36mcreate_ensemble_forecasts\u001b[0;34m(ens_params, df_buyer, df_market, end_training_timestamp, forecast_range, challenge_usecase, simulation)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# # for conformalized quantile regression\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# if ens_params['conformalized_qr']:\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m#     conformalized_qr = {}\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Loop over quantiles\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m quantile \u001b[38;5;129;01min\u001b[39;00m tqdm(ens_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantiles\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantile Regression\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Run ensemble learning\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     results_per_quantile_wp \u001b[38;5;241m=\u001b[39m \u001b[43mpredico_ensemble_predictions_per_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mens_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mens_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_ensemble\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mbest_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mX_train_quantile10\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_quantile10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_quantile10\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_quantile10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mdf_train_ensemble_quantile10\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_ensemble_quantile10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mX_train_quantile90\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_quantile90\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_quantile90\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_quantile90\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mdf_train_ensemble_quantile90\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train_ensemble_quantile90\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m results_per_quantile_wp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/ensemble_model.py:94\u001b[0m, in \u001b[0;36mpredico_ensemble_predictions_per_quantile\u001b[0;34m(ens_params, X_train, X_test, y_train, df_train_ensemble, predictions, quantile, best_results, iteration, X_train_quantile10, X_test_quantile10, df_train_ensemble_quantile10, X_train_quantile90, X_test_quantile90, df_train_ensemble_quantile90)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m%\u001b[39m gbr_update_every_days \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Optimize hyperparameters every gbr_update_every_days\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     logger\u001b[38;5;241m.\u001b[39mopt(colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<fg 250,128,114> Optimizing model hyperparameters - updating every \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgbr_update_every_days\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m days</fg 250,128,114>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m     best_score, best_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_augmented\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mnr_cv_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgbr_config_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mlr_config_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     best_results[quantile] \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m, best_score), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m, best_params)]\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/hyperparam_optimization/optimization.py:13\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m(X_train, y_train, quantile, nr_cv_splits, model_type, solver, gbr_config_params, lr_config_params)\u001b[0m\n\u001b[1;32m     11\u001b[0m     best_score, best_params \u001b[38;5;241m=\u001b[39m optimize_gbr(X_train, y_train, quantile, nr_cv_splits, gbr_config_params)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     best_score, best_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnr_cv_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_config_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not valid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/hyperparam_optimization/models/quantile_lr.py:29\u001b[0m, in \u001b[0;36moptimize_lr\u001b[0;34m(X_train, y_train, quantile, nr_cv_splits, solver, params)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     lr \u001b[38;5;241m=\u001b[39m QuantileRegressor(quantile\u001b[38;5;241m=\u001b[39mquantile, solver\u001b[38;5;241m=\u001b[39msolver, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlr_params)\n\u001b[0;32m---> 29\u001b[0m mean_cv_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean_cv_score \u001b[38;5;241m<\u001b[39m best_score:\n\u001b[1;32m     31\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m mean_cv_score\n",
      "File \u001b[0;32m~/Desktop/Elia-RES-forecasting/source/ensemble/stack_generalization/hyperparam_optimization/models/utils/cross_validation.py:38\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, X, y, cv, quantile)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m quantile \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.9\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid quantile value. Must be 0.1, 0.5, or 0.9.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m score_func \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0.1\u001b[39m: score_func_10,\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;241m0.5\u001b[39m: score_func_50,\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;241m0.9\u001b[39m: score_func_90}\n\u001b[0;32m---> 38\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_func\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m score_mean \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mean_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score_mean\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/elia/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/elia/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/elia/lib/python3.9/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/elia/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/elia/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/elia/lib/python3.9/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set random seed\n",
    "np.random.seed(sim_params['random_seed'])\n",
    "\n",
    "# process and concatenate files\n",
    "files = [sim_params['file_1'], sim_params['file_2'], sim_params['file_3'], sim_params['file_4'], \n",
    "            sim_params['file_5'], sim_params['file_6'], sim_params['file_7'], sim_params['file_8'], \n",
    "            sim_params['file_9'], sim_params['file_10'], sim_params['file_11'], sim_params['file_12']]\n",
    "logger.info(' ')\n",
    "logger.info(f'Load Files: {files}')\n",
    "\n",
    "df = process_and_concat_files(files)\n",
    "\n",
    "# filter data forecasters\n",
    "df_filtered = filter_df(df, sim_params['forecasts_col'], sim_params['measured_col'])\n",
    "\n",
    "# replace NaN values\n",
    "if sim_params['replace_nan']:\n",
    "    logger.info(' ')\n",
    "    logger.warning(\"Replacing NaN values with 0s\")\n",
    "    print(df_filtered.isna().sum())\n",
    "    df_filtered.fillna(0, inplace=True)\n",
    "\n",
    "# set buyer resource name\n",
    "buyer_resource_name = 'b1r1'\n",
    "\n",
    "# remove previous day pickle file\n",
    "logger.info(' ')\n",
    "delete_previous_day_pickle()\n",
    "logger.opt(colors = True).warning('previous day pickle file removed')\n",
    "\n",
    "# Collect Ramp Alarm\n",
    "list_ramp_alarm = []\n",
    "# Collect Intraday Ramp Alarm\n",
    "list_ramp_alarm_intraday = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    if i >= 5:\n",
    "        day_calibration = 5\n",
    "        start_training_timestamp = start_training_timestamp - pd.Timedelta('5day')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors=True).info(f'<blue>Start training: {start_training_timestamp} - End training: {end_training_timestamp}</blue>')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors = True).info(f'<blue>Start prediction: {start_prediction_timestamp} - End prediction: {end_prediction_timestamp}</blue>')\n",
    "\n",
    "    day_previous_start_prediction_timestamp = start_prediction_timestamp - pd.Timedelta('1day')\n",
    "    df_train = df_filtered[df_filtered.index.to_series().between(start_training_timestamp, end_training_timestamp)].iloc[:-1,:]\n",
    "    df_test = df_filtered[df_filtered.index.to_series().between(day_previous_start_prediction_timestamp, end_prediction_timestamp)].iloc[:-1,:]\n",
    "                                                                                                                            \n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of training data: {len(df_train)} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of test data: {len(df_test)} </blue>')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue> -----------------> Forecasters prediction submitted </blue>')\n",
    "\n",
    "# # ----------------------------> FORECASTERS PREDICTION SUBMISSION <----------------------------\n",
    "\n",
    "    df_market, df_train, df_test = submission_forecasters(sim_params, df_train, df_test)  \n",
    "\n",
    "# # ----------------------------> target DATA <----------------------------\n",
    "\n",
    "    df_buyer, forecast_range = prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "\n",
    "# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\n",
    "\n",
    "    results_predico_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                                            df_buyer=df_buyer, \n",
    "                                                            df_market=df_market,\n",
    "                                                            end_training_timestamp=end_training_timestamp,\n",
    "                                                            forecast_range = forecast_range,\n",
    "                                                            challenge_usecase='simulation',\n",
    "                                                            simulation=True)\n",
    "    \n",
    "    # # ----------------------------> TARGET VARIABILITY<----------------------------\n",
    "    df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var = process_combination_scheme(df_train, df_test, end_training_timestamp, day_previous_start_prediction_timestamp)\n",
    "\n",
    "    df_pred_plot = results_predico_forecasts['wind_power']['predictions']\n",
    "    df_pred_plot.rename(columns={'q50_' + 'b1r1': '50_predictions', 'q10_' + 'b1r1': '10_predictions', 'q90_' + 'b1r1': '90_predictions'}, inplace=True)\n",
    "    df_test_plot = pd.DataFrame(day_previous_df_test_norm['norm_measured'].iloc[-96:])\n",
    "    df_test_plot.columns = ['targets']\n",
    "\n",
    "    df_pred_var_plot = results_predico_forecasts['wind_power_ramp']['predictions'][['q50_b1r1', 'q10_b1r1', 'q90_b1r1']]\n",
    "    df_pred_var_plot.rename(columns={'q50_' + 'b1r1': '50_var_predictions', 'q10_' + 'b1r1': '10_var_predictions', 'q90_' + 'b1r1': '90_var_predictions'}, inplace=True)\n",
    "    df_test_var_plot = pd.DataFrame(day_previous_df_test_norm_var['norm_measured'].iloc[-96:])\n",
    "    df_test_var_plot.columns = ['targets']\n",
    "\n",
    "    # drop 'norm_measured' column\n",
    "    df_train_norm = df_train_norm.drop(columns=['norm_measured'])\n",
    "    day_previous_df_test_norm = day_previous_df_test_norm.drop(columns=['norm_measured'])\n",
    "\n",
    "    # get last 96 values of the day_previous_df_test_norm\n",
    "    df_test_norm = day_previous_df_test_norm.iloc[-96:]\n",
    "    target_variability = day_previous_df_test_norm_var['norm_measured'].values[-96:]\n",
    "\n",
    "    # Predictions Insample and Outsample retrieved from the ensemble forecasts\n",
    "    pred_var_insample = results_predico_forecasts['wind_power_ramp']['predictions_insample']\n",
    "    pred_var_outsample = results_predico_forecasts['wind_power_ramp']['predictions_outsample']\n",
    "\n",
    "    # set params for ramp detection\n",
    "    preprocess_ramps = ens_params['preprocess_ramps']\n",
    "    max_consecutive_points = ens_params['max_consecutive_points']\n",
    "\n",
    "    # Wind Ramp Detection using Boxplot technique\n",
    "    if ens_params['detector'] == 'box':\n",
    "        list_ramp_alarm, alarm_status, upper_box_bound, df_ramp_clusters = detect_wind_ramp_boxplot(pred_insample = pred_var_insample, \n",
    "                                                                                                    pred_outsample = pred_var_outsample, \n",
    "                                                                                                    forecast_range=forecast_range, \n",
    "                                                                                                    list_ramp_alarm = list_ramp_alarm, \n",
    "                                                                                                    df_train = df_train, \n",
    "                                                                                                    q1 = ens_params['q1_box'], \n",
    "                                                                                                    q3 = ens_params['q3_box'], \n",
    "                                                                                                    k = ens_params['k_box'], \n",
    "                                                                                                    preprocess_ramps = preprocess_ramps,\n",
    "                                                                                                    max_consecutive_points = max_consecutive_points)\n",
    "    # Wind Ramp Detection using KDE technique\n",
    "    if ens_params['detector'] == 'kde':\n",
    "        list_ramp_alarm, alarm_status, df_ramp_clusters = detect_wind_ramp_kde(df_train = df_train,\n",
    "                                                                                df_insample = pred_var_insample, \n",
    "                                                                                df_outsample = pred_var_outsample, \n",
    "                                                                                forecast_range=forecast_range, \n",
    "                                                                                list_ramp_alarm = list_ramp_alarm, \n",
    "                                                                                threshold_quantile = ens_params['threshold_quantile_kde'],\n",
    "                                                                                preprocess_ramps = preprocess_ramps,\n",
    "                                                                                cv_folds = ens_params['cv_folds_kde'],\n",
    "                                                                                max_consecutive_points = max_consecutive_points)\n",
    "    # Wind Ramp Detection using EQ technique\n",
    "    if ens_params['detector'] == 'eq':\n",
    "        list_ramp_alarm, list_ramp_alarm_intraday, alarm_status, df_ramp_clusters = detect_wind_ramp_eq(df_train = df_train,\n",
    "                                                                                                        df_insample = pred_var_insample, \n",
    "                                                                                                        df_outsample = pred_var_outsample,\n",
    "                                                                                                        list_ramp_alarm = list_ramp_alarm, \n",
    "                                                                                                        threshold_quantile = ens_params['threshold_quantile_eq'],\n",
    "                                                                                                        list_ramp_alarm_intraday = list_ramp_alarm_intraday,\n",
    "                                                                                                        preprocess_ramps = preprocess_ramps,\n",
    "                                                                                                        max_consecutive_points = max_consecutive_points)\n",
    "    # Wind Ramp Detection using LOF technique\n",
    "    if ens_params['detector'] == 'lof':\n",
    "        list_ramp_alarm, alarm_status, df_ramp_clusters = detect_wind_ramp_lof(pred_insample = pred_var_insample, \n",
    "                                                                                    pred_outsample = pred_var_outsample,\n",
    "                                                                                    df_train_norm = df_train_norm, \n",
    "                                                                                    df_test_norm = df_test_norm, \n",
    "                                                                                    forecast_range=forecast_range, \n",
    "                                                                                    list_ramp_alarm = list_ramp_alarm, \n",
    "                                                                                    df_train = df_train, \n",
    "                                                                                    n_neighbors = ens_params['n_neighbors_lof'], \n",
    "                                                                                    contamination = ens_params['contamination_lof'],\n",
    "                                                                                    preprocess_ramps = preprocess_ramps,\n",
    "                                                                                    max_consecutive_points = max_consecutive_points)\n",
    "\n",
    "    # # # # ----------------------------> PLOT FORECASTS <----------------------------\n",
    "\n",
    "    # # # # ----------------------------> WIND RAMP EVENTS <----------------------------\n",
    "    list_wind_ramps = check_wind_ramp_events_day(df, list_ramp_alarm, i)\n",
    "\n",
    "    str_forecaster = 'dayahead'\n",
    "    df_dayahead = df_test.filter(like=str_forecaster, axis=1)\n",
    "    if str_forecaster == 'dayahead':\n",
    "        df_dayahead.drop(['dayahead11hforecast', 'dayahead11hconfidence10','dayahead11hconfidence90'], axis=1, inplace=True)\n",
    "    # replace with \"50_predictions\", \"10_predictions\", \"90_predictions\"\n",
    "    df_dayahead.columns = ['50_predictions', '10_predictions', '90_predictions']\n",
    "    # retain last 96 values\n",
    "    df_dayahead = df_dayahead.iloc[-96:]\n",
    "\n",
    "    # compute rmse\n",
    "    rmse = np.sqrt(np.mean((df_dayahead['50_predictions'].values - df_test_plot['targets'].values)**2))\n",
    "    # pinball loss q10\n",
    "    from sklearn.metrics import mean_pinball_loss\n",
    "    pinball_loss_q10 = mean_pinball_loss(df_test_plot['targets'].values, df_dayahead['10_predictions'].values, alpha=0.1)\n",
    "    # pinball loss q90\n",
    "    pinball_loss_q90 = mean_pinball_loss(df_test_plot['targets'].values, df_dayahead['90_predictions'].values, alpha=0.9)\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Forecasters: dayahead </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> RMSE: {rmse} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Pinball Loss Q10: {pinball_loss_q10} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Pinball Loss Q90: {pinball_loss_q90} </blue>')\n",
    "\n",
    "\n",
    "    # filter dataframes where \"mostrecent\" is contained in name\n",
    "    df_dayahead11 = df_test.filter(like='dayahead11h', axis=1)\n",
    "    # replace with \"50_predictions\", \"10_predictions\", \"90_predictions\"\n",
    "    df_dayahead11.columns = ['50_predictions', '10_predictions', '90_predictions']\n",
    "    # retain last 96 values\n",
    "    df_dayahead11 = df_dayahead11.iloc[-96:]\n",
    "\n",
    "    # compute rmse\n",
    "    rmse = np.sqrt(np.mean((df_dayahead11['50_predictions'].values - df_test_plot['targets'].values)**2))\n",
    "    # pinball loss q10\n",
    "    pinball_loss_q10 = mean_pinball_loss(df_test_plot['targets'].values, df_dayahead11['10_predictions'].values, alpha=0.1)\n",
    "    # pinball loss q90\n",
    "    pinball_loss_q90 = mean_pinball_loss(df_test_plot['targets'].values, df_dayahead11['90_predictions'].values, alpha=0.9)\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Forecasters: dayahead11h </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> RMSE: {rmse} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Pinball Loss Q10: {pinball_loss_q10} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Pinball Loss Q90: {pinball_loss_q90} </blue>')\n",
    "\n",
    "    # filter dataframes where \"weekahead\" is contained in name\n",
    "    df_weekahead = df_test.filter(like='weekahead', axis=1)\n",
    "    # replace with \"50_predictions\", \"10_predictions\", \"90_predictions\"\n",
    "    df_weekahead.columns = ['50_predictions', '10_predictions', '90_predictions']\n",
    "    # retain last 96 values\n",
    "    df_weekahead = df_weekahead.iloc[-96:]\n",
    "\n",
    "    # compute rmse\n",
    "    rmse = np.sqrt(np.mean((df_weekahead['50_predictions'].values - df_test_plot['targets'].values)**2))\n",
    "    # pinball loss q10\n",
    "    pinball_loss_q10 = mean_pinball_loss(df_test_plot['targets'].values, df_weekahead['10_predictions'].values, alpha=0.1)\n",
    "    # pinball loss q90\n",
    "    pinball_loss_q90 = mean_pinball_loss(df_test_plot['targets'].values, df_weekahead['90_predictions'].values, alpha=0.9)\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Forecasters: weekahead </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> RMSE: {rmse} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Pinball Loss Q10: {pinball_loss_q10} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Pinball Loss Q90: {pinball_loss_q90} </blue>')\n",
    "    \n",
    "    # # filter dataframes where \"mostrecent\" is contained in name\n",
    "    # df_most_recent = df_test.filter(like='mostrecent', axis=1)\n",
    "    # # replace with \"50_predictions\", \"10_predictions\", \"90_predictions\"\n",
    "    # df_most_recent.columns = ['50_predictions', '10_predictions', '90_predictions']\n",
    "    # # retain last 96 values\n",
    "    # df_most_recent = df_most_recent.iloc[-96:]\n",
    "\n",
    "    # # plot day-ahead forecasts\n",
    "    # plot_forecasts(df_dayahead, df_test_plot, list_wind_ramps, title = 'Wind Power - Day-Ahead Forecasts', color='yellow')\n",
    "\n",
    "    # # plot day-ahead-11h forecasts\n",
    "    # plot_forecasts(df_dayahead11, df_test_plot, list_wind_ramps, title = 'Wind Power - Day-Ahead-11h Forecasts', color='orange')\n",
    "\n",
    "    # # plot week-ahead forecasts\n",
    "    # plot_forecasts(df_weekahead, df_test_plot, list_wind_ramps, title = 'Wind Power - Week-Ahead Forecasts', color='purple')\n",
    "\n",
    "    # # plot most recent forecasts\n",
    "    # if sim_params['most_recent']:\n",
    "    #     plot_forecasts(df_most_recent, df_test_plot, list_wind_ramps, title = 'Wind Power - Most-Recent Forecasts', color='green')\n",
    "\n",
    "    # plot wind power forecast results\n",
    "    if ens_params['plt_wind_power_ensemble']:\n",
    "        plot_forecasts(df_pred_plot, df_test_plot, list_wind_ramps, title = 'Wind Power - QR Forecasts')\n",
    "\n",
    "    # # plot variability forecast results\n",
    "    # if ens_params['plt_wind_power_variability_ensemble']:\n",
    "    #     plot_var_forecasts(df_pred_var_plot, df_test_var_plot, list_wind_ramps, title = 'Wind Power Variability - QR Forecasts')\n",
    "\n",
    "    # if not df_ramp_clusters.empty:\n",
    "    #     num_ramp_cluster_events = len(df_ramp_clusters.cluster_id.unique())\n",
    "    #     logger.info(' ')\n",
    "    #     logger.opt(colors = True).info(f'<blue> -----------------> Number of Ramp Cluster Events: {num_ramp_cluster_events} </blue>')\n",
    "    #     plot_ramp_detection(df_test_var_plot, df_pred_var_plot, df_ramp_clusters, list_wind_ramps)\n",
    "\n",
    "\n",
    "    # # # # ----------------------------> FORECASTERS PERMUTATION CONTRIBUTIONS <----------------------------\n",
    "    from source.assessment_contributions import compute_forecasters_contributions\n",
    "    from source.plots.display_contributions import permutation_pivot_data\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    if ens_params['model_type'] == 'LR' and ens_params['var_model_type'] == 'LR':\n",
    "        logger.info(' ')\n",
    "        logger.opt(colors = True).info('<blue> -----------------> Forecasters LASSO coefficients contributions computed </blue>')\n",
    "        import pickle\n",
    "        from source.simulation.helpers_simulation import compute_coefficients\n",
    "        from source.plots.display_contributions import lasso_coefs_pivot_data\n",
    "        with open('/Users/gio/Desktop/Elia-RES-Forecasting/info_model/b1r1_previous_day.pickle', 'rb') as handle:\n",
    "            previous_day = pickle.load(handle)\n",
    "        iter_coefficients_contributions = compute_coefficients(ens_params, previous_day, p_values=True)\n",
    "        df_pivot = lasso_coefs_pivot_data(sim_params, iter_coefficients_contributions)\n",
    "        title = 'Lasso Coefficients'\n",
    "        plot_stacked_bar_chart(df_pivot, title)\n",
    "        plot_heatmap(df_pivot, title)\n",
    "\n",
    "    logger.info(' -----------------> Forecasters  Permutation Contributions')\n",
    "    logger.info(' ')\n",
    "    ens_params['contribution_method'] = 'permutation'\n",
    "    contr_mthd = ens_params['contribution_method']\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Forecasters {contr_mthd} contributions computed </blue>')\n",
    "    y_test = df_test['measured'].values\n",
    "    iter_permutation_contributions = compute_forecasters_contributions(buyer_resource_name, ens_params, y_test, forecast_range)\n",
    "\n",
    "    df_pivot = permutation_pivot_data(sim_params, iter_permutation_contributions)\n",
    "    # Plot the stacked bar chart\n",
    "    df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "    plt.xlabel('Key and Quantile')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Stacked Bar Chart of Average Permutation Contributions')\n",
    "    plt.show()\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "    plt.xlabel('Series')\n",
    "    plt.ylabel('Key and Quantile')\n",
    "    plt.title('Heatmap of Average Permutation Contributions')\n",
    "    plt.show()\n",
    "\n",
    "    ens_params['contribution_method'] = 'shapley'\n",
    "    contr_mthd = ens_params['contribution_method']\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Forecasters {contr_mthd} contributions computed </blue>')\n",
    "    y_test = df_test['measured'].values\n",
    "    iter_shapley_contributions = compute_forecasters_contributions(buyer_resource_name, ens_params, y_test, forecast_range)\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'{iter_shapley_contributions}')\n",
    "    df_pivot = permutation_pivot_data(sim_params, iter_shapley_contributions)\n",
    "\n",
    "    # Plot the stacked bar chart\n",
    "    df_pivot.plot(kind='bar', stacked=True, figsize=(15, 6))\n",
    "    plt.xlabel('Key and Quantile')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Stacked Bar Chart of Average Shapley Contributions')\n",
    "    plt.show()\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.heatmap(df_pivot, annot=True, cmap='viridis')\n",
    "    plt.xlabel('Series')\n",
    "    plt.ylabel('Key and Quantile')\n",
    "    plt.title('Heatmap of Average Shapley Contributions')\n",
    "    plt.show()\n",
    "\n",
    "    # clear_output(wait=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
