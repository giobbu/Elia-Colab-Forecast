{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from source.utils.file_read import process_and_concat_files \n",
    "from source.utils.file_read import filter_df\n",
    "from source.utils.collect_results import collect_pb_result, collect_rmse_result, create_df_forecaster_first_stage, create_df_forecaster_second_stage\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.simulation.submission_module import submission_forecasters\n",
    "from source.simulation.buyer_module import prepare_buyer_data\n",
    "from source.ensemble.stack_generalization.utils.display_results import display_forecasting_metrics\n",
    "from source.ensemble.combination_scheme.equal_weights import calculate_equal_weights\n",
    "from source.ensemble.combination_scheme.avg_weights import calculate_weighted_avg\n",
    "from source.ensemble.combination_scheme.model_selection import run_model_selection\n",
    "from source.plots.plot_forecasts import plot_forecasts, plot_var_forecasts\n",
    "from source.plots.display_hypothesis_testing import run_statistical_comparison_analysis\n",
    "from source.plots.display_metrics import display_table_metrics\n",
    "from source.ml_engine import create_ensemble_forecasts\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.simulation_setting import Simulation, WeightedAvg, Stack\n",
    "from source.simulation.helpers_simulation import process_combination_scheme\n",
    "from source.utils.session_ml_info import delete_previous_day_pickle\n",
    "sim_params = Simulation.testing_period\n",
    "weight_avg_params = WeightedAvg.params\n",
    "ens_params = Stack.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coverage(df_pred_ensemble, col_90, col_10, col_targets):\n",
    "    \"\"\"\n",
    "    Calculates the coverage percentage of target values falling within the\n",
    "    10th and 90th percentile predictions.\n",
    "    \"\"\"\n",
    "    condition = (df_pred_ensemble[col_10] <= df_pred_ensemble[col_targets]) &\\\n",
    "        (df_pred_ensemble[col_targets] <= df_pred_ensemble[col_90])\n",
    "    return np.mean(condition)\n",
    "\n",
    "def average_interval_width(df_pred_ensemble, col_90, col_10):\n",
    "    \"\"\"\n",
    "    Calculates the average width of the 80% prediction interval.\n",
    "    \"\"\"\n",
    "    return np.mean(df_pred_ensemble[col_90] - df_pred_ensemble[col_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(sim_params['random_seed'])\n",
    "\n",
    "# process and concatenate files\n",
    "files = [sim_params['file_1'], sim_params['file_2'], sim_params['file_3'], sim_params['file_4'], \n",
    "            sim_params['file_5'], sim_params['file_6'], sim_params['file_7'], sim_params['file_8'], \n",
    "            sim_params['file_9'], sim_params['file_10'], sim_params['file_11'], sim_params['file_12']]\n",
    "\n",
    "logger.info(' ')\n",
    "logger.info(f'Load Files: {files}')\n",
    "\n",
    "df = process_and_concat_files(files)\n",
    "\n",
    "# filter data forecasters\n",
    "df_filtered = filter_df(df, sim_params['forecasts_col'], sim_params['measured_col'])\n",
    "\n",
    "# replace NaN values\n",
    "if sim_params['replace_nan']:\n",
    "    logger.info(' ')\n",
    "    logger.warning(\"Replacing NaN values with 0s\")\n",
    "    print(df_filtered.isna().sum())\n",
    "    df_filtered.fillna(0, inplace=True)\n",
    "\n",
    "# # set buyer resource name\n",
    "buyer_resource_name = 'b1r1'\n",
    "\n",
    "# loss quantile ensemble regressor\n",
    "lst_rmse_ensemble = []\n",
    "#loss best model selection\n",
    "lst_rmse_best_model = []\n",
    "# loss equal weights scheme\n",
    "lst_rmse_equal_weights = []\n",
    "# loss weighted average scheme\n",
    "lst_rmse_weighted_avg = []\n",
    "# loss weighted average scheme soft\n",
    "lst_rmse_weighted_avg_soft = []\n",
    "# loss baseline day ahead\n",
    "lst_rmse_baseline_dayahead = []\n",
    "# loss baseline day ahead 11\n",
    "lst_rmse_baseline_dayahead11h = []\n",
    "# loss baseline week ahead\n",
    "lst_rmse_baseline_week_ahead = []\n",
    "# loss baseline most recent\n",
    "if sim_params['most_recent']:\n",
    "    lst_rmse_baseline_most_recent = []\n",
    "# loss baseline malicious\n",
    "if sim_params['malicious']:\n",
    "    lst_rmse_baseline_malicious = []\n",
    "# loss baseline noisy\n",
    "if sim_params['noisy']:\n",
    "    lst_rmse_baseline_noisy = []\n",
    "\n",
    "# loss var ensemble regressor\n",
    "lst_rmse_var_ensemble = []\n",
    "# loss var best model selection\n",
    "lst_rmse_var_best_model = []\n",
    "# loss var equal weights scheme\n",
    "lst_rmse_var_equal_weights = []\n",
    "# loss var weighted average scheme\n",
    "lst_rmse_var_weighted_avg = []\n",
    "# loss var weighted average scheme soft\n",
    "lst_rmse_var_weighted_avg_soft = []\n",
    "# loss var baseline day ahead\n",
    "lst_rmse_var_baseline_dayahead = []\n",
    "# loss var baseline day ahead 11\n",
    "lst_rmse_var_baseline_dayahead11h = []\n",
    "# loss var baseline week ahead\n",
    "lst_rmse_var_baseline_week_ahead = []\n",
    "# loss var baseline most recent\n",
    "if sim_params['most_recent']:\n",
    "    lst_rmse_var_baseline_most_recent = []\n",
    "    lst_pb_most_recent_q10 = []\n",
    "    lst_pb_most_recent_q90 = []\n",
    "# loss var baseline malicious\n",
    "if sim_params['malicious']:\n",
    "    lst_rmse_var_baseline_malicious = []\n",
    "    lst_pb_malicious_q10 = []\n",
    "    lst_pb_malicious_q90 = []\n",
    "# loss var baseline noisy\n",
    "if sim_params['noisy']:\n",
    "    lst_rmse_var_baseline_noisy = []\n",
    "    lst_pb_noisy_q10 = []\n",
    "    lst_pb_noisy_q90 = []\n",
    "\n",
    "# loss quantile ensemble regressor\n",
    "lst_pb_ensemble_q10 = []\n",
    "lst_pb_ensemble_q90 = []\n",
    "# loss quantile best model selection\n",
    "lst_pb_best_model_q10 = []\n",
    "lst_pb_best_model_q90 = []\n",
    "# loss avg weights scheme\n",
    "lst_pb_weighted_avg_q10 = []\n",
    "lst_pb_weighted_avg_q90 = []\n",
    "# loss soft avg weights scheme\n",
    "lst_pb_weighted_avg_soft_q10 = []\n",
    "lst_pb_weighted_avg_soft_q90 = []\n",
    "# loss equal weighted scheme\n",
    "lst_pb_equal_weights_q10 = []\n",
    "lst_pb_equal_weights_q90 = []\n",
    "# loss baseline day ahead\n",
    "lst_pb_dayahead_q10 = []\n",
    "lst_pb_dayahead_q90  = []\n",
    "# loss baseline day ahead 11\n",
    "lst_pb_dayahead_11h_q10 = []\n",
    "lst_pb_dayahead_11h_q90 = []\n",
    "# loss baseline week ahead\n",
    "lst_pb_week_ahead_q10 = []\n",
    "lst_pb_week_ahead_q90 = []\n",
    "\n",
    "# coverage probability\n",
    "lst_coverage_ensemble = []\n",
    "lst_coverage_var_ensemble = []\n",
    "lst_coverage_best_model = []\n",
    "lst_coverage_equal_weights = []\n",
    "lst_coverage_weighted_avg = []\n",
    "lst_coverage_weighted_avg_soft = []\n",
    "lst_coverage_baseline_dayahead = []\n",
    "lst_coverage_baseline_dayahead11h = []\n",
    "lst_coverage_baseline_week_ahead = []\n",
    "if sim_params['most_recent']:\n",
    "    lst_coverage_baseline_most_recent = []\n",
    "if sim_params['malicious']:\n",
    "    lst_coverage_baseline_malicious = []\n",
    "if sim_params['noisy']:\n",
    "    lst_coverage_baseline_noisy = []\n",
    "\n",
    "\n",
    "# average interval width\n",
    "lst_avg_width_ensemble = []\n",
    "lst_avg_width_ensemble_var = []\n",
    "lst_avg_width_best_model = []\n",
    "lst_avg_width_equal_weights = []\n",
    "lst_avg_width_weighted_avg = []\n",
    "lst_avg_width_weighted_avg_soft = []\n",
    "lst_avg_width_baseline_dayahead = []\n",
    "lst_avg_width_baseline_dayahead11h = []\n",
    "lst_avg_width_baseline_week_ahead = []\n",
    "if sim_params['most_recent']:\n",
    "    lst_avg_width_baseline_most_recent = []\n",
    "if sim_params['malicious']:\n",
    "    lst_avg_width_baseline_malicious = []\n",
    "if sim_params['noisy']:\n",
    "    lst_avg_width_baseline_noisy = []\n",
    "\n",
    "\n",
    "# remove previous day pickle file\n",
    "logger.info(' ')\n",
    "delete_previous_day_pickle()\n",
    "logger.opt(colors = True).warning('previous day pickle file removed')\n",
    "\n",
    "# final contributions forecasters\n",
    "avg_permutation_contributions = defaultdict(dict)\n",
    "avg_shapley_contributions = defaultdict(dict)\n",
    "avg_coefficients_contributions = defaultdict(dict)\n",
    "avg_weighted_avg_contributions = defaultdict(dict)\n",
    "avg_weighted_soft_avg_contributions = defaultdict(dict)\n",
    "\n",
    "# Collect Ramp Alarm\n",
    "list_ramp_alarm = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    if i >= ens_params['day_calibration'] and ens_params['conformalized_qr']:\n",
    "        day_calibration = ens_params['day_calibration']\n",
    "        start_training_timestamp = start_training_timestamp - pd.Timedelta(f'{day_calibration}day')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors=True).info(f'<blue>Start training: {start_training_timestamp} - End training: {end_training_timestamp}</blue>')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors = True).info(f'<blue>Start prediction: {start_prediction_timestamp} - End prediction: {end_prediction_timestamp}</blue>')\n",
    "\n",
    "    day_previous_start_prediction_timestamp = start_prediction_timestamp - pd.Timedelta('1day')\n",
    "    df_train = df_filtered[df_filtered.index.to_series().between(start_training_timestamp, end_training_timestamp)].iloc[:-1,:]\n",
    "    df_test = df_filtered[df_filtered.index.to_series().between(day_previous_start_prediction_timestamp, end_prediction_timestamp)].iloc[:-1,:]\n",
    "                                                                                                                            \n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of training data: {len(df_train)} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of test data: {len(df_test)} </blue>')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue> -----------------> Forecasters prediction submitted </blue>')\n",
    "\n",
    "# # ----------------------------> FORECASTERS PREDICTION SUBMISSION <----------------------------\n",
    "\n",
    "    df_market, df_train, df_test = submission_forecasters(sim_params, df_train, df_test)   \n",
    "\n",
    "# # ----------------------------> BUYERS DATA <----------------------------\n",
    "\n",
    "    df_buyer, forecast_range = prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "\n",
    "# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\n",
    "\n",
    "    results_ensemble_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                                            df_buyer=df_buyer, \n",
    "                                                            df_market=df_market,\n",
    "                                                            end_training_timestamp=end_training_timestamp,\n",
    "                                                            forecast_range = forecast_range,\n",
    "                                                            challenge_usecase='simulation',\n",
    "                                                            simulation=True)\n",
    "    \n",
    "\n",
    "    if sim_params['baselines_comparison']:\n",
    "\n",
    "        # # # ----------------------------> COMBINATION SCHEME DATA <----------------------------\n",
    "\n",
    "        df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var = process_combination_scheme(df_train, df_test, end_training_timestamp, day_previous_start_prediction_timestamp)\n",
    "        \n",
    "        df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']   \n",
    "        df_pred_ensemble.rename(columns={'q50_' + 'b1r1': '50_predictions', 'q10_' + 'b1r1': '10_predictions', 'q90_' + 'b1r1': '90_predictions', 'norm_' + 'b1r1': 'targets'}, inplace=True)\n",
    "        df_pred_ensemble['targets'] = day_previous_df_test_norm['norm_measured'].values[-96:]\n",
    "        df_var_ensemble = results_ensemble_forecasts['wind_power_ramp']['predictions']\n",
    "        df_var_ensemble.rename(columns={'q50_' + 'b1r1': '50_var_predictions', 'q10_' + 'b1r1': '10_var_predictions', 'q90_' + 'b1r1': '90_var_predictions', 'targets': 'targets'}, inplace=True)\n",
    "        df_var_ensemble['targets'] = day_previous_df_test_norm_var['norm_measured'].values[-96:]\n",
    "        \n",
    "        df_test_ensemble = pd.DataFrame(df_pred_ensemble['targets']) \n",
    "        df_2stage_test = pd.DataFrame(df_var_ensemble['targets'])\n",
    "\n",
    "    # # ----------------------------> PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "    ## ----------------------------> WIND POWER VARIABILITY - PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        # performance variability ensemble\n",
    "        lst_rmse_var_ensemble, rmse_var_ensemble = collect_rmse_result(df_var_ensemble, '50_var_predictions', lst_rmse_var_ensemble)\n",
    "        # coverage ensemble variability\n",
    "        coverage_var_ensemble = calculate_coverage(df_var_ensemble, '90_var_predictions', '10_var_predictions', 'targets')\n",
    "        lst_coverage_var_ensemble.append(round(coverage_var_ensemble, 3))\n",
    "        # average interval width\n",
    "        avg_width_ensemble_var = average_interval_width(df_var_ensemble, '90_var_predictions', '10_var_predictions')\n",
    "        lst_avg_width_ensemble_var.append(round(avg_width_ensemble_var, 3))\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model_var = run_model_selection(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid = weight_avg_params['window_size_valid'], var=True)\n",
    "        lst_rmse_var_best_model, rmse_var_best_model = collect_rmse_result(df_best_model_var, 'mean_prediction', lst_rmse_var_best_model)\n",
    "\n",
    "        # performance weighted average\n",
    "        df_weighted_avg_var, dict_weights_var = calculate_weighted_avg(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid=weight_avg_params['window_size_valid'], var=True)\n",
    "        lst_rmse_var_weighted_avg, rmse_var_weighted_avg = collect_rmse_result(df_weighted_avg_var, 'mean_prediction', lst_rmse_var_weighted_avg)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft_var, dict_weights_soft_var = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], var=True, norm='softmax')\n",
    "        lst_rmse_var_weighted_avg_soft, rmse_var_weighted_avg_soft = collect_rmse_result(df_weighted_avg_soft_var, 'mean_prediction', lst_rmse_var_weighted_avg_soft)\n",
    "\n",
    "        # performance equal weights\n",
    "        df_equal_weights_var = calculate_equal_weights(day_previous_df_test_norm_var, start_prediction_timestamp)\n",
    "        lst_rmse_var_equal_weights, rmse_var_equal_weights = collect_rmse_result(df_equal_weights_var, 'mean_prediction', lst_rmse_var_equal_weights)\n",
    "\n",
    "        # performance day-ahead\n",
    "        df_dayahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead', start_prediction_timestamp)\n",
    "        lst_rmse_var_baseline_dayahead, rmse_var_dayahead = collect_rmse_result(df_dayahead_var, 'norm_dayaheadforecast', lst_rmse_var_baseline_dayahead)\n",
    "\n",
    "        # performance day-ahead-11h\n",
    "        df_dayahead_11h_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead11h', start_prediction_timestamp)\n",
    "        lst_rmse_var_baseline_dayahead11h, rmse_var_dayahead_11h = collect_rmse_result(df_dayahead_11h_var, 'norm_dayahead11hforecast', lst_rmse_var_baseline_dayahead11h)\n",
    "\n",
    "        # performance week ahead\n",
    "        df_week_ahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'weekahead', start_prediction_timestamp)\n",
    "        lst_rmse_var_baseline_week_ahead, rmse_var_week_ahead = collect_rmse_result(df_week_ahead_var, 'norm_weekaheadforecast', lst_rmse_var_baseline_week_ahead)\n",
    "\n",
    "        # performance most recent\n",
    "        if sim_params['most_recent']:\n",
    "            # performance most recent\n",
    "            df_most_recent_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'mostrecent', start_prediction_timestamp)\n",
    "            lst_rmse_var_baseline_most_recent, rmse_var_most_recent = collect_rmse_result(df_most_recent_var, 'norm_mostrecentforecast', lst_rmse_var_baseline_most_recent)\n",
    "\n",
    "        # performance malicious\n",
    "        if sim_params['malicious']:\n",
    "            # performance malicious\n",
    "            df_malicious_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'malicious', start_prediction_timestamp)\n",
    "            lst_rmse_var_baseline_malicious, rmse_var_malicious = collect_rmse_result(df_malicious_var, 'norm_maliciousforecast', lst_rmse_var_baseline_malicious)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            # performance noisy\n",
    "            df_noisy_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'noisy', start_prediction_timestamp)\n",
    "            lst_rmse_var_baseline_noisy, rmse_var_noisy = collect_rmse_result(df_noisy_var, 'norm_noisyforecast', lst_rmse_var_baseline_noisy)\n",
    "\n",
    "    ## ----------------------------> WIND POWER - PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        # performance ensemble\n",
    "        lst_rmse_ensemble, rmse_ensemble = collect_rmse_result(df_pred_ensemble, '50_predictions', lst_rmse_ensemble)\n",
    "        lst_pb_ensemble_q10, lst_pb_ensemble_q90, pinball_ensemble_q10, pinball_ensemble_q90 = collect_pb_result(df_pred_ensemble, \n",
    "                                                                                                                '10_predictions', '90_predictions', \n",
    "                                                                                                                lst_pb_ensemble_q10, lst_pb_ensemble_q90)\n",
    "        # coverage ensemble\n",
    "        coverage_ensemble = calculate_coverage(df_pred_ensemble, '90_predictions', '10_predictions', 'targets')\n",
    "        lst_coverage_ensemble.append(round(coverage_ensemble, 3))\n",
    "        # average interval width\n",
    "        avg_width_ensemble = average_interval_width(df_pred_ensemble, '90_predictions', '10_predictions')\n",
    "        lst_avg_width_ensemble.append(round(avg_width_ensemble, 3))\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model = run_model_selection(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        \n",
    "        lst_rmse_best_model, rmse_best_model = collect_rmse_result(df_best_model, 'mean_prediction', lst_rmse_best_model)\n",
    "        lst_pb_best_model_q10, lst_pb_best_model_q90, pinball_best_model_q10, pinball_best_model_q90 = collect_pb_result(df_best_model,\n",
    "                                                                                                                        'Q10', 'Q90',\n",
    "                                                                                                                        lst_pb_best_model_q10, lst_pb_best_model_q90)\n",
    "        # coverage best model selection\n",
    "        coverage_best_model = calculate_coverage(df_best_model, 'Q90', 'Q10', 'targets')\n",
    "        lst_coverage_best_model.append(round(coverage_best_model, 3))\n",
    "        # average interval width\n",
    "        avg_width_best_model = average_interval_width(df_best_model, 'Q90', 'Q10')\n",
    "        lst_avg_width_best_model.append(round(avg_width_best_model, 3))\n",
    "\n",
    "        # performance weighted average\n",
    "        df_weighted_avg, dict_weights = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        lst_rmse_weighted_avg, rmse_weighted_avg = collect_rmse_result(df_weighted_avg, 'mean_prediction', lst_rmse_weighted_avg)\n",
    "        lst_pb_weighted_avg_q10, lst_pb_weighted_avg_q90, pinball_weighted_avg_q10, pinball_weighted_avg_q90 = collect_pb_result(df_weighted_avg, \n",
    "                                                                                                                                    'Q10', 'Q90', \n",
    "                                                                                                                                    lst_pb_weighted_avg_q10, lst_pb_weighted_avg_q90)\n",
    "        # coverage weighted average\n",
    "        coverage_weighted_avg = calculate_coverage(df_weighted_avg, 'Q90', 'Q10', 'targets')\n",
    "        lst_coverage_weighted_avg.append(round(coverage_weighted_avg, 3))\n",
    "        # average interval width\n",
    "        avg_width_weighted_avg = average_interval_width(df_weighted_avg, 'Q90', 'Q10')\n",
    "        lst_avg_width_weighted_avg.append(round(avg_width_weighted_avg, 3))\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft, dict_weights_soft = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], norm='softmax')\n",
    "        lst_rmse_weighted_avg_soft, rmse_weighted_avg_soft = collect_rmse_result(df_weighted_avg_soft, 'mean_prediction', lst_rmse_weighted_avg_soft)\n",
    "        lst_pb_weighted_avg_soft_q10, lst_pb_weighted_avg_soft_q90, pinball_weighted_avg_soft_q10, pinball_weighted_avg_soft_q90 = collect_pb_result(df_weighted_avg_soft,\n",
    "                                                                                                                                                    'Q10', 'Q90', \n",
    "                                                                                                                                                    lst_pb_weighted_avg_soft_q10, lst_pb_weighted_avg_soft_q90)\n",
    "        # coverage weighted avg soft\n",
    "        coverage_weighted_avg_soft = calculate_coverage(df_weighted_avg_soft, 'Q90', 'Q10', 'targets')\n",
    "        lst_coverage_weighted_avg_soft.append(round(coverage_weighted_avg_soft, 3))\n",
    "        # average interval width\n",
    "        avg_width_weighted_avg_soft = average_interval_width(df_weighted_avg_soft, 'Q90', 'Q10')\n",
    "        lst_avg_width_weighted_avg_soft.append(round(avg_width_weighted_avg_soft, 3))\n",
    "        \n",
    "        # performance equal weights\n",
    "        df_equal_weights = calculate_equal_weights(day_previous_df_test_norm, start_prediction_timestamp)\n",
    "        lst_rmse_equal_weights, rmse_equal_weights = collect_rmse_result(df_equal_weights, 'mean_prediction', lst_rmse_equal_weights)\n",
    "        lst_pb_equal_weights_q10, lst_pb_equal_weights_q90, pinball_equal_weights_q10, pinball_equal_weights_q90 = collect_pb_result(df_equal_weights, \n",
    "                                                                                                                                            'Q10', 'Q90', \n",
    "                                                                                                                                            lst_pb_equal_weights_q10, lst_pb_equal_weights_q90)\n",
    "        # coverage equal weights\n",
    "        coverage_equal_weights = calculate_coverage(df_equal_weights, 'Q90', 'Q10', 'targets')\n",
    "        lst_coverage_equal_weights.append(round(coverage_equal_weights, 3))\n",
    "        # average interval width\n",
    "        avg_width_equal_weights = average_interval_width(df_equal_weights, 'Q90', 'Q10')\n",
    "        lst_avg_width_equal_weights.append(round(avg_width_equal_weights, 3))\n",
    "\n",
    "\n",
    "        # performance day-ahead\n",
    "        df_dayahead = create_df_forecaster_first_stage(day_previous_df_test_norm, 'dayahead', start_prediction_timestamp)\n",
    "        lst_rmse_baseline_dayahead, rmse_dayahead = collect_rmse_result(df_dayahead, 'norm_dayaheadforecast', lst_rmse_baseline_dayahead)\n",
    "        lst_pb_dayahead_q10, lst_pb_dayahead_q90, pinball_dayahead_q10, pinball_dayahead_q90 = collect_pb_result(df_dayahead, \n",
    "                                                                                                                    'norm_dayaheadconfidence10', 'norm_dayaheadconfidence90', \n",
    "                                                                                                                    lst_pb_dayahead_q10, lst_pb_dayahead_q90)\n",
    "        # coverage day-ahead\n",
    "        coverage_dayahead = calculate_coverage(df_dayahead, 'norm_dayaheadconfidence90', 'norm_dayaheadconfidence10', 'targets')\n",
    "        lst_coverage_baseline_dayahead.append(round(coverage_dayahead, 3))\n",
    "        # average interval width\n",
    "        avg_width_dayahead = average_interval_width(df_dayahead, 'norm_dayaheadconfidence90', 'norm_dayaheadconfidence10')\n",
    "        lst_avg_width_baseline_dayahead.append(round(avg_width_dayahead, 3))\n",
    "\n",
    "\n",
    "        # performance day-ahead-11h\n",
    "        df_dayahead_11h = create_df_forecaster_first_stage(day_previous_df_test_norm, 'dayahead11h', start_prediction_timestamp)\n",
    "        lst_rmse_baseline_dayahead11h, rmse_dayahead_11h = collect_rmse_result(df_dayahead_11h, 'norm_dayahead11hforecast', lst_rmse_baseline_dayahead11h)\n",
    "        lst_pb_dayahead_11h_q10, lst_pb_dayahead_11h_q90, pinball_dayahead_11h_q10, pinball_dayahead_11h_q90 = collect_pb_result(df_dayahead_11h, \n",
    "                                                                                                                                    'norm_dayahead11hconfidence10', 'norm_dayahead11hconfidence90', \n",
    "                                                                                                                                    lst_pb_dayahead_11h_q10, lst_pb_dayahead_11h_q90)\n",
    "        # coverage day-ahead-11h\n",
    "        coverage_dayahead_11h = calculate_coverage(df_dayahead_11h, 'norm_dayahead11hconfidence90', 'norm_dayahead11hconfidence10', 'targets')\n",
    "        lst_coverage_baseline_dayahead11h.append(round(coverage_dayahead_11h, 3))\n",
    "        # average interval width\n",
    "        avg_width_dayahead_11h = average_interval_width(df_dayahead_11h, 'norm_dayahead11hconfidence90', 'norm_dayahead11hconfidence10')\n",
    "        lst_avg_width_baseline_dayahead11h.append(round(avg_width_dayahead_11h, 3))\n",
    "\n",
    "        # performance week ahead\n",
    "        df_week_ahead = create_df_forecaster_first_stage(day_previous_df_test_norm, 'weekahead', start_prediction_timestamp)\n",
    "        lst_rmse_baseline_week_ahead, rmse_week_ahead = collect_rmse_result(df_week_ahead, 'norm_weekaheadforecast', lst_rmse_baseline_week_ahead)\n",
    "        lst_pb_week_ahead_q10, lst_pb_week_ahead_q90, pinball_week_ahead_q10, pinball_week_ahead_q90 = collect_pb_result(df_week_ahead, \n",
    "                                                                                                                            'norm_weekaheadconfidence10', 'norm_weekaheadconfidence90', \n",
    "                                                                                                                            lst_pb_week_ahead_q10, lst_pb_week_ahead_q90)\n",
    "        # coverage week ahead\n",
    "        coverage_week_ahead = calculate_coverage(df_week_ahead, 'norm_weekaheadconfidence90', 'norm_weekaheadconfidence10', 'targets')\n",
    "        lst_coverage_baseline_week_ahead.append(round(coverage_week_ahead, 3))\n",
    "        # average interval width\n",
    "        avg_width_week_ahead = average_interval_width(df_week_ahead, 'norm_weekaheadconfidence90', 'norm_weekaheadconfidence10')\n",
    "        lst_avg_width_baseline_week_ahead.append(round(avg_width_week_ahead, 3))\n",
    "\n",
    "        # performance most recent\n",
    "        if sim_params['most_recent']:\n",
    "            df_most_recent = create_df_forecaster_first_stage(day_previous_df_test_norm, 'mostrecent', start_prediction_timestamp)\n",
    "            lst_rmse_baseline_most_recent, rmse_most_recent = collect_rmse_result(df_most_recent, 'norm_mostrecentforecast', lst_rmse_baseline_most_recent)\n",
    "            lst_pb_most_recent_q10, lst_pb_most_recent_q90, pinball_most_recent_q10, pinball_most_recent_q90 = collect_pb_result(df_most_recent, \n",
    "                                                                                                                                    'norm_mostrecentconfidence10', 'norm_mostrecentconfidence90', \n",
    "                                                                                                                                    lst_pb_most_recent_q10, lst_pb_most_recent_q90)\n",
    "            # coverage most recent\n",
    "            coverage_most_recent = calculate_coverage(df_most_recent, 'norm_mostrecentconfidence90', 'norm_mostrecentconfidence10', 'targets')\n",
    "            lst_coverage_baseline_most_recent.append(round(coverage_most_recent, 3))\n",
    "            # average interval width\n",
    "            avg_width_most_recent = average_interval_width(df_most_recent, 'norm_mostrecentconfidence90', 'norm_mostrecentconfidence10')\n",
    "            lst_avg_width_baseline_most_recent.append(round(avg_width_most_recent, 3))\n",
    "\n",
    "        # performance malicious cheat\n",
    "        if sim_params['malicious']:\n",
    "            df_malicious = create_df_forecaster_first_stage(day_previous_df_test_norm, 'malicious', start_prediction_timestamp)\n",
    "            lst_rmse_baseline_malicious, rmse_malicious = collect_rmse_result(df_malicious, 'norm_maliciousforecast', lst_rmse_baseline_malicious)\n",
    "            lst_pb_malicious_q10, lst_pb_malicious_q90, pinball_malicious_q10, pinball_malicious_q90 = collect_pb_result(df_malicious, \n",
    "                                                                                                                            'norm_maliciousconfidence10', 'norm_maliciousconfidence90', \n",
    "                                                                                                                            lst_pb_malicious_q10, lst_pb_malicious_q90)\n",
    "            # coverage malicious\n",
    "            coverage_malicious = calculate_coverage(df_malicious, 'norm_maliciousconfidence90', 'norm_maliciousconfidence10', 'targets')\n",
    "            lst_coverage_baseline_malicious.append(round(coverage_malicious, 3))\n",
    "            # average interval width\n",
    "            avg_width_malicious = average_interval_width(df_malicious, 'norm_maliciousconfidence90', 'norm_maliciousconfidence10')\n",
    "            lst_avg_width_baseline_malicious.append(round(avg_width_malicious, 3))\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            df_noisy = create_df_forecaster_first_stage(day_previous_df_test_norm, 'noisy', start_prediction_timestamp)\n",
    "            lst_rmse_baseline_noisy, rmse_noisy = collect_rmse_result(df_noisy, 'norm_noisyforecast', lst_rmse_baseline_noisy)\n",
    "            lst_pb_noisy_q10, lst_pb_noisy_q90, pinball_noisy_q10, pinball_noisy_q90 = collect_pb_result(df_noisy, \n",
    "                                                                                                            'norm_noisyconfidence10', 'norm_noisyconfidence90', \n",
    "                                                                                                            lst_pb_noisy_q10, lst_pb_noisy_q90)\n",
    "            # coverage noisy\n",
    "            coverage_noisy = calculate_coverage(df_noisy, 'norm_noisyconfidence90', 'norm_noisyconfidence10', 'targets')\n",
    "            lst_coverage_baseline_noisy.append(round(coverage_noisy, 3))\n",
    "            # average interval width\n",
    "            avg_width_noisy = average_interval_width(df_noisy, 'norm_noisyconfidence90', 'norm_noisyconfidence10')\n",
    "            lst_avg_width_baseline_noisy.append(round(avg_width_noisy, 3))\n",
    "            \n",
    "        # plot forecasts\n",
    "        if ens_params['plt_wind_power_ensemble']:\n",
    "            plot_forecasts(df_pred_ensemble, df_test_ensemble, list_wind_ramps=[], title=f'Wind Power Forecasting - coverage {coverage_ensemble} - avg width {avg_width_ensemble}')\n",
    "\n",
    "        # plot variability forecast results\n",
    "        if ens_params['plt_wind_power_variability_ensemble']:\n",
    "            plot_var_forecasts(df_var_ensemble, df_2stage_test, list_wind_ramps=[], title=f'Wind Power Variability Forecasting - coverage {coverage_var_ensemble} - avg width {avg_width_ensemble_var}')\n",
    "\n",
    "        ## ----------------------------> DISPLAY METRICS <----------------------------\n",
    "        if sim_params['display_metrics']:\n",
    "            results_metrics = {'ensemble': {'rmse': rmse_ensemble, \n",
    "                                            'pb10': pinball_ensemble_q10, \n",
    "                                            'pb90': pinball_ensemble_q90, \n",
    "                                            'rmse_var': rmse_var_ensemble},\n",
    "                                'best_model': {'rmse': rmse_best_model,\n",
    "                                                'pb10': pinball_best_model_q10, \n",
    "                                                'pb90': pinball_best_model_q90, \n",
    "                                                'rmse_var': rmse_var_best_model},\n",
    "                                'weighted_avg': {'rmse': rmse_weighted_avg, \n",
    "                                                'pb10': pinball_weighted_avg_q10, \n",
    "                                                'pb90': pinball_weighted_avg_q90, \n",
    "                                                'rmse_var': rmse_var_weighted_avg},\n",
    "                                'weighted_avg_soft': {'rmse': rmse_weighted_avg_soft, \n",
    "                                                    'pb10': pinball_weighted_avg_soft_q10, \n",
    "                                                    'pb90': pinball_weighted_avg_soft_q90, \n",
    "                                                    'rmse_var': rmse_var_weighted_avg_soft},\n",
    "                                'equal_weights': {'rmse': rmse_equal_weights, \n",
    "                                                'pb10': pinball_equal_weights_q10, \n",
    "                                                'pb90': pinball_equal_weights_q90, \n",
    "                                                'rmse_var': rmse_var_equal_weights},\n",
    "                                'day_ahead': {'rmse': rmse_dayahead, \n",
    "                                            'pb10': pinball_dayahead_q10, \n",
    "                                            'pb90': pinball_dayahead_q90, \n",
    "                                            'rmse_var': rmse_var_dayahead},\n",
    "                                'day_ahead_11h': {'rmse': rmse_dayahead_11h, \n",
    "                                                'pb10': pinball_dayahead_11h_q10, \n",
    "                                                'pb90': pinball_dayahead_11h_q90, \n",
    "                                                'rmse_var': rmse_var_dayahead_11h},\n",
    "                                'week_ahead': {'rmse': rmse_week_ahead, \n",
    "                                            'pb10': pinball_week_ahead_q10, \n",
    "                                            'pb90': pinball_week_ahead_q90, \n",
    "                                            'rmse_var': rmse_var_week_ahead}\n",
    "                                }\n",
    "            if sim_params['most_recent']:\n",
    "                results_metrics['most_recent'] = {'rmse': rmse_most_recent, \n",
    "                                                'pb10': pinball_most_recent_q10, \n",
    "                                                'pb90': pinball_most_recent_q90, \n",
    "                                                'rmse_var': rmse_var_most_recent}\n",
    "            if sim_params['malicious']:\n",
    "                results_metrics['malicious'] = {'rmse': rmse_malicious, \n",
    "                                                        'pb10': pinball_malicious_q10, \n",
    "                                                        'pb90': pinball_malicious_q90, \n",
    "                                                        'rmse_var': rmse_var_malicious}\n",
    "            if sim_params['noisy']:\n",
    "                results_metrics['noisy'] = {'rmse': rmse_noisy, \n",
    "                                                'pb10': pinball_noisy_q10, \n",
    "                                                'pb90': pinball_noisy_q90, \n",
    "                                                'rmse_var': rmse_var_noisy}\n",
    "            \n",
    "            display_forecasting_metrics(sim_params=sim_params, ens_params=ens_params, dict_metrics = results_metrics)\n",
    "\n",
    "\n",
    "    #Clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # import time\n",
    "    # time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most recent\n",
    "if not sim_params['most_recent']:\n",
    "    lst_rmse_baseline_most_recent = None\n",
    "    lst_pb_most_recent_q10 = None\n",
    "    lst_pb_most_recent_q90 = None\n",
    "    lst_rmse_var_baseline_most_recent = None\n",
    "    \n",
    "# malicious\n",
    "if not sim_params['malicious']:\n",
    "    lst_rmse_baseline_malicious = None\n",
    "    lst_pb_malicious_q10 = None\n",
    "    lst_pb_malicious_q90 = None\n",
    "    lst_rmse_var_baseline_malicious = None\n",
    "\n",
    "# noisy\n",
    "if not sim_params['noisy']:\n",
    "    lst_rmse_baseline_noisy = None\n",
    "    lst_pb_noisy_q10 = None\n",
    "    lst_pb_noisy_q90 = None\n",
    "    lst_rmse_var_baseline_noisy = None\n",
    "\n",
    "# plot statistical comparison q50\n",
    "title1='RMSE-based Statistical Significance'\n",
    "title2='RMSE-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q50, avg_rank_q50 = run_statistical_comparison_analysis(ens_params['model_type'],\n",
    "                                                                lst_rmse_ensemble,\n",
    "                                                                lst_rmse_best_model,\n",
    "                                                                lst_rmse_equal_weights, \n",
    "                                                                lst_rmse_weighted_avg,\n",
    "                                                                lst_rmse_weighted_avg_soft,\n",
    "                                                                lst_rmse_baseline_dayahead, \n",
    "                                                                lst_rmse_baseline_dayahead11h, \n",
    "                                                                lst_rmse_baseline_week_ahead,\n",
    "                                                                lst_rmse_baseline_most_recent,\n",
    "                                                                lst_rmse_baseline_malicious,\n",
    "                                                                lst_rmse_baseline_noisy,\n",
    "                                                                title1, title2)\n",
    "# plot statistical comparison q10\n",
    "title1 = 'Q10 Pinball loss-based Statistical Significance'\n",
    "title2 = 'Q10 Pinball loss-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q10, avg_rank_q10 = run_statistical_comparison_analysis(ens_params['model_type'],\n",
    "                                                            lst_pb_ensemble_q10, \n",
    "                                                            lst_pb_best_model_q10,\n",
    "                                                            lst_pb_equal_weights_q10, \n",
    "                                                            lst_pb_weighted_avg_q10, \n",
    "                                                            lst_pb_weighted_avg_soft_q10,\n",
    "                                                            lst_pb_dayahead_q10, \n",
    "                                                            lst_pb_dayahead_11h_q10, \n",
    "                                                            lst_pb_week_ahead_q10,\n",
    "                                                            lst_pb_most_recent_q10,\n",
    "                                                            lst_pb_malicious_q10,\n",
    "                                                            lst_pb_noisy_q10,\n",
    "                                                            title1, title2)\n",
    "# plot statistical comparison q90\n",
    "title1 = 'Q90 Pinball loss-based Statistical Significance'\n",
    "title2 = 'Q90 Pinball loss-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q90, avg_rank_q90 = run_statistical_comparison_analysis(ens_params['model_type'],\n",
    "                                                            lst_pb_ensemble_q90,\n",
    "                                                            lst_pb_best_model_q90,\n",
    "                                                            lst_pb_equal_weights_q90, \n",
    "                                                            lst_pb_weighted_avg_q90,\n",
    "                                                            lst_pb_weighted_avg_soft_q90, \n",
    "                                                            lst_pb_dayahead_q90, \n",
    "                                                            lst_pb_dayahead_11h_q90, \n",
    "                                                            lst_pb_week_ahead_q90,\n",
    "                                                            lst_pb_most_recent_q90,\n",
    "                                                            lst_pb_malicious_q90,\n",
    "                                                            lst_pb_noisy_q90,\n",
    "                                                            title1, title2)\n",
    "# plot statistical comparison variability\n",
    "title1 = 'RMSE-based Statistical Significance'\n",
    "title2 = 'RMSE-based Statistical Comparison: critical difference diagram of ranks'\n",
    "data_q50_var, avg_rank_q50_var = run_statistical_comparison_analysis(ens_params['var_model_type'],\n",
    "                                                                lst_rmse_var_ensemble,\n",
    "                                                                lst_rmse_var_best_model, \n",
    "                                                                lst_rmse_var_equal_weights, \n",
    "                                                                lst_rmse_var_weighted_avg,\n",
    "                                                                lst_rmse_var_weighted_avg_soft, \n",
    "                                                                lst_rmse_var_baseline_dayahead, \n",
    "                                                                lst_rmse_var_baseline_dayahead11h, \n",
    "                                                                lst_rmse_var_baseline_week_ahead,\n",
    "                                                                lst_rmse_var_baseline_most_recent,\n",
    "                                                                lst_rmse_var_baseline_malicious,\n",
    "                                                                lst_rmse_var_baseline_noisy,\n",
    "                                                                title1, title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the styled DataFrame\n",
    "dfs = [data_q10, data_q50, data_q90, data_q50_var]\n",
    "prefixes = ['Q10', 'Q50', 'Q90', 'Q50_var']\n",
    "result, styled_result = display_table_metrics(dfs, prefixes)\n",
    "styled_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute percentage of improvement of the best\n",
    "perc_improvement_df = (result/np.min(result, axis=0)-1)*100\n",
    "perc_improvement_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute mean rmse and se\n",
    "mean_rmse_ensemble = np.mean(lst_rmse_ensemble)\n",
    "mean_rmse_best_model = np.mean(lst_rmse_best_model)\n",
    "mean_rmse_equal_weights = np.mean(lst_rmse_equal_weights)\n",
    "mean_rmse_weighted_avg = np.mean(lst_rmse_weighted_avg)\n",
    "mean_rmse_weighted_avg_soft = np.mean(lst_rmse_weighted_avg_soft)\n",
    "mean_rmse_baseline_dayahead = np.mean(lst_rmse_baseline_dayahead)\n",
    "mean_rmse_baseline_dayahead11h = np.mean(lst_rmse_baseline_dayahead11h)\n",
    "mean_rmse_baseline_week_ahead = np.mean(lst_rmse_baseline_week_ahead)\n",
    "\n",
    "\n",
    "se_rmse_ensemble = 1.96*sem(lst_rmse_ensemble)\n",
    "se_rmse_best_model = 1.96*sem(lst_rmse_best_model)\n",
    "se_rmse_equal_weights = 1.96*sem(lst_rmse_equal_weights)\n",
    "se_rmse_weighted_avg = 1.96*sem(lst_rmse_weighted_avg)\n",
    "se_rmse_weighted_avg_soft = 1.96*sem(lst_rmse_weighted_avg_soft)\n",
    "se_rmse_baseline_dayahead = 1.96*sem(lst_rmse_baseline_dayahead)\n",
    "se_rmse_baseline_dayahead11h = 1.96*sem(lst_rmse_baseline_dayahead11h)\n",
    "se_rmse_baseline_week_ahead = 1.96*sem(lst_rmse_baseline_week_ahead)\n",
    "\n",
    "# plot seaborn barplot of mean rmse with std\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "data = {'Forecaster': ['QR Ensemble', 'Best Model', 'Equal Weights', 'Weighted Avg', 'Weighted Avg Soft', 'Day-ahead', 'Day-ahead 11h', 'Week-ahead'],\n",
    "        'Mean RMSE': [mean_rmse_ensemble, mean_rmse_best_model, mean_rmse_equal_weights, mean_rmse_weighted_avg, mean_rmse_weighted_avg_soft, mean_rmse_baseline_dayahead, mean_rmse_baseline_dayahead11h, mean_rmse_baseline_week_ahead],\n",
    "        'SE RMSE': [se_rmse_ensemble, se_rmse_best_model, se_rmse_equal_weights, se_rmse_weighted_avg, se_rmse_weighted_avg_soft, se_rmse_baseline_dayahead, se_rmse_baseline_dayahead11h, se_rmse_baseline_week_ahead]}\n",
    "df = pd.DataFrame(data)\n",
    "sns.barplot(x='Mean RMSE', y='Forecaster', data=df, alpha=0.5)\n",
    "# add error bars\n",
    "plt.errorbar(df['Mean RMSE'], df['Forecaster'], xerr=df['SE RMSE'], fmt='o', label='95% CI',)\n",
    "# plot legend\n",
    "plt.legend()\n",
    "plt.title('RMSE')\n",
    "plt.show()\n",
    "\n",
    "# compute mean pinball loss and se quantile 10\n",
    "mean_pb_ensemble_q10 = np.mean(lst_pb_ensemble_q10)\n",
    "mean_pb_best_model_q10 = np.mean(lst_pb_best_model_q10)\n",
    "mean_pb_equal_weights_q10 = np.mean(lst_pb_equal_weights_q10)\n",
    "mean_pb_weighted_avg_q10 = np.mean(lst_pb_weighted_avg_q10)\n",
    "mean_pb_weighted_avg_soft_q10 = np.mean(lst_pb_weighted_avg_soft_q10)\n",
    "mean_pb_baseline_dayahead_q10 = np.mean(lst_pb_dayahead_q10)\n",
    "mean_pb_baseline_dayahead11h_q10 = np.mean(lst_pb_dayahead_11h_q10)\n",
    "mean_pb_baseline_week_ahead_q10 = np.mean(lst_pb_week_ahead_q10)\n",
    "\n",
    "\n",
    "se_pb_ensemble_q10 = 1.96*sem(lst_pb_ensemble_q10)\n",
    "se_pb_best_model_q10 = 1.96*sem(lst_pb_best_model_q10)\n",
    "se_pb_equal_weights_q10 = 1.96*sem(lst_pb_equal_weights_q10)\n",
    "se_pb_weighted_avg_q10 = 1.96*sem(lst_pb_weighted_avg_q10)\n",
    "se_pb_weighted_avg_soft_q10 = 1.96*sem(lst_pb_weighted_avg_soft_q10)\n",
    "se_pb_baseline_dayahead_q10 = 1.96*sem(lst_pb_dayahead_q10)\n",
    "se_pb_baseline_dayahead11h_q10 = 1.96*sem(lst_pb_dayahead_11h_q10)\n",
    "se_pb_baseline_week_ahead_q10 = 1.96*sem(lst_pb_week_ahead_q10)\n",
    "\n",
    "# plot seaborn barplot of mean pinball loss with std\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "data = {'Forecaster': ['QR Ensemble', 'Best Model', 'Equal Weights', 'Weighted Avg', 'Weighted Avg Soft', 'Day-ahead', 'Day-ahead 11h', 'Week-ahead'],\n",
    "        'Mean PB Q10': [mean_pb_ensemble_q10, mean_pb_best_model_q10, mean_pb_equal_weights_q10, mean_pb_weighted_avg_q10, mean_pb_weighted_avg_soft_q10, mean_pb_baseline_dayahead_q10, mean_pb_baseline_dayahead11h_q10, mean_pb_baseline_week_ahead_q10],\n",
    "        'SE PB Q10': [se_pb_ensemble_q10, se_pb_best_model_q10, se_pb_equal_weights_q10, se_pb_weighted_avg_q10, se_pb_weighted_avg_soft_q10, se_pb_baseline_dayahead_q10, se_pb_baseline_dayahead11h_q10, se_pb_baseline_week_ahead_q10]}\n",
    "df = pd.DataFrame(data)\n",
    "sns.barplot(x='Mean PB Q10', y='Forecaster', data=df, alpha=0.5)\n",
    "# add error bars\n",
    "plt.errorbar(df['Mean PB Q10'], df['Forecaster'], xerr=df['SE PB Q10'], fmt='o', label='95% CI',)\n",
    "# plot legend\n",
    "plt.legend()\n",
    "plt.title('Pinball Loss Q10')\n",
    "plt.show()\n",
    "\n",
    "# compute mean pinball loss and se quantile 90\n",
    "mean_pb_ensemble_q90 = np.mean(lst_pb_ensemble_q90)\n",
    "mean_pb_best_model_q90 = np.mean(lst_pb_best_model_q90)\n",
    "mean_pb_equal_weights_q90 = np.mean(lst_pb_equal_weights_q90)\n",
    "mean_pb_weighted_avg_q90 = np.mean(lst_pb_weighted_avg_q90)\n",
    "mean_pb_weighted_avg_soft_q90 = np.mean(lst_pb_weighted_avg_soft_q90)\n",
    "mean_pb_baseline_dayahead_q90 = np.mean(lst_pb_dayahead_q90)\n",
    "mean_pb_baseline_dayahead11h_q90 = np.mean(lst_pb_dayahead_11h_q90)\n",
    "mean_pb_baseline_week_ahead_q90 = np.mean(lst_pb_week_ahead_q90)\n",
    "\n",
    "\n",
    "se_pb_ensemble_q90 = 1.96*sem(lst_pb_ensemble_q90)\n",
    "se_pb_best_model_q90 = 1.96*sem(lst_pb_best_model_q90)\n",
    "se_pb_equal_weights_q90 = 1.96*sem(lst_pb_equal_weights_q90)\n",
    "se_pb_weighted_avg_q90 = 1.96*sem(lst_pb_weighted_avg_q90)\n",
    "se_pb_weighted_avg_soft_q90 = 1.96*sem(lst_pb_weighted_avg_soft_q90)\n",
    "se_pb_baseline_dayahead_q90 = 1.96*sem(lst_pb_dayahead_q90)\n",
    "se_pb_baseline_dayahead11h_q90 = 1.96*sem(lst_pb_dayahead_11h_q90)\n",
    "se_pb_baseline_week_ahead_q90 = 1.96*sem(lst_pb_week_ahead_q90)\n",
    "\n",
    "# plot seaborn barplot of mean pinball loss with std\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "data = {'Forecaster': ['QR Ensemble', 'Best Model', 'Equal Weights', 'Weighted Avg', 'Weighted Avg Soft', 'Day-ahead', 'Day-ahead 11h', 'Week-ahead'],\n",
    "        'Mean PB Q90': [mean_pb_ensemble_q90, mean_pb_best_model_q90, mean_pb_equal_weights_q90, mean_pb_weighted_avg_q90, mean_pb_weighted_avg_soft_q90, mean_pb_baseline_dayahead_q90, mean_pb_baseline_dayahead11h_q90, mean_pb_baseline_week_ahead_q90],\n",
    "        'SE PB Q90': [se_pb_ensemble_q90, se_pb_best_model_q90, se_pb_equal_weights_q90, se_pb_weighted_avg_q90, se_pb_weighted_avg_soft_q90, se_pb_baseline_dayahead_q90, se_pb_baseline_dayahead11h_q90, se_pb_baseline_week_ahead_q90]}\n",
    "df = pd.DataFrame(data)\n",
    "sns.barplot(x='Mean PB Q90', y='Forecaster', data=df, alpha=0.5)\n",
    "# add error bars\n",
    "plt.errorbar(df['Mean PB Q90'], df['Forecaster'], xerr=df['SE PB Q90'], fmt='o', label='95% CI',)\n",
    "# plot legend\n",
    "plt.legend()\n",
    "plt.title('Pinball Loss Q90')\n",
    "plt.show()\n",
    "\n",
    "# compute mean rmse for variability and se\n",
    "mean_rmse_var_ensemble = np.mean(lst_rmse_var_ensemble)\n",
    "mean_rmse_var_best_model = np.mean(lst_rmse_var_best_model)\n",
    "mean_rmse_var_equal_weights = np.mean(lst_rmse_var_equal_weights)\n",
    "mean_rmse_var_weighted_avg = np.mean(lst_rmse_var_weighted_avg)\n",
    "mean_rmse_var_weighted_avg_soft = np.mean(lst_rmse_var_weighted_avg_soft)\n",
    "mean_rmse_var_baseline_dayahead = np.mean(lst_rmse_var_baseline_dayahead)\n",
    "mean_rmse_var_baseline_dayahead11h = np.mean(lst_rmse_var_baseline_dayahead11h)\n",
    "mean_rmse_var_baseline_week_ahead = np.mean(lst_rmse_var_baseline_week_ahead)\n",
    "\n",
    "se_rmse_var_ensemble = 1.96*sem(lst_rmse_var_ensemble)\n",
    "se_rmse_var_best_model = 1.96*sem(lst_rmse_var_best_model)\n",
    "se_rmse_var_equal_weights = 1.96*sem(lst_rmse_var_equal_weights)\n",
    "se_rmse_var_weighted_avg = 1.96*sem(lst_rmse_var_weighted_avg)\n",
    "se_rmse_var_weighted_avg_soft = 1.96*sem(lst_rmse_var_weighted_avg_soft)\n",
    "se_rmse_var_baseline_dayahead = 1.96*sem(lst_rmse_var_baseline_dayahead)\n",
    "se_rmse_var_baseline_dayahead11h = 1.96*sem(lst_rmse_var_baseline_dayahead11h)\n",
    "se_rmse_var_baseline_week_ahead = 1.96*sem(lst_rmse_var_baseline_week_ahead)\n",
    "\n",
    "# plot seaborn barplot of mean rmse with std\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "data = {'Forecaster': ['QR Ensemble', 'Best Model', 'Equal Weights', 'Weighted Avg', 'Weighted Avg Soft', 'Day-ahead', 'Day-ahead 11h', 'Week-ahead'],\n",
    "        'Mean RMSE Var': [mean_rmse_var_ensemble, mean_rmse_var_best_model, mean_rmse_var_equal_weights, mean_rmse_var_weighted_avg, mean_rmse_var_weighted_avg_soft, mean_rmse_var_baseline_dayahead, mean_rmse_var_baseline_dayahead11h, mean_rmse_var_baseline_week_ahead],\n",
    "        'SE RMSE Var': [se_rmse_var_ensemble, se_rmse_var_best_model, se_rmse_var_equal_weights, se_rmse_var_weighted_avg, se_rmse_var_weighted_avg_soft, se_rmse_var_baseline_dayahead, se_rmse_var_baseline_dayahead11h, se_rmse_var_baseline_week_ahead]}\n",
    "df = pd.DataFrame(data)\n",
    "sns.barplot(x='Mean RMSE Var', y='Forecaster', data=df, alpha=0.5)\n",
    "# add error bars\n",
    "plt.errorbar(df['Mean RMSE Var'], df['Forecaster'], xerr=df['SE RMSE Var'], fmt='o', label='95% CI',)\n",
    "# plot legend\n",
    "plt.legend()\n",
    "plt.title('RMSE Variability')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean_cov_ensemble = np.mean(lst_coverage_ensemble)\n",
    "mean_cov_var_ensemble = np.mean(lst_coverage_var_ensemble)\n",
    "mean_cov_best_model = np.mean(lst_coverage_best_model)\n",
    "mean_cov_equal_weights = np.mean(lst_coverage_equal_weights)\n",
    "mean_cov_weighted_avg = np.mean(lst_coverage_weighted_avg)\n",
    "mean_cov_weighted_avg_soft = np.mean(lst_coverage_weighted_avg_soft)\n",
    "mean_cov_baseline_dayahead = np.mean(lst_coverage_baseline_dayahead)\n",
    "mean_cov_baseline_dayahead11h = np.mean(lst_coverage_baseline_dayahead11h)\n",
    "mean_cov_baseline_week_ahead = np.mean(lst_coverage_baseline_week_ahead)\n",
    "\n",
    "\n",
    "se_cov_ensemble = 1.96*sem(lst_coverage_ensemble)\n",
    "se_cov_var_ensemble = 1.96*sem(lst_coverage_var_ensemble)\n",
    "se_cov_best_model = 1.96*sem(lst_coverage_best_model)\n",
    "se_cov_equal_weights = 1.96*sem(lst_coverage_equal_weights)\n",
    "se_cov_weighted_avg = 1.96*sem(lst_coverage_weighted_avg)\n",
    "se_cov_weighted_avg_soft = 1.96*sem(lst_coverage_weighted_avg_soft)\n",
    "se_cov_baseline_dayahead = 1.96*sem(lst_coverage_baseline_dayahead)\n",
    "se_cov_baseline_dayahead11h = 1.96*sem(lst_coverage_baseline_dayahead11h)\n",
    "se_cov_baseline_week_ahead = 1.96*sem(lst_coverage_baseline_week_ahead)\n",
    "\n",
    "# plot seaborn barplot of mean coverage with std\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "data = {'Forecaster': ['QR Ensemble', 'QR Var Ensemble', 'Best Model', 'Equal Weights', 'Weighted Avg', 'Weighted Avg Soft', 'Day-ahead', 'Day-ahead 11h', 'Week-ahead'],\n",
    "        'Mean Coverage': [mean_cov_ensemble, mean_cov_var_ensemble, mean_cov_best_model, mean_cov_equal_weights, mean_cov_weighted_avg, mean_cov_weighted_avg_soft, mean_cov_baseline_dayahead, mean_cov_baseline_dayahead11h, mean_cov_baseline_week_ahead],\n",
    "        'SE Coverage': [se_cov_ensemble, se_cov_var_ensemble, se_cov_best_model, se_cov_equal_weights, se_cov_weighted_avg, se_cov_weighted_avg_soft, se_cov_baseline_dayahead, se_cov_baseline_dayahead11h, se_cov_baseline_week_ahead]}\n",
    "df = pd.DataFrame(data)\n",
    "sns.barplot(x='Mean Coverage', y='Forecaster', data=df, alpha=0.5)\n",
    "# add error bars\n",
    "plt.errorbar(df['Mean Coverage'], df['Forecaster'], xerr=df['SE Coverage'], fmt='o', label='95% CI',)\n",
    "# vertical line at 0.8\n",
    "plt.axvline(x=0.8, color='r', linestyle='--')\n",
    "# plot legend\n",
    "plt.legend()\n",
    "plt.title('PI Mean Coverage Probability')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mean_width_ensemble = np.mean(lst_avg_width_ensemble)\n",
    "mean_width_ensemble_var = np.mean(lst_avg_width_ensemble_var)\n",
    "mean_width_best_model = np.mean(lst_avg_width_best_model)\n",
    "mean_width_equal_weights = np.mean(lst_avg_width_equal_weights)\n",
    "mean_width_weighted_avg = np.mean(lst_avg_width_weighted_avg)\n",
    "mean_width_weighted_avg_soft = np.mean(lst_avg_width_weighted_avg_soft)\n",
    "mean_width_baseline_dayahead = np.mean(lst_avg_width_baseline_dayahead)\n",
    "mean_width_baseline_dayahead11h = np.mean(lst_avg_width_baseline_dayahead11h)\n",
    "mean_width_baseline_week_ahead = np.mean(lst_avg_width_baseline_week_ahead)\n",
    "\n",
    "se_width_ensemble = 1.96*sem(lst_avg_width_ensemble)\n",
    "se_width_ensemble_var = 1.96*sem(lst_avg_width_ensemble_var)\n",
    "se_width_best_model = 1.96*sem(lst_avg_width_best_model)\n",
    "se_width_equal_weights = 1.96*sem(lst_avg_width_equal_weights)\n",
    "se_width_weighted_avg = 1.96*sem(lst_avg_width_weighted_avg)\n",
    "se_width_weighted_avg_soft = 1.96*sem(lst_avg_width_weighted_avg_soft)\n",
    "se_width_baseline_dayahead = 1.96*sem(lst_avg_width_baseline_dayahead)\n",
    "se_width_baseline_dayahead11h = 1.96*sem(lst_avg_width_baseline_dayahead11h)\n",
    "se_width_baseline_week_ahead = 1.96*sem(lst_avg_width_baseline_week_ahead)\n",
    "\n",
    "# plot seaborn barplot of mean coverage with std\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "data = {'Forecaster': ['QR Ensemble', 'Best Model', 'Equal Weights', 'Weighted Avg', 'Weighted Avg Soft', 'Day-ahead', 'Day-ahead 11h', 'Week-ahead'],\n",
    "        'Mean Width': [mean_width_ensemble, mean_width_best_model, mean_width_equal_weights, mean_width_weighted_avg, mean_width_weighted_avg_soft, mean_width_baseline_dayahead, mean_width_baseline_dayahead11h, mean_width_baseline_week_ahead],\n",
    "        'SE Width': [se_width_ensemble, se_width_best_model, se_width_equal_weights, se_width_weighted_avg, se_width_weighted_avg_soft, se_width_baseline_dayahead, se_width_baseline_dayahead11h, se_width_baseline_week_ahead]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# display mean width value next to the barplot\n",
    "sns.barplot(x='Mean Width', y='Forecaster', data=df, alpha=0.5, label='Mean Width')\n",
    "# add error bars\n",
    "plt.errorbar(df['Mean Width'], df['Forecaster'], xerr=df['SE Width'], fmt='o', label='95% CI',)\n",
    "# vertical line at 0.8\n",
    "plt.axvline(x=0.8, color='r', linestyle='--')\n",
    "# plot legend\n",
    "plt.legend()\n",
    "plt.title('PI Mean Width')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
