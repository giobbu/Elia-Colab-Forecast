{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from source.utils.file_read import read_csv_file, join_dataframes\n",
    "from source.utils.collect_results import create_df_forecaster_first_stage, create_df_forecaster_second_stage\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.simulation.submission_module import submission_forecasters\n",
    "from source.simulation.buyer_module import prepare_buyer_data\n",
    "from source.ensemble.combination_scheme.equal_weights import calculate_equal_weights\n",
    "from source.ensemble.combination_scheme.avg_weights import calculate_weighted_avg\n",
    "from source.ensemble.combination_scheme.model_selection import run_model_selection\n",
    "from source.plots.plot_forecasts import plot_forecasts, plot_var_forecasts\n",
    "from source.ml_engine import create_ensemble_forecasts\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.simulation_setting import Simulation, WeightedAvg, Stack\n",
    "from source.simulation.helpers_simulation import process_combination_scheme\n",
    "from source.utils.session_ml_info import delete_previous_day_pickle\n",
    "sim_params = Simulation.testing_period\n",
    "weight_avg_params = WeightedAvg.params\n",
    "ens_params = Stack.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(sim_params['random_seed'])\n",
    "\n",
    "# read csv file\n",
    "df_filtered = read_csv_file(sim_params['csv_filename'], sim_params['list_columns'], sim_params['starting_period'], sim_params['ending_period'])\n",
    "\n",
    "# replace NaN values\n",
    "if sim_params['replace_nan']:\n",
    "    logger.info(' ')\n",
    "    logger.warning(\"Replacing NaN values with 0s\")\n",
    "    print(df_filtered.isna().sum())\n",
    "    df_filtered.fillna(0, inplace=True)\n",
    "\n",
    "# remove previous day pickle file\n",
    "logger.info(' ')\n",
    "delete_previous_day_pickle()\n",
    "logger.opt(colors = True).warning('previous day pickle file removed')\n",
    "\n",
    "# save csv variables\n",
    "list_csv_to_save = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    if i >= ens_params['day_calibration'] and ens_params['conformalized_qr']:\n",
    "        day_calibration = ens_params['day_calibration']\n",
    "        start_training_timestamp = start_training_timestamp - pd.Timedelta(f'{day_calibration}day')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors=True).info(f'<blue>Start training: {start_training_timestamp} - End training: {end_training_timestamp}</blue>')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors = True).info(f'<blue>Start prediction: {start_prediction_timestamp} - End prediction: {end_prediction_timestamp}</blue>')\n",
    "\n",
    "    df_train = df_filtered[df_filtered.index.to_series().between(start_training_timestamp, end_training_timestamp)].iloc[:-1,:]\n",
    "    df_test = df_filtered[df_filtered.index.to_series().between(start_prediction_timestamp, end_prediction_timestamp)].iloc[:-1,:]\n",
    "                                                                                                                            \n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of training data: {len(df_train)} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of test data: {len(df_test)} </blue>')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue> -----------------> Forecasters prediction submitted </blue>')\n",
    "\n",
    "# # ----------------------------> FORECASTERS PREDICTION SUBMISSION <----------------------------\n",
    "\n",
    "    df_market, df_train, df_test = submission_forecasters(sim_params, df_train, df_test)   \n",
    "\n",
    "# # ----------------------------> BUYERS DATA <----------------------------\n",
    "\n",
    "    df_buyer, forecast_range = prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "\n",
    "# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\n",
    "\n",
    "    results_ensemble_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                                            df_buyer=df_buyer, \n",
    "                                                            df_market=df_market,\n",
    "                                                            end_training_timestamp=end_training_timestamp,\n",
    "                                                            forecast_range = forecast_range,\n",
    "                                                            challenge_usecase='simulation',\n",
    "                                                            simulation=True)\n",
    "    \n",
    "    ## ----------------------------> SAVE to CSV <----------------------------\n",
    "    # wind power\n",
    "    df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']\n",
    "    df_pred_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_predictions', \n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_predictions', \n",
    "                                        'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "    df_pred_ensemble_clean = df_pred_ensemble.drop(columns=['targets'], axis=1)\n",
    "    df_test_clean = df_test.iloc[-96:, :]  # last 96 rows\n",
    "\n",
    "    # wind power variability\n",
    "    df_pred_ensemble_var = results_ensemble_forecasts['wind_power_variability']['predictions']\n",
    "    df_pred_ensemble_var.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_var_predictions',\n",
    "                                            'q10_' + sim_params['buyer_resource_name']: '10_var_predictions',\n",
    "                                            'q90_' + sim_params['buyer_resource_name']: '90_var_predictions',\n",
    "                                            'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "    df_pred_ensemble_var_clean = df_pred_ensemble_var.drop(columns=['targets'], axis=1)\n",
    "    df_test_ensemble_var_clean = df_test.iloc[-96:, :]  # last 96 rows\n",
    "\n",
    "    if sim_params['baselines_comparison']:\n",
    "\n",
    "        # # # ----------------------------> COMBINATION SCHEME DATA <----------------------------\n",
    "\n",
    "        # process data for baselines combination schemes\n",
    "        df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var = process_combination_scheme(df_train, df_test, end_training_timestamp, start_prediction_timestamp)\n",
    "        \n",
    "        # Wind power\n",
    "        df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']   \n",
    "        df_pred_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_predictions', \n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_predictions',\n",
    "                                        'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "        df_pred_ensemble['targets'] = day_previous_df_test_norm['norm_measured'].values[-96:]\n",
    "        \n",
    "        # Wind power variability\n",
    "        df_var_ensemble = results_ensemble_forecasts['wind_power_variability']['predictions']\n",
    "        df_var_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_var_predictions',\n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_var_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_var_predictions',\n",
    "                                        'targets': 'targets'}, inplace=True)\n",
    "        df_var_ensemble['targets'] = day_previous_df_test_norm_var['norm_measured'].values[-96:]\n",
    "        \n",
    "        # create dataframes\n",
    "        df_test_ensemble = pd.DataFrame(df_pred_ensemble['targets']) \n",
    "        df_test_ensemble_var = pd.DataFrame(df_var_ensemble['targets'])\n",
    "\n",
    "    # # ----------------------------> PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "    ## ----------------------------> WIND POWER VARIABILITY - PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model_var = run_model_selection(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid = weight_avg_params['window_size_valid'], var=True)\n",
    "        df_best_model_clean_var = df_best_model_var.rename(columns={'mean_prediction': 'q50_best_model_var'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance weighted average\n",
    "        df_weighted_avg_var, dict_weights_var = calculate_weighted_avg(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid=weight_avg_params['window_size_valid'], var=True)\n",
    "        df_weighted_avg_clean_var = df_weighted_avg_var.rename(columns={'mean_prediction': 'q50_weight_avg_var'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft_var, dict_weights_soft_var = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], var=True, norm='softmax')\n",
    "        df_weighted_avg_soft_clean_var = df_weighted_avg_soft_var.rename(columns={'mean_prediction': 'q50_weight_avg_soft_var'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance equal weights\n",
    "        df_equal_weights_var = calculate_equal_weights(day_previous_df_test_norm_var, start_prediction_timestamp)\n",
    "        df_equal_weights_clean_var = df_equal_weights_var.rename(columns={'mean_prediction': 'q50_equal_weights_var'}).drop(columns=['targets', 'Q10', 'Q90'], axis=1)\n",
    "\n",
    "        # performance day-ahead\n",
    "        df_dayahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead', start_prediction_timestamp)\n",
    "        df_dayahead_var_clean = df_dayahead_var.rename(columns={'norm_dayaheadforecast': 'q50_dayahead_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance day-ahead-11h\n",
    "        df_dayahead_11h_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead11h', start_prediction_timestamp)\n",
    "        df_dayahead_11h_var_clean = df_dayahead_11h_var.rename(columns={'norm_dayahead11hforecast': 'q50_dayahead_11h_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance week ahead\n",
    "        df_week_ahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'weekahead', start_prediction_timestamp)\n",
    "        df_week_ahead_var_clean = df_week_ahead_var.rename(columns={'norm_weekaheadforecast': 'q50_week_ahead_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance most recent\n",
    "        if sim_params['most_recent']:\n",
    "            # performance most recent\n",
    "            df_most_recent_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'mostrecent', start_prediction_timestamp)\n",
    "            df_most_recent_var_clean = df_most_recent_var.rename(columns={'norm_mostrecentforecast': 'q50_most_recent_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance malicious\n",
    "        if sim_params['malicious']:\n",
    "            # performance malicious\n",
    "            df_malicious_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'malicious', start_prediction_timestamp)\n",
    "            df_malicious_var_clean = df_malicious_var.rename(columns={'norm_maliciousforecast': 'q50_malicious_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            # performance noisy\n",
    "            df_noisy_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'noisy', start_prediction_timestamp)\n",
    "            df_noisy_var_clean = df_noisy_var.rename(columns={'norm_noisyforecast': 'q50_noisy_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "    ## ----------------------------> WIND POWER - PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model = run_model_selection(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_best_model_clean = df_best_model.rename(columns={'Q10': 'q10_best_model', \n",
    "                                                            'mean_prediction': 'q50_best_model', \n",
    "                                                            'Q90': 'q90_best_model'}).drop(columns=['targets'], axis=1)\n",
    "        \n",
    "        # performance weighted average\n",
    "        df_weighted_avg, dict_weights = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_weighted_avg_clean = df_weighted_avg.rename(columns={'Q10': 'q10_weight_avg', \n",
    "                                                                'mean_prediction': 'q50_weight_avg', \n",
    "                                                                'Q90': 'q90_weight_avg'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft, dict_weights_soft = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], norm='softmax')\n",
    "        df_weighted_avg_soft_clean = df_weighted_avg_soft.rename(columns={'Q10': 'q10_weight_avg_soft', \n",
    "                                                                        'mean_prediction': 'q50_weight_avg_soft', \n",
    "                                                                        'Q90': 'q90_weight_avg_soft'}).drop(columns=['targets'], axis=1)\n",
    "        \n",
    "        # performance equal weights\n",
    "        df_equal_weights = calculate_equal_weights(day_previous_df_test_norm, start_prediction_timestamp)\n",
    "        df_equal_weights_clean = df_equal_weights.rename(columns={'Q10': 'q10_equal_weights', \n",
    "                                                                'mean_prediction': 'q50_equal_weights',\n",
    "                                                                'Q90': 'q90_equal_weights'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance malicious cheat\n",
    "        if sim_params['malicious']:\n",
    "            df_malicious = create_df_forecaster_first_stage(day_previous_df_test_norm, 'malicious', start_prediction_timestamp)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            df_noisy = create_df_forecaster_first_stage(day_previous_df_test_norm, 'noisy', start_prediction_timestamp)\n",
    "\n",
    "        # plot forecasts\n",
    "        if ens_params['plt_wind_power_ensemble']:\n",
    "            plot_forecasts(df_pred_ensemble, df_test_ensemble, list_wind_ramps=[], title=f'Wind Power Forecasting')\n",
    "\n",
    "        # plot variability forecast results\n",
    "        if ens_params['plt_wind_power_variability_ensemble']:\n",
    "            plot_var_forecasts(df_var_ensemble, df_test_ensemble_var, list_wind_ramps=[], title=f'Wind Power Variability Forecasting')\n",
    "\n",
    "    # join dataframes and append to list\n",
    "    list_df_wind_power = [df_test_clean, df_pred_ensemble_clean, df_best_model_clean, df_weighted_avg_clean, df_weighted_avg_soft_clean, df_equal_weights_clean]\n",
    "    df_csv_wind_power = join_dataframes(*list_df_wind_power)\n",
    "    list_df_wind_power_variability = [df_var_ensemble, df_best_model_clean_var, df_weighted_avg_clean_var, df_weighted_avg_soft_clean_var, df_equal_weights_clean_var, df_dayahead_var_clean, df_dayahead_11h_var_clean, df_week_ahead_var_clean]\n",
    "    df_csv_wind_power_variability = join_dataframes(*list_df_wind_power_variability)\n",
    "    if sim_params['most_recent']:\n",
    "        df_csv_wind_power_variability = df_csv_wind_power_variability.join(df_most_recent_var_clean)\n",
    "    if sim_params['malicious']:\n",
    "        df_csv_wind_power = df_csv_wind_power.join(df_malicious)\n",
    "        df_csv_wind_power_variability = df_csv_wind_power_variability.join(df_malicious_var_clean)\n",
    "    if sim_params['noisy']:\n",
    "        df_csv_wind_power = df_csv_wind_power.join(df_noisy)\n",
    "        df_csv_wind_power_variability = df_csv_wind_power_variability.join(df_noisy_var_clean)\n",
    "    df_csv_wind_power_variability_fillna = df_csv_wind_power_variability.fillna(method='bfill').drop(['10_var_predictions', '90_var_predictions'], axis=1)\n",
    "    # renale measured and targets columns\n",
    "    df_csv_wind_power_variability_fillna.rename(columns={'targets': 'measured_var'}, inplace=True)\n",
    "    df_csv_test_day = join_dataframes(df_csv_wind_power, df_csv_wind_power_variability_fillna)\n",
    "    list_csv_to_save.append(df_csv_test_day)\n",
    "\n",
    "    #Clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    import time\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------> SAVE TO CSV <----------------------------\n",
    "# from list to dataframe\n",
    "df_csv = pd.concat(list_csv_to_save)#.to_csv('ensemble_results_no_mostrecent.csv')\n",
    "#df_csv.head()\n",
    "df_csv[['measured', '10_predictions', '50_predictions', '90_predictions']].iloc[1000:2000].plot(figsize=(20,10)) #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
