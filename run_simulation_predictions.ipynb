{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "from source.utils.file_read import read_csv_file, join_dataframes\n",
    "from source.utils.collect_results import create_df_forecaster_first_stage, create_df_forecaster_second_stage\n",
    "from source.utils.generate_timestamp import generate_timestamps\n",
    "from source.simulation.submission_module import submission_forecasters\n",
    "from source.simulation.buyer_module import prepare_buyer_data\n",
    "from source.ensemble.combination_scheme.equal_weights import calculate_equal_weights\n",
    "from source.ensemble.combination_scheme.avg_weights import calculate_weighted_avg\n",
    "from source.ensemble.combination_scheme.model_selection import run_model_selection\n",
    "from source.plots.plot_forecasts import plot_forecasts, plot_var_forecasts\n",
    "from source.ml_engine import create_ensemble_forecasts\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.simulation_setting import Simulation, WeightedAvg, Stack\n",
    "from source.simulation.helpers_simulation import process_combination_scheme\n",
    "from source.utils.session_ml_info import delete_previous_day_pickle\n",
    "sim_params = Simulation.testing_period\n",
    "weight_avg_params = WeightedAvg.params\n",
    "ens_params = Stack.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(sim_params['random_seed'])\n",
    "\n",
    "# read csv file\n",
    "df_filtered = read_csv_file(sim_params['csv_filename'], sim_params['list_columns'], sim_params['starting_period'], sim_params['ending_period'])\n",
    "\n",
    "# replace NaN values\n",
    "if sim_params['replace_nan']:\n",
    "    logger.info(' ')\n",
    "    logger.warning(\"Replacing NaN values with 0s\")\n",
    "    print(df_filtered.isna().sum())\n",
    "    df_filtered.fillna(0, inplace=True)\n",
    "\n",
    "# remove previous day pickle file\n",
    "logger.info(' ')\n",
    "delete_previous_day_pickle()\n",
    "logger.opt(colors = True).warning('previous day pickle file removed')\n",
    "\n",
    "# save csv variables\n",
    "list_csv_to_save = []\n",
    "\n",
    "# loop over test days\n",
    "for i in tqdm(range(sim_params['num_test_days']), desc='Testing Days'):\n",
    "\n",
    "    # generate timestamps train and prediction\n",
    "    start_training_timestamp, end_training_timestamp, start_prediction_timestamp, end_prediction_timestamp = generate_timestamps(sim_params['start_training'], i, sim_params['window_size'])\n",
    "\n",
    "    if i >= ens_params['day_calibration'] and ens_params['conformalized_qr']:\n",
    "        day_calibration = ens_params['day_calibration']\n",
    "        start_training_timestamp = start_training_timestamp - pd.Timedelta(f'{day_calibration}day')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors=True).info(f'<blue>Start training: {start_training_timestamp} - End training: {end_training_timestamp}</blue>')\n",
    "    logger.opt(colors = True).info('<blue>-------------------------------------------------------------------------------------------</blue>')\n",
    "    logger.opt(colors = True).info(f'<blue>Start prediction: {start_prediction_timestamp} - End prediction: {end_prediction_timestamp}</blue>')\n",
    "\n",
    "    df_train = df_filtered[df_filtered.index.to_series().between(start_training_timestamp, end_training_timestamp)].iloc[:-1,:]\n",
    "    df_test = df_filtered[df_filtered.index.to_series().between(start_prediction_timestamp, end_prediction_timestamp)].iloc[:-1,:]\n",
    "                                                                                                                            \n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of training data: {len(df_train)} </blue>')\n",
    "    logger.opt(colors = True).info(f'<blue> -----------------> Length of test data: {len(df_test)} </blue>')\n",
    "\n",
    "    logger.info(' ')\n",
    "    logger.opt(colors = True).info('<blue> -----------------> Forecasters prediction submitted </blue>')\n",
    "\n",
    "# # ----------------------------> FORECASTERS PREDICTION SUBMISSION <----------------------------\n",
    "\n",
    "    df_market, df_train, df_test = submission_forecasters(sim_params, df_train, df_test)   \n",
    "\n",
    "# # ----------------------------> BUYERS DATA <----------------------------\n",
    "\n",
    "    df_buyer, forecast_range = prepare_buyer_data(df_train, df_test, start_prediction_timestamp, end_prediction_timestamp)\n",
    "\n",
    "# # ----------------------------> PREDICO PLATFORM ML ENGINE <----------------------------\n",
    "\n",
    "# # ----------------------------> ENSEMBLE FORECASTS <----------------------------\n",
    "\n",
    "    results_ensemble_forecasts = create_ensemble_forecasts(ens_params=ens_params,\n",
    "                                                            df_buyer=df_buyer, \n",
    "                                                            df_market=df_market,\n",
    "                                                            end_training_timestamp=end_training_timestamp,\n",
    "                                                            forecast_range = forecast_range,\n",
    "                                                            challenge_usecase='simulation',\n",
    "                                                            simulation=True)\n",
    "    \n",
    "    ## ----------------------------> SAVE to CSV <----------------------------\n",
    "    # wind power\n",
    "    df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']\n",
    "    df_pred_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_predictions', \n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_predictions', \n",
    "                                        'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "    df_pred_ensemble_clean = df_pred_ensemble.drop(columns=['targets'], axis=1)\n",
    "    df_test_clean = df_test.iloc[-96:, :]  # last 96 rows\n",
    "\n",
    "    # wind power variability\n",
    "    df_pred_ensemble_var = results_ensemble_forecasts['wind_power_variability']['predictions']\n",
    "    df_pred_ensemble_var.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_var_predictions',\n",
    "                                            'q10_' + sim_params['buyer_resource_name']: '10_var_predictions',\n",
    "                                            'q90_' + sim_params['buyer_resource_name']: '90_var_predictions',\n",
    "                                            'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "    df_pred_ensemble_var_clean = df_pred_ensemble_var.drop(columns=['targets'], axis=1)\n",
    "    df_test_ensemble_var_clean = df_test.iloc[-96:, :]  # last 96 rows\n",
    "\n",
    "    if sim_params['baselines_comparison']:\n",
    "\n",
    "        # # # ----------------------------> COMBINATION SCHEME DATA <----------------------------\n",
    "\n",
    "        # process data for baselines combination schemes\n",
    "        df_train_norm, day_previous_df_test_norm, day_previous_df_test_norm_var = process_combination_scheme(df_train, df_test, end_training_timestamp, start_prediction_timestamp)\n",
    "        \n",
    "        # Wind power\n",
    "        df_pred_ensemble = results_ensemble_forecasts['wind_power']['predictions']   \n",
    "        df_pred_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_predictions', \n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_predictions',\n",
    "                                        'norm_' + sim_params['buyer_resource_name']: 'targets'}, inplace=True)\n",
    "        df_pred_ensemble['targets'] = day_previous_df_test_norm['norm_measured'].values[-96:]\n",
    "        \n",
    "        # Wind power variability\n",
    "        df_var_ensemble = results_ensemble_forecasts['wind_power_variability']['predictions']\n",
    "        df_var_ensemble.rename(columns={'q50_' + sim_params['buyer_resource_name']: '50_var_predictions',\n",
    "                                        'q10_' + sim_params['buyer_resource_name']: '10_var_predictions',\n",
    "                                        'q90_' + sim_params['buyer_resource_name']: '90_var_predictions',\n",
    "                                        'targets': 'targets'}, inplace=True)\n",
    "        df_var_ensemble['targets'] = day_previous_df_test_norm_var['norm_measured'].values[-96:]\n",
    "        \n",
    "        # create dataframes\n",
    "        df_test_ensemble = pd.DataFrame(df_pred_ensemble['targets']) \n",
    "        df_test_ensemble_var = pd.DataFrame(df_var_ensemble['targets'])\n",
    "\n",
    "    # # ----------------------------> PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "    ## ----------------------------> WIND POWER VARIABILITY - PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model_var = run_model_selection(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid = weight_avg_params['window_size_valid'], var=True)\n",
    "        df_best_model_clean_var = df_best_model_var.rename(columns={'mean_prediction': 'q50_best_model_var'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance weighted average\n",
    "        df_weighted_avg_var, dict_weights_var = calculate_weighted_avg(sim_params, df_train_norm , day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp , window_size_valid=weight_avg_params['window_size_valid'], var=True)\n",
    "        df_weighted_avg_clean_var = df_weighted_avg_var.rename(columns={'mean_prediction': 'q50_weight_avg_var'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft_var, dict_weights_soft_var = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], var=True, norm='softmax')\n",
    "        df_weighted_avg_soft_clean_var = df_weighted_avg_soft_var.rename(columns={'mean_prediction': 'q50_weight_avg_soft_var'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance equal weights\n",
    "        df_equal_weights_var = calculate_equal_weights(day_previous_df_test_norm_var, start_prediction_timestamp)\n",
    "        df_equal_weights_clean_var = df_equal_weights_var.rename(columns={'mean_prediction': 'q50_equal_weights_var'}).drop(columns=['targets', 'Q10', 'Q90'], axis=1)\n",
    "\n",
    "        # performance day-ahead\n",
    "        df_dayahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead', start_prediction_timestamp)\n",
    "        df_dayahead_var_clean = df_dayahead_var.rename(columns={'norm_dayaheadforecast': 'q50_dayahead_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance day-ahead-11h\n",
    "        df_dayahead_11h_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'dayahead11h', start_prediction_timestamp)\n",
    "        df_dayahead_11h_var_clean = df_dayahead_11h_var.rename(columns={'norm_dayahead11hforecast': 'q50_dayahead_11h_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance week ahead\n",
    "        df_week_ahead_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'weekahead', start_prediction_timestamp)\n",
    "        df_week_ahead_var_clean = df_week_ahead_var.rename(columns={'norm_weekaheadforecast': 'q50_week_ahead_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance most recent\n",
    "        if sim_params['most_recent']:\n",
    "            # performance most recent\n",
    "            df_most_recent_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'mostrecent', start_prediction_timestamp)\n",
    "            df_most_recent_var_clean = df_most_recent_var.rename(columns={'norm_mostrecentforecast': 'q50_most_recent_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance malicious\n",
    "        if sim_params['malicious']:\n",
    "            # performance malicious\n",
    "            df_malicious_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'malicious', start_prediction_timestamp)\n",
    "            df_malicious_var_clean = df_malicious_var.rename(columns={'norm_maliciousforecast': 'q50_malicious_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            # performance noisy\n",
    "            df_noisy_var = create_df_forecaster_second_stage(day_previous_df_test_norm_var, 'noisy', start_prediction_timestamp)\n",
    "            df_noisy_var_clean = df_noisy_var.rename(columns={'norm_noisyforecast': 'q50_noisy_var'}).drop(columns=['norm_measured','targets'], axis=1)\n",
    "\n",
    "    ## ----------------------------> WIND POWER - PERFORMANCE METRICS <----------------------------\n",
    "\n",
    "        # performance best model selection\n",
    "        df_best_model = run_model_selection(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_best_model_clean = df_best_model.rename(columns={'Q10': 'q10_best_model', \n",
    "                                                            'mean_prediction': 'q50_best_model', \n",
    "                                                            'Q90': 'q90_best_model'}).drop(columns=['targets'], axis=1)\n",
    "        \n",
    "        # performance weighted average\n",
    "        df_weighted_avg, dict_weights = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'])\n",
    "        df_weighted_avg_clean = df_weighted_avg.rename(columns={'Q10': 'q10_weight_avg', \n",
    "                                                                'mean_prediction': 'q50_weight_avg', \n",
    "                                                                'Q90': 'q90_weight_avg'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance weighted avg soft\n",
    "        df_weighted_avg_soft, dict_weights_soft = calculate_weighted_avg(sim_params, df_train_norm, day_previous_df_test_norm, end_training_timestamp, start_prediction_timestamp, window_size_valid=weight_avg_params['window_size_valid'], norm='softmax')\n",
    "        df_weighted_avg_soft_clean = df_weighted_avg_soft.rename(columns={'Q10': 'q10_weight_avg_soft', \n",
    "                                                                        'mean_prediction': 'q50_weight_avg_soft', \n",
    "                                                                        'Q90': 'q90_weight_avg_soft'}).drop(columns=['targets'], axis=1)\n",
    "        \n",
    "        # performance equal weights\n",
    "        df_equal_weights = calculate_equal_weights(day_previous_df_test_norm, start_prediction_timestamp)\n",
    "        df_equal_weights_clean = df_equal_weights.rename(columns={'Q10': 'q10_equal_weights', \n",
    "                                                                'mean_prediction': 'q50_equal_weights',\n",
    "                                                                'Q90': 'q90_equal_weights'}).drop(columns=['targets'], axis=1)\n",
    "\n",
    "        # performance malicious cheat\n",
    "        if sim_params['malicious']:\n",
    "            df_malicious = create_df_forecaster_first_stage(day_previous_df_test_norm, 'malicious', start_prediction_timestamp)\n",
    "\n",
    "        # performance noisy\n",
    "        if sim_params['noisy']:\n",
    "            df_noisy = create_df_forecaster_first_stage(day_previous_df_test_norm, 'noisy', start_prediction_timestamp)\n",
    "\n",
    "        # plot forecasts\n",
    "        if ens_params['plt_wind_power_ensemble']:\n",
    "            plot_forecasts(df_pred_ensemble, df_test_ensemble, list_wind_ramps=[], title=f'Wind Power Forecasting')\n",
    "\n",
    "        # plot variability forecast results\n",
    "        if ens_params['plt_wind_power_variability_ensemble']:\n",
    "            plot_var_forecasts(df_var_ensemble, df_test_ensemble_var, list_wind_ramps=[], title=f'Wind Power Variability Forecasting')\n",
    "\n",
    "    # join dataframes and append to list\n",
    "    list_df_wind_power = [df_test_clean, df_pred_ensemble_clean, df_best_model_clean, df_weighted_avg_clean, df_weighted_avg_soft_clean, df_equal_weights_clean]\n",
    "    df_csv_wind_power = join_dataframes(*list_df_wind_power)\n",
    "    list_df_wind_power_variability = [df_var_ensemble, df_best_model_clean_var, df_weighted_avg_clean_var, df_weighted_avg_soft_clean_var, df_equal_weights_clean_var, df_dayahead_var_clean, df_dayahead_11h_var_clean, df_week_ahead_var_clean]\n",
    "    df_csv_wind_power_variability = join_dataframes(*list_df_wind_power_variability)\n",
    "    if sim_params['most_recent']:\n",
    "        df_csv_wind_power_variability = df_csv_wind_power_variability.join(df_most_recent_var_clean)\n",
    "    if sim_params['malicious']:\n",
    "        df_csv_wind_power = df_csv_wind_power.join(df_malicious)\n",
    "        df_csv_wind_power_variability = df_csv_wind_power_variability.join(df_malicious_var_clean)\n",
    "    if sim_params['noisy']:\n",
    "        df_csv_wind_power = df_csv_wind_power.join(df_noisy)\n",
    "        df_csv_wind_power_variability = df_csv_wind_power_variability.join(df_noisy_var_clean)\n",
    "    df_csv_wind_power_variability_fillna = df_csv_wind_power_variability.fillna(method='bfill').drop(['10_var_predictions', '90_var_predictions'], axis=1)\n",
    "    # renale measured and targets columns\n",
    "    df_csv_wind_power_variability_fillna.rename(columns={'targets': 'measured_var'}, inplace=True)\n",
    "    df_csv_test_day = join_dataframes(df_csv_wind_power, df_csv_wind_power_variability_fillna)\n",
    "    list_csv_to_save.append(df_csv_test_day)\n",
    "\n",
    "    #Clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    import time\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50_var_predictions</th>\n",
       "      <th>measured_var</th>\n",
       "      <th>q50_best_model_var</th>\n",
       "      <th>q50_weight_avg_var</th>\n",
       "      <th>q50_weight_avg_soft_var</th>\n",
       "      <th>q10_equal_weights</th>\n",
       "      <th>q50_equal_weights</th>\n",
       "      <th>q90_equal_weights</th>\n",
       "      <th>q50_dayahead_var</th>\n",
       "      <th>q50_dayahead_11h_var</th>\n",
       "      <th>q50_week_ahead_var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-12 00:00:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51.97</td>\n",
       "      <td>949.53</td>\n",
       "      <td>923.483185</td>\n",
       "      <td>900.750491</td>\n",
       "      <td>523.5700</td>\n",
       "      <td>1328.0125</td>\n",
       "      <td>1629.6525</td>\n",
       "      <td>23.79</td>\n",
       "      <td>38.50</td>\n",
       "      <td>13.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 00:15:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51.97</td>\n",
       "      <td>38.50</td>\n",
       "      <td>25.241530</td>\n",
       "      <td>29.177199</td>\n",
       "      <td>555.9900</td>\n",
       "      <td>1356.4900</td>\n",
       "      <td>1640.4875</td>\n",
       "      <td>23.79</td>\n",
       "      <td>38.50</td>\n",
       "      <td>13.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 00:30:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>71.11</td>\n",
       "      <td>39.79</td>\n",
       "      <td>18.580855</td>\n",
       "      <td>26.138771</td>\n",
       "      <td>585.8125</td>\n",
       "      <td>1379.0325</td>\n",
       "      <td>1652.7950</td>\n",
       "      <td>12.35</td>\n",
       "      <td>39.79</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 00:45:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>40.72</td>\n",
       "      <td>18.692830</td>\n",
       "      <td>25.929286</td>\n",
       "      <td>605.0400</td>\n",
       "      <td>1401.1550</td>\n",
       "      <td>1676.1650</td>\n",
       "      <td>14.12</td>\n",
       "      <td>40.72</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 01:00:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.91</td>\n",
       "      <td>25.15</td>\n",
       "      <td>19.708539</td>\n",
       "      <td>16.810650</td>\n",
       "      <td>621.0125</td>\n",
       "      <td>1424.2225</td>\n",
       "      <td>1695.7225</td>\n",
       "      <td>33.09</td>\n",
       "      <td>25.15</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 22:45:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.73</td>\n",
       "      <td>-16.12</td>\n",
       "      <td>-13.524704</td>\n",
       "      <td>-14.915237</td>\n",
       "      <td>288.4625</td>\n",
       "      <td>741.0800</td>\n",
       "      <td>1154.2075</td>\n",
       "      <td>-11.32</td>\n",
       "      <td>-16.12</td>\n",
       "      <td>-12.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 23:00:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.10</td>\n",
       "      <td>-18.65</td>\n",
       "      <td>7.100590</td>\n",
       "      <td>6.747591</td>\n",
       "      <td>281.5675</td>\n",
       "      <td>751.1500</td>\n",
       "      <td>1146.4925</td>\n",
       "      <td>-12.66</td>\n",
       "      <td>-18.65</td>\n",
       "      <td>51.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 23:15:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.51</td>\n",
       "      <td>-20.54</td>\n",
       "      <td>-18.115051</td>\n",
       "      <td>-19.335223</td>\n",
       "      <td>274.5275</td>\n",
       "      <td>741.1925</td>\n",
       "      <td>1124.8800</td>\n",
       "      <td>-16.30</td>\n",
       "      <td>-20.54</td>\n",
       "      <td>-17.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 23:30:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.90</td>\n",
       "      <td>-17.56</td>\n",
       "      <td>-17.974188</td>\n",
       "      <td>-18.651865</td>\n",
       "      <td>268.4175</td>\n",
       "      <td>730.6950</td>\n",
       "      <td>1105.3600</td>\n",
       "      <td>-15.54</td>\n",
       "      <td>-17.56</td>\n",
       "      <td>-20.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-12 23:45:00+00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.81</td>\n",
       "      <td>-12.59</td>\n",
       "      <td>-9.829076</td>\n",
       "      <td>-9.346343</td>\n",
       "      <td>256.9150</td>\n",
       "      <td>725.1950</td>\n",
       "      <td>1095.6900</td>\n",
       "      <td>-13.56</td>\n",
       "      <td>-12.59</td>\n",
       "      <td>-3.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           50_var_predictions  measured_var  \\\n",
       "datetime                                                      \n",
       "2021-05-12 00:00:00+00:00                 0.0         51.97   \n",
       "2021-05-12 00:15:00+00:00                 0.0         51.97   \n",
       "2021-05-12 00:30:00+00:00                 0.0         71.11   \n",
       "2021-05-12 00:45:00+00:00                 0.0          1.50   \n",
       "2021-05-12 01:00:00+00:00                 0.0         -7.91   \n",
       "...                                       ...           ...   \n",
       "2021-05-12 22:45:00+00:00                 0.0        -17.73   \n",
       "2021-05-12 23:00:00+00:00                 0.0        -10.10   \n",
       "2021-05-12 23:15:00+00:00                 0.0         19.51   \n",
       "2021-05-12 23:30:00+00:00                 0.0         10.90   \n",
       "2021-05-12 23:45:00+00:00                 0.0        -20.81   \n",
       "\n",
       "                           q50_best_model_var  q50_weight_avg_var  \\\n",
       "datetime                                                            \n",
       "2021-05-12 00:00:00+00:00              949.53          923.483185   \n",
       "2021-05-12 00:15:00+00:00               38.50           25.241530   \n",
       "2021-05-12 00:30:00+00:00               39.79           18.580855   \n",
       "2021-05-12 00:45:00+00:00               40.72           18.692830   \n",
       "2021-05-12 01:00:00+00:00               25.15           19.708539   \n",
       "...                                       ...                 ...   \n",
       "2021-05-12 22:45:00+00:00              -16.12          -13.524704   \n",
       "2021-05-12 23:00:00+00:00              -18.65            7.100590   \n",
       "2021-05-12 23:15:00+00:00              -20.54          -18.115051   \n",
       "2021-05-12 23:30:00+00:00              -17.56          -17.974188   \n",
       "2021-05-12 23:45:00+00:00              -12.59           -9.829076   \n",
       "\n",
       "                           q50_weight_avg_soft_var  q10_equal_weights  \\\n",
       "datetime                                                                \n",
       "2021-05-12 00:00:00+00:00               900.750491           523.5700   \n",
       "2021-05-12 00:15:00+00:00                29.177199           555.9900   \n",
       "2021-05-12 00:30:00+00:00                26.138771           585.8125   \n",
       "2021-05-12 00:45:00+00:00                25.929286           605.0400   \n",
       "2021-05-12 01:00:00+00:00                16.810650           621.0125   \n",
       "...                                            ...                ...   \n",
       "2021-05-12 22:45:00+00:00               -14.915237           288.4625   \n",
       "2021-05-12 23:00:00+00:00                 6.747591           281.5675   \n",
       "2021-05-12 23:15:00+00:00               -19.335223           274.5275   \n",
       "2021-05-12 23:30:00+00:00               -18.651865           268.4175   \n",
       "2021-05-12 23:45:00+00:00                -9.346343           256.9150   \n",
       "\n",
       "                           q50_equal_weights  q90_equal_weights  \\\n",
       "datetime                                                          \n",
       "2021-05-12 00:00:00+00:00          1328.0125          1629.6525   \n",
       "2021-05-12 00:15:00+00:00          1356.4900          1640.4875   \n",
       "2021-05-12 00:30:00+00:00          1379.0325          1652.7950   \n",
       "2021-05-12 00:45:00+00:00          1401.1550          1676.1650   \n",
       "2021-05-12 01:00:00+00:00          1424.2225          1695.7225   \n",
       "...                                      ...                ...   \n",
       "2021-05-12 22:45:00+00:00           741.0800          1154.2075   \n",
       "2021-05-12 23:00:00+00:00           751.1500          1146.4925   \n",
       "2021-05-12 23:15:00+00:00           741.1925          1124.8800   \n",
       "2021-05-12 23:30:00+00:00           730.6950          1105.3600   \n",
       "2021-05-12 23:45:00+00:00           725.1950          1095.6900   \n",
       "\n",
       "                           q50_dayahead_var  q50_dayahead_11h_var  \\\n",
       "datetime                                                            \n",
       "2021-05-12 00:00:00+00:00             23.79                 38.50   \n",
       "2021-05-12 00:15:00+00:00             23.79                 38.50   \n",
       "2021-05-12 00:30:00+00:00             12.35                 39.79   \n",
       "2021-05-12 00:45:00+00:00             14.12                 40.72   \n",
       "2021-05-12 01:00:00+00:00             33.09                 25.15   \n",
       "...                                     ...                   ...   \n",
       "2021-05-12 22:45:00+00:00            -11.32                -16.12   \n",
       "2021-05-12 23:00:00+00:00            -12.66                -18.65   \n",
       "2021-05-12 23:15:00+00:00            -16.30                -20.54   \n",
       "2021-05-12 23:30:00+00:00            -15.54                -17.56   \n",
       "2021-05-12 23:45:00+00:00            -13.56                -12.59   \n",
       "\n",
       "                           q50_week_ahead_var  \n",
       "datetime                                       \n",
       "2021-05-12 00:00:00+00:00               13.17  \n",
       "2021-05-12 00:15:00+00:00               13.17  \n",
       "2021-05-12 00:30:00+00:00                2.91  \n",
       "2021-05-12 00:45:00+00:00                0.65  \n",
       "2021-05-12 01:00:00+00:00                1.74  \n",
       "...                                       ...  \n",
       "2021-05-12 22:45:00+00:00              -12.95  \n",
       "2021-05-12 23:00:00+00:00               51.57  \n",
       "2021-05-12 23:15:00+00:00              -17.35  \n",
       "2021-05-12 23:30:00+00:00              -20.66  \n",
       "2021-05-12 23:45:00+00:00               -3.56  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv_wind_power_variability_fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------> SAVE TO CSV <----------------------------\n",
    "# from list to dataframe\n",
    "df_csv = pd.concat(list_csv_to_save)#.to_csv('ensemble_results_no_mostrecent.csv')\n",
    "#df_csv.head()\n",
    "df_csv[['measured', '10_predictions', '50_predictions', '90_predictions']].iloc[1000:2000].plot(figsize=(20,10)) #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
